"""
Procesador de mensajes y comandos para la interfaz de chat
VERSI√ìN SIMPLIFICADA CON SISTEMA DE PLANTILLAS SQL
"""
import random
from datetime import datetime
from typing import Dict, Any
from app.core.config import Config
from app.core.logging import get_logger

class MessageProcessor:
    """Procesador de mensajes simplificado con sistema de plantillas SQL"""

    def __init__(self, gemini_client=None, pdf_panel=None):
        """Inicializa el procesador de mensajes"""
        self.gemini_client = gemini_client
        self.pdf_panel = pdf_panel

        # üÜï LOGGING CENTRALIZADO
        self.logger = get_logger(__name__)

        # üéØ INICIALIZAR MASTER INTERPRETER AL CARGAR EL SISTEMA
        self.logger.info("üéØ [MESSAGEPROCESSOR] Inicializando MasterInterpreter al cargar sistema...")
        from app.core.ai.interpretation.master_interpreter import MasterInterpreter
        self.master_interpreter = MasterInterpreter(self.gemini_client)
        self.logger.info("‚úÖ [MESSAGEPROCESSOR] MasterInterpreter inicializado y listo")

        # CONTEXTO CONVERSACIONAL SIMPLE
        self.conversation_history = []
        self.last_query_results = None

        # üîß ATRIBUTOS REQUERIDOS PARA COMPATIBILIDAD
        self.conversation_stack = []
        self.awaiting_continuation = False

        # üÜï FRASES DESDE CONFIGURACI√ìN CENTRALIZADA
        self.greeting_phrases = Config.RESPONSES['greeting_phrases']
        self.success_phrases = Config.RESPONSES['success_phrases']

        # üéØ CONFIGURACI√ìN INTELIGENTE: ACCIONES ‚Üí VISUALIZACI√ìN
        self.action_display_config = {
            # SIEMPRE mostrar datos (distribuciones, estad√≠sticas)
            "CALCULAR_ESTADISTICA": "always",

            # CONDICIONAL seg√∫n cantidad (b√∫squedas, listas)
            "BUSCAR_UNIVERSAL": "conditional",
            "consulta_sql_exitosa": "conditional",

            # NUNCA mostrar datos t√©cnicos (solo respuesta humana)
            "OBTENER_ALUMNO_EXACTO": "never",
            "GENERAR_CONSTANCIA_COMPLETA": "never",
            "ayuda_proporcionada": "never",
            "ayuda_funcionalidades": "never",
            "conversacion_general": "never",

            # ESPECIALES (manejan su propia visualizaci√≥n)
            "constancia_preview": "special",
            "transformation_preview": "special",
            "solicitar_aclaracion": "special"
        }

        # üéØ UMBRALES CONFIGURABLES
        self.display_thresholds = {
            "max_auto_display": 50,      # M√°ximo para mostrar autom√°ticamente
            "large_list_limit": 25,      # L√≠mite para listas grandes
            "summary_threshold": 100     # Umbral para mostrar solo resumen
        }

        self.logger.info("‚úÖ MessageProcessor inicializado con MasterInterpreter cargado")
    def should_display_data(self, action: str, data_count: int) -> bool:
        """
        üéØ DECISI√ìN INTELIGENTE: ¬øMostrar datos estructurados?

        Args:
            action: Acci√≥n ejecutada (ej: CALCULAR_ESTADISTICA, BUSCAR_UNIVERSAL)
            data_count: Cantidad de registros en los datos

        Returns:
            bool: True si debe mostrar datos estructurados
        """
        # Obtener configuraci√≥n para esta acci√≥n
        display_mode = self.action_display_config.get(action, "conditional")

        if display_mode == "always":
            self.logger.info(f"üéØ [DISPLAY_DECISION] {action} ‚Üí ALWAYS ‚Üí Mostrar datos ({data_count} registros)")
            return True
        elif display_mode == "never":
            self.logger.info(f"üéØ [DISPLAY_DECISION] {action} ‚Üí NEVER ‚Üí Solo respuesta humana")
            return False
        elif display_mode == "special":
            self.logger.info(f"üéØ [DISPLAY_DECISION] {action} ‚Üí SPECIAL ‚Üí Manejo espec√≠fico")
            return False  # Las acciones especiales manejan su propia visualizaci√≥n
        elif display_mode == "conditional":
            # Decisi√≥n basada en cantidad de datos
            should_show = data_count <= self.display_thresholds["max_auto_display"]
            decision = "Mostrar" if should_show else "Solo resumen"
            self.logger.info(f"üéØ [DISPLAY_DECISION] {action} ‚Üí CONDITIONAL ‚Üí {decision} ({data_count} registros)")
            return should_show
        else:
            # Fallback: comportamiento por defecto
            self.logger.info(f"üéØ [DISPLAY_DECISION] {action} ‚Üí DEFAULT ‚Üí Condicional ({data_count} registros)")
            return data_count <= self.display_thresholds["max_auto_display"]





    def process_command(self, command_data, current_pdf=None, original_query=None, conversation_context=None):
        """Procesa un comando y devuelve el resultado"""
        if not command_data:
            return False, "No se pudo entender tu solicitud. ¬øPodr√≠as reformularla?", {}

        # A√±adir consulta original para el bypass SQL
        if original_query and isinstance(command_data, dict):
            command_data["original_query"] = original_query

        # NUEVO: A√±adir contexto conversacional
        if conversation_context and isinstance(command_data, dict):
            command_data["conversation_context"] = conversation_context

        # Procesar el comando
        accion = command_data.get("accion", "desconocida")
        parametros = command_data.get("parametros", {})

        # Si es una transformaci√≥n y hay un PDF cargado, manejarla especialmente
        if accion == "transformar_constancia" and current_pdf:
            # Verificar si el usuario quiere guardar los datos
            if "guardar" in parametros and parametros["guardar"]:
                parametros["guardar_alumno"] = True
            elif "guardar_alumno" in parametros and parametros["guardar_alumno"]:
                # Asegurarse de que el valor sea booleano
                parametros["guardar_alumno"] = True

            # Si hay un PDF cargado, usar esa ruta
            if not parametros.get("ruta_archivo"):
                parametros["ruta_archivo"] = current_pdf

            # Para transformaciones, devolver directamente el comando sin ejecutar
            # El ChatWindow se encargar√° de manejar la transformaci√≥n
            return True, "Iniciando transformaci√≥n de constancia...", {
                "accion": "transformar_constancia",
                "parametros": parametros
            }

        # Si es guardar alumno desde PDF y hay un PDF cargado, usar esa ruta
        if accion == "guardar_alumno_pdf" and current_pdf:
            if not parametros.get("ruta_archivo"):
                parametros["ruta_archivo"] = current_pdf

            command_data["parametros"] = parametros

        # NUEVO FLUJO DIRECTO: Sin CommandExecutor, directo a MasterInterpreter
        return self._execute_with_master_interpreter(command_data)

    def _execute_with_master_interpreter(self, command_data):
        """Ejecuta comando con sistema de plantillas SQL (simplificado)"""
        try:
            accion = command_data.get("accion", "")
            parametros = command_data.get("parametros", {})
            original_query = command_data.get("original_query", "")
            conversation_context = command_data.get("conversation_context", {})

            self.logger.debug(f"Procesando: {accion}")
            self.logger.debug(f"Query original: {original_query}")

            # Preparar consulta para procesar
            consulta_para_procesar = original_query or parametros.get("consulta_original", "")

            if not consulta_para_procesar:
                return False, "No se pudo determinar la consulta a procesar", {}

            # üéØ FLUJO PRINCIPAL: MASTERINTERPRETER
            self.logger.info("üéØ [MESSAGEPROCESSOR] Procesando con MasterInterpreter (ya inicializado)")

            self.logger.debug(f"Enviando a MasterInterpreter: '{consulta_para_procesar}'")

            # Crear contexto de interpretaci√≥n
            from app.core.ai.interpretation.base_interpreter import InterpretationContext

            context = InterpretationContext(
                user_message=consulta_para_procesar,
                conversation_state=conversation_context.get("conversation_state", {}),
                user_preferences={}
            )

            # üÜï AGREGAR PDF_PANEL AL CONTEXTO PARA TRANSFORMACIONES
            if hasattr(self, 'pdf_panel') and self.pdf_panel:
                context.pdf_panel = self.pdf_panel

            # CORREGIDO: Agregar historial conversacional desde self.conversation_history
            if self.conversation_history:
                context.conversation_history = self.conversation_history
                self.logger.debug(f"Pasando {len(self.conversation_history)} mensajes de contexto conversacional")

            # Tambi√©n agregar resultados de √∫ltima consulta para referencias
            if self.last_query_results:
                context.last_query_results = self.last_query_results
                self.logger.debug(f"Pasando resultados de √∫ltima consulta: '{self.last_query_results['user_query']}'")

            # Mantener contexto externo si existe
            if conversation_context.get("conversation_history"):
                context.external_conversation_history = conversation_context["conversation_history"]
            if conversation_context.get("recent_messages"):
                context.recent_messages = conversation_context["recent_messages"]

            # üéØ PROCESAMIENTO CON CONTEXTO CONVERSACIONAL ACTIVADO
            conversation_stack = self.conversation_stack  # ‚Üê USAR PILA REAL

            # üîß CR√çTICO: Agregar conversation_stack al context para que llegue al Student
            context.conversation_stack = conversation_stack



            if conversation_stack:
                self.logger.info(f"üéØ CONTEXTO ACTIVO - {len(conversation_stack)} niveles disponibles")
            else:
                self.logger.info("üéØ CONTEXTO VAC√çO - Procesando consulta individual")



            result = self.master_interpreter.interpret(context, conversation_stack)

            if result:


                # üéØ DECISI√ìN INTELIGENTE BASADA EN CONFIGURACI√ìN DE ACCIONES
                data = result.parameters.get("data", [])
                data_count = len(data) if isinstance(data, list) else 0

                if self.should_display_data(result.action, data_count):
                    message = result.parameters.get("human_response",
                                                   result.parameters.get("message", "Consulta procesada"))

                    # NUEVO: Procesar auto-reflexi√≥n del LLM
                    # Para BUSCAR_UNIVERSAL, la auto-reflexi√≥n est√° en 'reflexion_conversacional'
                    auto_reflexion = result.parameters.get("reflexion_conversacional",
                                                          result.parameters.get("auto_reflexion", {}))

                    # üîß DEBUG: Verificar si auto-reflexi√≥n est√° llegando
                    self.logger.info(f"üß† DEBUG - Auto-reflexi√≥n recibida: {auto_reflexion}")



                    # üéØ CONTEXTO ACTIVADO - Evaluar auto-reflexi√≥n para conversation_stack
                    if auto_reflexion.get("espera_continuacion", False):
                        tipo_esperado = auto_reflexion.get("tipo_esperado", "analysis")
                        datos_recordar = auto_reflexion.get("datos_recordar", {})

                        self.logger.info(f"üéØ CONTEXTO ACTIVADO - Auto-reflexi√≥n detecta continuaci√≥n esperada: {tipo_esperado}")

                        # Agregar a conversation_stack
                        self.add_to_conversation_stack(
                            consulta_para_procesar,
                            {**result.parameters, **datos_recordar},
                            tipo_esperado
                        )
                    else:
                        self.logger.info("üéØ CONTEXTO EVALUADO - No se espera continuaci√≥n para esta consulta")

                    # üéØ CONFIGURAR DATOS ESTRUCTURADOS PARA DATADISPLAYMANAGER
                    # (data ya extra√≠do arriba)
                    row_count = result.parameters.get("row_count", data_count)

                    # Si hay datos, configurar para mostrar con DataDisplayManager
                    if data and data_count > 0:
                        self.logger.info(f"üéØ Datos estructurados detectados ({row_count} registros) - Configurando para DataDisplayManager")

                        # Configurar par√°metros para DataDisplayManager
                        formatted_parameters = result.parameters.copy()
                        formatted_parameters["action"] = "show_data"

                        # Mantener datos en formato original para que DataDisplayManager los detecte
                        # No necesitamos agregar clave "alumnos" - DataDisplayManager lo detecta autom√°ticamente

                        # NUEVO: Guardar conversaci√≥n con resultados formateados
                        self.logger.debug(f"Guardando conversaci√≥n con datos estructurados: '{consulta_para_procesar}' -> '{message[:50]}...'")
                        self.add_to_conversation(consulta_para_procesar, message, formatted_parameters)
                        self.logger.debug(f"Total mensajes en historial: {len(self.conversation_history)}")



                        return True, message, formatted_parameters

                    else:
                        # Sin datos estructurados, procesar normalmente
                        # NUEVO: Guardar conversaci√≥n con resultados
                        self.logger.debug(f"Guardando conversaci√≥n: '{consulta_para_procesar}' -> '{message[:50]}...'")
                        self.add_to_conversation(consulta_para_procesar, message, result.parameters)
                        self.logger.debug(f"Total mensajes en historial: {len(self.conversation_history)}")

                        return True, message, result.parameters

                elif result.action in ["ayuda_proporcionada", "ayuda_funcionalidades", "ayuda_solucion", "ayuda_ejemplo",
                                     "conversacion_general", "estadisticas_generadas",
                                     "constancia_generada", "constancia_requiere_aclaracion"]:
                    # üõ†Ô∏è USAR EL MENSAJE REAL GENERADO POR EL HELPINTERPRETER
                    message = result.parameters.get("message",
                                                   result.parameters.get("mensaje", "Respuesta procesada"))

                    # NUEVO: Guardar conversaci√≥n
                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)

                    return True, message, result.parameters

                # üÜï NUEVAS ACCIONES DE CONSTANCIA
                elif result.action == "constancia_preview":
                    message = result.parameters.get("message", "Vista previa de constancia generada")

                    # Procesar auto-reflexi√≥n para constancias
                    auto_reflexion = result.parameters.get("auto_reflexion", {})
                    if auto_reflexion.get("espera_continuacion", False):
                        datos_recordar = auto_reflexion.get("datos_recordar", {})

                        self.logger.debug(f"Constancia con auto-reflexi√≥n: {auto_reflexion.get('razonamiento', '')}")
                        self.add_to_conversation_stack(
                            consulta_para_procesar,
                            {**result.parameters, **datos_recordar},
                            "confirmation"  # Espera confirmaci√≥n para constancia
                        )

                    # üéØ AGREGAR ACCI√ìN A LOS PAR√ÅMETROS PARA QUE LLEGUE AL CHATENGINE
                    parameters_with_action = result.parameters.copy()
                    parameters_with_action["action"] = result.action  # ‚Üê PRESERVAR ACCI√ìN

                    self.add_to_conversation(consulta_para_procesar, message, parameters_with_action)
                    return True, message, parameters_with_action

                elif result.action in ["constancia_confirmada", "constancia_abierta", "constancia_cancelada"]:
                    message = result.parameters.get("message", "Acci√≥n de constancia completada")

                    # Limpiar pila conversacional despu√©s de acci√≥n de constancia
                    self.clear_conversation_stack()

                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)
                    return True, message, result.parameters

                elif result.action == "transformar_constancia":
                    # Manejar transformaci√≥n de constancia
                    data_with_action = result.parameters.copy()
                    data_with_action["accion"] = "transformar_constancia"
                    return True, result.parameters.get("message", "Transformaci√≥n iniciada"), data_with_action

                elif result.action == "constancia_error":
                    # üÜï USAR MENSAJE AMIGABLE EN LUGAR DE ERROR T√âCNICO
                    error_message = result.parameters.get("message", "Error al procesar constancia")
                    return False, error_message, result.parameters

                elif result.action == "transformation_preview":
                    # üÜï MANEJAR VISTA PREVIA DE TRANSFORMACI√ìN
                    message = result.parameters.get("message", "Vista previa de transformaci√≥n generada")

                    # üéØ AGREGAR ACCI√ìN A LOS PAR√ÅMETROS PARA QUE LLEGUE AL CHATENGINE
                    parameters_with_action = result.parameters.copy()
                    parameters_with_action["action"] = result.action  # ‚Üê PRESERVAR ACCI√ìN

                    # üîç DEBUG: Verificar que la acci√≥n se est√° agregando
                    self.logger.info(f"üîç [DEBUG] TRANSFORMATION_PREVIEW - Acci√≥n agregada: {parameters_with_action.get('action')}")
                    self.logger.info(f"üîç [DEBUG] TRANSFORMATION_PREVIEW - Mensaje: {message}")
                    self.logger.info(f"üîç [DEBUG] TRANSFORMATION_PREVIEW - Parameters keys: {list(parameters_with_action.keys())}")

                    self._handle_transformation_preview(parameters_with_action)
                    return True, message, parameters_with_action

                elif result.action == "transformation_error":
                    # üÜï MANEJAR ERRORES DE TRANSFORMACI√ìN
                    error_message = result.parameters.get("message", "Error al transformar PDF")
                    return False, error_message, result.parameters

                # NUEVO: Manejar resultados del sistema conversacional
                elif result.action == "seleccion_realizada":
                    message = result.parameters.get("message", "Selecci√≥n realizada")

                    # Agregar a la pila conversacional si es necesario
                    elemento_seleccionado = result.parameters.get("elemento_seleccionado", {})
                    if elemento_seleccionado:
                        self.add_to_conversation_stack(
                            consulta_para_procesar,
                            {"data": [elemento_seleccionado], "row_count": 1, "message": message},
                            "action"  # Espera acci√≥n sobre el elemento seleccionado
                        )

                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)
                    return True, message, result.parameters

                elif result.action in ["accion_realizada", "confirmacion_realizada", "especificacion_realizada"]:
                    message = result.parameters.get("message", "Acci√≥n procesada")
                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)
                    return True, message, result.parameters

                elif result.action == "continuacion_error":
                    # Error en continuaci√≥n - limpiar pila y proceder normalmente
                    self.clear_conversation_stack()
                    error_message = result.parameters.get("message", "Error en continuaci√≥n conversacional")
                    return False, error_message, result.parameters

                elif result.action == "continuacion_inteligente":
                    # NUEVO: Manejo de continuaci√≥n inteligente
                    message = result.parameters.get("message", "Continuaci√≥n procesada")

                    # Procesar auto-reflexi√≥n si est√° disponible
                    auto_reflexion = result.parameters.get("auto_reflexion", {})
                    if auto_reflexion.get("espera_continuacion", False):
                        tipo_esperado = auto_reflexion.get("tipo_esperado", "action")
                        datos_recordar = auto_reflexion.get("datos_recordar", {})

                        self.logger.debug(f"Continuaci√≥n inteligente con auto-reflexi√≥n: {auto_reflexion.get('razonamiento', '')}")
                        self.add_to_conversation_stack(consulta_para_procesar, {**result.parameters, **datos_recordar}, tipo_esperado)
                    else:
                        self.logger.debug(f"Continuaci√≥n inteligente completada: {result.parameters.get('razonamiento', '')}")

                    # üîß IMPORTANTE: Agregar return que faltaba
                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)
                    return True, message, result.parameters

                elif result.action == "solicitar_aclaracion":
                    # üîÑ COMUNICACI√ìN BIDIRECCIONAL: Master solicita aclaraci√≥n al usuario
                    message = result.parameters.get("message", "Necesito m√°s informaci√≥n")

                    # üéØ AGREGAR ACCI√ìN A LOS PAR√ÅMETROS PARA QUE LLEGUE AL CHATENGINE
                    parameters_with_action = result.parameters.copy()
                    parameters_with_action["action"] = result.action  # ‚Üê PRESERVAR ACCI√ìN

                    # üîÑ GUARDAR ESTADO DE ESPERA DE CLARIFICACI√ìN
                    # Crear conversation_context si no existe
                    if not hasattr(self, 'conversation_context'):
                        self.conversation_context = {}
                    self.conversation_context["waiting_for"] = "clarification"
                    self.conversation_context["clarification_info"] = result.parameters

                    self.logger.info(f"üîÑ [MESSAGEPROCESSOR] Solicitando aclaraci√≥n al usuario")
                    return True, message, parameters_with_action

                else:
                    # Otros tipos de resultado
                    message = result.parameters.get("mensaje",
                                                   result.parameters.get("message", "Consulta procesada"))

                    # NUEVO: Procesar auto-reflexi√≥n si est√° disponible (para otros tipos de resultado)
                    auto_reflexion = result.parameters.get("auto_reflexion", {})
                    if auto_reflexion.get("espera_continuacion", False):
                        tipo_esperado = auto_reflexion.get("tipo_esperado", "action")
                        datos_recordar = auto_reflexion.get("datos_recordar", {})

                        self.logger.debug(f"Auto-reflexi√≥n en resultado '{result.action}': {auto_reflexion.get('razonamiento', '')}")
                        self.add_to_conversation_stack(consulta_para_procesar, {**result.parameters, **datos_recordar}, tipo_esperado)

                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)
                    return True, message, result.parameters
            else:
                return False, "No se pudo procesar la consulta", {}

        except Exception as e:
            self.logger.error(f"Error en _execute_with_master_interpreter: {str(e)}")
            return False, f"Error procesando consulta: {str(e)}", {}





    def get_current_time(self):
        """Obtiene la hora actual en formato HH:MM"""
        now = datetime.now()
        return now.strftime("%H:%M")

    def get_random_greeting(self):
        """Devuelve un saludo aleatorio"""
        return random.choice(self.greeting_phrases)

    def get_random_success_phrase(self):
        """Devuelve una frase de √©xito aleatoria"""
        return random.choice(self.success_phrases)

    def add_to_conversation_stack(self, query, result_data, awaiting_type):
        """
        Agrega nivel a la pila conversacional seg√∫n PROTOCOLO_COMUNICACION_BIDIRECCIONAL.md

        Args:
            query (str): Consulta del usuario que gener√≥ estos datos
            result_data (dict): Datos del resultado (data, row_count, sql_executed)
            awaiting_type (str): Tipo de continuaci√≥n esperada (analysis, action, confirmation, selection)
        """
        from datetime import datetime



        # Estructura seg√∫n PROTOCOLO_COMUNICACION_BIDIRECCIONAL.md
        level = {
            "id": len(self.conversation_stack) + 1,
            "query": query,
            "data": result_data.get("data", []),
            "row_count": result_data.get("row_count", 0),
            "sql_executed": result_data.get("sql_executed", ""),
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "awaiting": awaiting_type,
            "active": True,
            "context_available": {
                "positions": len(result_data.get("data", [])) > 0,  # "el segundo", "el tercero"
                "names": len(result_data.get("data", [])) > 0,      # "FRANCO", "VALERIA"
                "actions": awaiting_type in ["confirmation", "action"],  # "constancia para"
                "filters": awaiting_type in ["analysis", "selection"]    # "que tengan"
            },
            "priority": 0.9  # M√°s reciente = mayor prioridad
        }

        # Actualizar prioridades de niveles anteriores
        for existing_level in self.conversation_stack:
            existing_level["priority"] *= 0.7  # Reducir prioridad

        self.conversation_stack.append(level)
        self.awaiting_continuation = True

        self.logger.info(f"üìã [CONVERSATION_STACK] Nivel agregado:")
        self.logger.info(f"    ‚îú‚îÄ‚îÄ Query: '{query}'")
        self.logger.info(f"    ‚îú‚îÄ‚îÄ Datos: {len(result_data.get('data', []))} elementos")
        self.logger.info(f"    ‚îú‚îÄ‚îÄ Esperando: {awaiting_type}")
        self.logger.info(f"    ‚îî‚îÄ‚îÄ Total niveles: {len(self.conversation_stack)}")



    def clear_conversation_stack(self):
        """Limpiar pila conversacional"""
        niveles_eliminados = len(self.conversation_stack)



        self.conversation_stack = []
        self.awaiting_continuation = False

        self.logger.info(f"üóëÔ∏è [CONVERSATION_STACK] Limpiado - {niveles_eliminados} niveles eliminados")



    def add_to_conversation(self, user_message, system_response, query_results=None):
        """Agregar intercambio al historial conversacional"""
        from datetime import datetime

        # Agregar mensaje del usuario
        self.conversation_history.append({
            'role': 'user',
            'content': user_message,
            'timestamp': datetime.now().strftime("%H:%M:%S")
        })

        # Agregar respuesta del sistema
        self.conversation_history.append({
            'role': 'system',
            'content': system_response,
            'timestamp': datetime.now().strftime("%H:%M:%S")
        })

        # Guardar resultados de la √∫ltima consulta para referencias
        if query_results:
            self.last_query_results = {
                'user_query': user_message,
                'results': query_results,
                'timestamp': datetime.now().strftime("%H:%M:%S")
            }

        # Mantener solo √∫ltimos 10 intercambios (20 mensajes)
        if len(self.conversation_history) > 20:
            self.conversation_history = self.conversation_history[-20:]

    def _get_conversation_context(self):
        """Genera contexto conversacional inteligente"""
        if not self.conversation_history:
            return ""

        # √öltimos 3 intercambios (6 mensajes)
        recent_messages = self.conversation_history[-6:]

        if not recent_messages:
            return ""

        context = """

=== CONTEXTO CONVERSACIONAL RECIENTE ===
üìù HISTORIAL DE LA SESI√ìN ACTUAL:
"""

        for msg in recent_messages:
            role_emoji = "üë§" if msg['role'] == 'user' else "ü§ñ"
            # Truncar respuestas largas del sistema
            content = msg['content']
            if msg['role'] == 'system' and len(content) > 150:
                content = content[:150] + "..."

            context += f"{role_emoji} {msg['role'].title()}: {content}\n"

        # Agregar informaci√≥n de √∫ltimos resultados si existen
        if self.last_query_results:
            context += f"""
üìä √öLTIMA CONSULTA REALIZADA:
- Consulta: "{self.last_query_results['user_query']}"
- Resultados disponibles para referencias
"""

        context += """
üß† INSTRUCCIONES PARA USO INTELIGENTE DEL CONTEXTO:
- USA el contexto SOLO si la consulta actual hace referencia a informaci√≥n anterior
- Si el usuario dice "el primero", "ese", "√©l", "ella" ‚Üí busca en el contexto
- Si dice "y cu√°ntos...", "tambi√©n...", "adem√°s..." ‚Üí relaciona con consulta anterior
- Si es una consulta completamente nueva ‚Üí IGNORA el contexto
- Si hay dudas sobre referencias ‚Üí pregunta al usuario para aclarar

EJEMPLOS DE CU√ÅNDO USAR CONTEXTO:
‚úÖ "CURP del tercero" (despu√©s de mostrar lista)
‚úÖ "constancia para √©l" (despu√©s de mostrar alumno espec√≠fico)
‚úÖ "y del turno vespertino" (despu√©s de consulta de grado)
‚ùå "cu√°ntos alumnos hay" (consulta independiente)
‚ùå "buscar Garc√≠a" (consulta nueva)
"""

        return context

    def _handle_transformation_preview(self, parameters: Dict[str, Any]):
        """Maneja vista previa de transformaci√≥n de PDF"""
        try:
            files = parameters.get("files", [])
            if files and self.pdf_panel:
                pdf_path = files[0]
                self.logger.info(f"Cargando vista previa de transformaci√≥n: {pdf_path}")

                # Cargar PDF transformado en el panel
                self.pdf_panel.show_pdf(pdf_path)

                # Establecer contexto de transformaci√≥n completada
                alumno_data = parameters.get("alumno", {})
                transformation_info = parameters.get("transformation_info", {})

                if hasattr(self.pdf_panel, 'set_transformation_completed_context'):
                    self.pdf_panel.set_transformation_completed_context(
                        original_data=self.pdf_panel.pdf_data,
                        transformed_data=parameters.get("data", {}),
                        alumno_data=alumno_data
                    )

                self.logger.debug(f"Vista previa de transformaci√≥n cargada: {transformation_info.get('tipo_transformacion', 'N/A')}")

        except Exception as e:
            self.logger.error(f"Error manejando vista previa de transformaci√≥n: {e}")

    # ==========================================
    # M√âTODOS DE GESTI√ìN DE PILA CONVERSACIONAL
    # ==========================================





    # üóëÔ∏è M√âTODOS DEL SISTEMA DE MEMORIA PROBLEM√ÅTICO ELIMINADOS
    # El sistema de plantillas SQL los reemplaza completamente

