"""
Int√©rprete maestro - Coordina todos los m√≥dulos de interpretaci√≥n
"""
from typing import Optional
from app.core.ai.interpretation.base_interpreter import InterpretationContext, InterpretationResult
from app.core.ai.interpretation.intention_detector import IntentionDetector
from app.core.ai.interpretation.student_query_interpreter import StudentQueryInterpreter
from app.core.logging import get_logger
from app.core.config import Config

class MasterInterpreter:
    """
    üéØ INT√âRPRETE MAESTRO - L√çDER INTELIGENTE DEL SISTEMA

    RESPONSABILIDADES:
    - Detectar intenciones con contexto estrat√©gico completo
    - Dirigir al especialista correcto con informaci√≥n precisa
    - Mantener memoria de interacciones para retroalimentaci√≥n
    - Comunicaci√≥n bidireccional con especialistas
    """

    def __init__(self, gemini_client):
        self.gemini_client = gemini_client
        self.logger = get_logger(__name__)

        # üéØ CONTEXTO ESTRAT√âGICO DEL SISTEMA (SEG√öN INTENCIONES_ACCIONES_DEFINITIVAS.md)
        self.system_map = {
            "StudentQueryInterpreter": {
                "handles": ["consulta_alumnos"],
                "sub_intentions": ["busqueda_simple", "busqueda_compleja", "estadisticas", "generar_constancia", "transformacion_pdf"],
                "capabilities": "Consultas de BD, documentos, an√°lisis de 211 alumnos",
                "description": "Especialista en datos de alumnos y generaci√≥n de documentos"
            },
            "HelpInterpreter": {
                "handles": ["ayuda_sistema"],
                "sub_intentions": ["pregunta_capacidades", "pregunta_tecnica"],
                "capabilities": "Ayuda y soporte t√©cnico del sistema",
                "description": "Especialista en ayuda y explicaciones del sistema"
            },
            "MasterInterpreter": {
                "handles": ["aclaracion_requerida"],
                "sub_intentions": ["multiple_interpretations", "incomplete_query", "ambiguous_reference"],
                "capabilities": "Detecci√≥n de ambig√ºedades y comunicaci√≥n directa con usuario",
                "description": "Master se delega a s√≠ mismo para consultas ambiguas"
            }
        }

        # üí≠ MEMORIA DE INTERACCIONES (RETROALIMENTACI√ìN)
        self.interaction_memory = {
            "last_specialist": None,
            "last_result_summary": None,
            "conversation_flow": None,
            "specialist_feedback": None,
            "awaiting_continuation": False,
            "continuation_type": None
        }

        # üîß INICIALIZAR COMPONENTES
        self.intention_detector = IntentionDetector(gemini_client)

        # üéØ LOGS DE DEPURACI√ìN FORZADOS - CONTEXTO ESTRAT√âGICO COMPLETO
        self.logger.info("üéØ [MASTER] INICIALIZADO CON CONTEXTO ESTRAT√âGICO")
        self.logger.info(f"   ‚îú‚îÄ‚îÄ Especialistas disponibles: {len(self.system_map)}")
        self.logger.info(f"   ‚îú‚îÄ‚îÄ StudentQueryInterpreter: {self.system_map['StudentQueryInterpreter']['capabilities']}")
        self.logger.info(f"   ‚îî‚îÄ‚îÄ HelpInterpreter: {self.system_map['HelpInterpreter']['capabilities']}")

        # üîç DEBUG DETALLADO DEL CONTEXTO ESTRAT√âGICO
        # Puedes cambiar esto a False para desactivar logs detallados
        self.debug_detailed_context = True
        if self.debug_detailed_context:
            self._log_detailed_strategic_context()

        # üéØ INICIALIZAR ESPECIALISTAS (DESPU√âS DE MOSTRAR CONTEXTO MASTER)
        self.logger.info("üéØ [MASTER] Inicializando especialistas...")
        from app.core.config import Config
        db_path = Config.DB_PATH
        self.student_interpreter = StudentQueryInterpreter(db_path, gemini_client)

        from app.core.ai.interpretation.help_interpreter import HelpInterpreter
        self.help_interpreter = HelpInterpreter(gemini_client)
        self.logger.info("‚úÖ [MASTER] Especialistas inicializados correctamente")

    def interpret(self, context: InterpretationContext, conversation_stack=None) -> Optional[InterpretationResult]:
        """
        üéØ INTERPRETACI√ìN MAESTRO CON CONTEXTO ESTRAT√âGICO COMPLETO

        FLUJO MEJORADO:
        1. An√°lisis con contexto estrat√©gico completo
        2. Detecci√≥n de intenci√≥n con memoria de interacciones
        3. Delegaci√≥n inteligente al especialista correcto
        4. Comunicaci√≥n bidireccional y retroalimentaci√≥n
        """
        try:
            # üéØ LOGS DE DEPURACI√ìN FORZADOS
            self.logger.info("üéØ [MASTER] INICIANDO INTERPRETACI√ìN CON CONTEXTO ESTRAT√âGICO")
            self.logger.info(f"   ‚îú‚îÄ‚îÄ Consulta: '{context.user_message}'")
            self.logger.info(f"   ‚îú‚îÄ‚îÄ Conversation_stack: {len(conversation_stack) if conversation_stack else 0} niveles")
            self.logger.info(f"   ‚îî‚îÄ‚îÄ Memoria anterior: {self.interaction_memory}")

            # üéØ PROCESAMIENTO CON CONTEXTO CONVERSACIONAL ACTIVADO
            context.conversation_stack = conversation_stack or []
            if context.conversation_stack:
                self.logger.info(f"üéØ [MASTER] Procesando con contexto - {len(context.conversation_stack)} niveles disponibles")
            else:
                self.logger.info("üéØ [MASTER] Procesando consulta individual")

            # PASO 1: DETECTAR INTENCI√ìN CON CONTEXTO
            intention = self._detect_intention_with_context(context.user_message, context.conversation_stack)

            # PASO 2: RESOLVER REFERENCIAS CONTEXTUALES SI ES NECESARIO
            if intention.requiere_contexto and context.conversation_stack:
                intention = self._resolve_contextual_references(intention, context.conversation_stack, context.user_message)

            # üéØ LOGS DE DEPURACI√ìN DE INTENCI√ìN CONSOLIDADA
            self.logger.info(f"üéØ [MASTER] INTENCI√ìN CONSOLIDADA DETECTADA:")
            self.logger.info(f"   ‚îú‚îÄ‚îÄ Tipo: {intention.intention_type}")
            self.logger.info(f"   ‚îú‚îÄ‚îÄ Sub-intenci√≥n: {intention.sub_intention}")
            self.logger.info(f"   ‚îú‚îÄ‚îÄ Confianza: {intention.confidence}")
            self.logger.info(f"   ‚îú‚îÄ‚îÄ üÜï Categor√≠a: {intention.categoria}")
            self.logger.info(f"   ‚îú‚îÄ‚îÄ üÜï Sub-tipo: {intention.sub_tipo}")
            self.logger.info(f"   ‚îú‚îÄ‚îÄ üÜï Complejidad: {intention.complejidad}")
            self.logger.info(f"   ‚îú‚îÄ‚îÄ üÜï Requiere contexto: {intention.requiere_contexto}")
            self.logger.info(f"   ‚îú‚îÄ‚îÄ üÜï Flujo √≥ptimo: {intention.flujo_optimo}")
            self.logger.info(f"   ‚îî‚îÄ‚îÄ Razonamiento: {intention.reasoning}")

            # PASO 3: VALIDAR INTENCI√ìN CON SISTEMA MAP
            validated_intention = self._validate_intention_with_system_map(intention)
            if validated_intention != intention:
                self.logger.info(f"üîß [MASTER] Intenci√≥n corregida por system_map")

            # üõë PAUSA ESTRAT√âGICA #1: MASTER RAZONAMIENTO INICIAL COMPLETO
            import os
            if os.environ.get('DEBUG_PAUSES', 'false').lower() == 'true':
                print(f"\nüõë [MASTER] AN√ÅLISIS INICIAL:")
                print(f"    ‚îú‚îÄ‚îÄ üìù Consulta: '{context.user_message}'")
                print(f"    ‚îú‚îÄ‚îÄ üß† Intenci√≥n detectada: {intention.intention_type}/{intention.sub_intention}")
                print(f"    ‚îú‚îÄ‚îÄ üìä Confianza: {intention.confidence}")
                print(f"    ‚îú‚îÄ‚îÄ üéØ Entidades extra√≠das: {list(intention.detected_entities.keys())}")
                for key, value in intention.detected_entities.items():
                    if isinstance(value, list) and len(value) > 2:
                        print(f"    ‚îÇ   ‚îú‚îÄ‚îÄ {key}: {value[:2]}... (+{len(value)-2} m√°s)")
                    else:
                        print(f"    ‚îÇ   ‚îú‚îÄ‚îÄ {key}: {value}")
                print(f"    ‚îú‚îÄ‚îÄ üí≠ Razonamiento: {intention.reasoning[:100]}...")
                print(f"    ‚îú‚îÄ‚îÄ üîç Confianza: {intention.confidence}")
                print(f"    ‚îî‚îÄ‚îÄ Presiona ENTER para delegar a Student...")
                input()

            # PASO 4: VERIFICAR SI NECESITA ACLARACI√ìN
            if validated_intention.intention_type == "aclaracion_requerida":
                return self._handle_ambiguous_query(context, validated_intention)

            # PASO 5: DIRIGIR AL ESPECIALISTA DIRECTAMENTE
            result = self._delegate_to_specialist_direct(context, validated_intention)

            # PASO 5: ANALIZAR RESULTADOS Y DECIDIR SI NECESITA COMUNICACI√ìN BIDIRECCIONAL
            if result and self._should_ask_user_about_results(result, context.user_message):
                return self._handle_results_analysis(context, validated_intention, result)

            # PASO 6: PROCESAR RETROALIMENTACI√ìN DEL ESPECIALISTA
            self._process_specialist_feedback(validated_intention, result)

            return result

        except Exception as e:
            self.logger.error(f"‚ùå [MASTER] Error en interpretaci√≥n: {e}")
            return None

    def _detect_intention_with_context(self, user_message: str, conversation_stack: list = None):
        """üéØ DETECTAR INTENCI√ìN CON CONTEXTO CONVERSACIONAL"""
        try:
            return self.intention_detector.detect_intention(user_message, conversation_stack)
        except Exception as e:
            self.logger.error(f"‚ùå Error detectando intenci√≥n: {e}")
            # Fallback b√°sico
            from app.core.ai.interpretation.intention_detector import IntentionResult
            return IntentionResult(
                intention_type="consulta_alumnos",
                sub_intention="busqueda_simple",
                confidence=0.5,
                reasoning="Fallback por error en detecci√≥n",
                detected_entities={}
            )

    def _resolve_contextual_references(self, intention, conversation_stack: list, user_query: str):
        """
        üéØ MASTER RESUELVE REFERENCIAS CONTEXTUALES COMPLETAMENTE
        Esta es la funcionalidad clave que faltaba
        """
        try:
            self.logger.info("üéØ [MASTER] RESOLVIENDO REFERENCIAS CONTEXTUALES...")

            detected_entities = intention.detected_entities.copy()
            contexto_especifico = detected_entities.get('contexto_especifico', '')

            # üéØ CASO 1: REFERENCIA POSICIONAL ("segundo", "tercero", etc.)
            if any(word in user_query.lower() for word in ['segundo', 'segunda', 'tercero', 'tercer', 'primero', 'primer', '√∫ltimo', '√∫ltima']):
                resolved_alumno = self._resolve_positional_reference(user_query, conversation_stack)
                if resolved_alumno:
                    detected_entities['alumno_resuelto'] = resolved_alumno
                    # Cambiar requiere_contexto a False porque ya lo resolvimos
                    intention.requiere_contexto = False
                    self.logger.info(f"‚úÖ [MASTER] REFERENCIA POSICIONAL RESUELTA: {resolved_alumno['nombre']} (ID: {resolved_alumno['id']})")

            # üéØ CASO 2: REFERENCIA PRONOMINAL ("√©l", "ella", "ese", "esa")
            elif any(word in user_query.lower() for word in ['√©l', 'ella', 'ese', 'esa', 'este', 'esta']):
                resolved_alumno = self._resolve_pronominal_reference(conversation_stack)
                if resolved_alumno:
                    detected_entities['alumno_resuelto'] = resolved_alumno
                    intention.requiere_contexto = False
                    self.logger.info(f"‚úÖ [MASTER] REFERENCIA PRONOMINAL RESUELTA: {resolved_alumno['nombre']} (ID: {resolved_alumno['id']})")

            # üéØ CASO 3: REFERENCIA POR NOMBRE PARCIAL ("mario", "juan", etc.)
            elif detected_entities.get('fuente_datos') == 'conversacion_previa':
                nombres_detectados = detected_entities.get('nombres', [])
                if nombres_detectados:
                    resolved_alumno = self._resolve_name_reference(nombres_detectados[0], conversation_stack)
                    if resolved_alumno:
                        detected_entities['alumno_resuelto'] = resolved_alumno
                        intention.requiere_contexto = False
                        self.logger.info(f"‚úÖ [MASTER] REFERENCIA POR NOMBRE RESUELTA: {resolved_alumno['nombre']} (ID: {resolved_alumno['id']})")

            # Actualizar las entidades detectadas
            intention.detected_entities = detected_entities

            return intention

        except Exception as e:
            self.logger.error(f"‚ùå Error resolviendo referencias contextuales: {e}")
            return intention

    def _resolve_positional_reference(self, user_query: str, conversation_stack: list) -> dict:
        """Resuelve referencias posicionales como 'segundo', 'tercero'"""
        try:
            if not conversation_stack:
                return None

            # Obtener datos del √∫ltimo nivel
            ultimo_nivel = conversation_stack[-1]
            data = ultimo_nivel.get('data', [])

            if not data:
                return None

            # Determinar posici√≥n
            position_index = None
            query_lower = user_query.lower()

            if 'primer' in query_lower or 'primero' in query_lower:
                position_index = 0
            elif 'segundo' in query_lower or 'segunda' in query_lower:
                position_index = 1
            elif 'tercer' in query_lower or 'tercero' in query_lower:
                position_index = 2
            elif 'cuarto' in query_lower or 'cuarta' in query_lower:
                position_index = 3
            elif 'quinto' in query_lower or 'quinta' in query_lower:
                position_index = 4
            elif '√∫ltimo' in query_lower or '√∫ltima' in query_lower:
                position_index = len(data) - 1

            if position_index is not None and position_index < len(data):
                alumno = data[position_index]
                return {
                    'id': alumno.get('id') or alumno.get('alumno_id'),
                    'nombre': alumno.get('nombre'),
                    'posicion': f"posici√≥n {position_index + 1}"
                }

            return None

        except Exception as e:
            self.logger.error(f"Error resolviendo referencia posicional: {e}")
            return None

    def _resolve_pronominal_reference(self, conversation_stack: list) -> dict:
        """Resuelve referencias pronominales como '√©l', 'ese'"""
        try:
            if not conversation_stack:
                return None

            # Buscar el √∫ltimo alumno mencionado espec√≠ficamente
            for nivel in reversed(conversation_stack):
                data = nivel.get('data', [])
                if data and len(data) == 1:  # Un solo alumno mencionado
                    alumno = data[0]
                    return {
                        'id': alumno.get('id') or alumno.get('alumno_id'),
                        'nombre': alumno.get('nombre'),
                        'posicion': '√∫ltimo mencionado'
                    }

            return None

        except Exception as e:
            self.logger.error(f"Error resolviendo referencia pronominal: {e}")
            return None

    def _resolve_name_reference(self, nombre_detectado: str, conversation_stack: list) -> dict:
        """Resuelve referencias por nombre parcial como 'mario' ‚Üí 'MARIO LOPEZ GONZALEZ'"""
        try:
            if not conversation_stack or not nombre_detectado:
                return None

            nombre_lower = nombre_detectado.lower()
            self.logger.info(f"üîç [MASTER] Buscando referencia por nombre: '{nombre_detectado}'")

            # Buscar en todos los niveles del contexto
            for nivel in reversed(conversation_stack):
                data = nivel.get('data', [])
                if not data:
                    continue

                # Buscar coincidencia por nombre parcial
                for alumno in data:
                    nombre_completo = alumno.get('nombre', '').lower()

                    # Verificar si el nombre detectado est√° contenido en el nombre completo
                    if nombre_lower in nombre_completo:
                        alumno_id = alumno.get('id') or alumno.get('alumno_id')
                        self.logger.info(f"‚úÖ [MASTER] COINCIDENCIA ENCONTRADA: '{nombre_detectado}' ‚Üí '{alumno.get('nombre')}' (ID: {alumno_id})")
                        return {
                            'id': alumno_id,
                            'nombre': alumno.get('nombre'),
                            'posicion': 'referencia por nombre'
                        }

            self.logger.warning(f"‚ùå [MASTER] No se encontr√≥ referencia para: '{nombre_detectado}'")
            return None

        except Exception as e:
            self.logger.error(f"Error resolviendo referencia por nombre: {e}")
            return None

    def _validate_intention_with_system_map(self, intention):
        """üéØ VALIDAR INTENCI√ìN CON SYSTEM MAP"""
        try:
            intention_type = intention.intention_type

            # Verificar si la intenci√≥n es manejada por alg√∫n especialista
            for specialist, config in self.system_map.items():
                if intention_type in config["handles"]:
                    self.logger.info(f"‚úÖ [MASTER] Intenci√≥n '{intention_type}' validada para {specialist}")
                    return intention

            # Si no se encuentra, log de advertencia pero continuar
            self.logger.warning(f"‚ö†Ô∏è [MASTER] Intenci√≥n '{intention_type}' no encontrada en system_map")
            return intention

        except Exception as e:
            self.logger.error(f"‚ùå Error validando intenci√≥n: {e}")
            return intention

    def _delegate_to_specialist_direct(self, context: InterpretationContext, intention):
        """üéØ DELEGAR AL ESPECIALISTA CON CONTEXTO COMPLETO"""
        try:


            # Agregar informaci√≥n de intenci√≥n consolidada al contexto
            context.intention_info = {
                'intention_type': intention.intention_type,
                'sub_intention': intention.sub_intention,
                'confidence': intention.confidence,
                'reasoning': intention.reasoning,
                'detected_entities': intention.detected_entities,
                # üÜï CATEGORIZACI√ìN ESPEC√çFICA CONSOLIDADA
                'categoria': intention.categoria,
                'sub_tipo': intention.sub_tipo,
                'complejidad': intention.complejidad,
                'requiere_contexto': intention.requiere_contexto,
                'flujo_optimo': intention.flujo_optimo
            }

            # üéØ DEBUG ESTRAT√âGICO: LO QUE MASTER ENV√çA A STUDENT (CONSOLIDADO)
            self.logger.info("=" * 60)
            self.logger.info("üéØ [DEBUG] MASTER ‚Üí STUDENT COMMUNICATION (CONSOLIDADO):")
            self.logger.info("=" * 60)
            self.logger.info(f"üì§ CONSULTA ORIGINAL: '{context.user_message}'")
            self.logger.info(f"üì§ INTENCI√ìN DETECTADA: {intention.intention_type}/{intention.sub_intention}")
            self.logger.info(f"üì§ CONFIANZA: {intention.confidence}")
            self.logger.info(f"üì§ üÜï CATEGOR√çA: {intention.categoria}")
            self.logger.info(f"üì§ üÜï SUB-TIPO: {intention.sub_tipo}")
            self.logger.info(f"üì§ üÜï COMPLEJIDAD: {intention.complejidad}")
            self.logger.info(f"üì§ üÜï FLUJO √ìPTIMO: {intention.flujo_optimo}")
            self.logger.info(f"üì§ ENTIDADES DETECTADAS: {len(intention.detected_entities)} elementos")
            for key, value in intention.detected_entities.items():
                self.logger.info(f"     ‚îú‚îÄ‚îÄ {key}: {value}")
            self.logger.info(f"üì§ RAZONAMIENTO MASTER: {intention.reasoning}")
            self.logger.info("=" * 60)

            # Dirigir seg√∫n la intenci√≥n
            if intention.intention_type == "consulta_alumnos":
                self.logger.info(f"üéØ [MASTER] Dirigiendo a StudentQueryInterpreter")
                self.logger.info(f"   ‚îú‚îÄ‚îÄ Sub-intenci√≥n: {intention.sub_intention}")
                self.logger.info(f"   ‚îî‚îÄ‚îÄ Entidades: {len(intention.detected_entities)} detectadas")



                result = self.student_interpreter.interpret(context)
                self.logger.info(f"üìä [MASTER] Resultado: {result.action if result else 'None'}")



                # üéØ MASTER COMO VOCERO: Generar respuesta final
                if result:
                    final_result = self._generate_master_response(result, context.user_message)
                    self.logger.info(f"üó£Ô∏è [MASTER] Respuesta final generada como vocero")
                    return final_result

                return result

            elif intention.intention_type == "generar_constancia":
                self.logger.info("üéØ [MASTER] Dirigiendo a StudentQueryInterpreter (constancia)")
                self.logger.info(f"   ‚îú‚îÄ‚îÄ Sub-intenci√≥n: {intention.sub_intention}")
                self.logger.info(f"   ‚îî‚îÄ‚îÄ Entidades: {len(intention.detected_entities)} detectadas")

                result = self.student_interpreter.interpret(context)
                self.logger.info(f"üìä [MASTER] Resultado: {result.action if result else 'None'}")

                # üéØ MASTER COMO VOCERO: Generar respuesta final
                if result:
                    final_result = self._generate_master_response(result, context.user_message)
                    self.logger.info(f"üó£Ô∏è [MASTER] Respuesta final generada como vocero")
                    return final_result

                return result

            elif intention.intention_type == "transformacion_pdf":
                self.logger.info("üéØ [MASTER] Dirigiendo a StudentQueryInterpreter (transformaci√≥n PDF)")
                self.logger.info(f"   ‚îú‚îÄ‚îÄ Sub-intenci√≥n: {intention.sub_intention}")
                self.logger.info(f"   ‚îî‚îÄ‚îÄ Entidades: {len(intention.detected_entities)} detectadas")

                result = self.student_interpreter.interpret(context)
                self.logger.info(f"üìä [MASTER] Resultado: {result.action if result else 'None'}")

                # üéØ MASTER COMO VOCERO: Generar respuesta final
                if result:
                    final_result = self._generate_master_response(result, context.user_message)
                    self.logger.info(f"üó£Ô∏è [MASTER] Respuesta final generada como vocero")
                    return final_result

                return result

            elif intention.intention_type == "ayuda_sistema":
                self.logger.info("üéØ [MASTER] Dirigiendo a HelpInterpreter")
                result = self.help_interpreter.interpret(context)
                self.logger.info(f"üìä [MASTER] Resultado: {result.action if result else 'None'}")

                # üéØ MASTER COMO VOCERO: Generar respuesta final
                if result:
                    final_result = self._generate_master_response(result, context.user_message)
                    self.logger.info(f"üó£Ô∏è [MASTER] Respuesta final generada como vocero")
                    return final_result

                return result

            else:
                # üßπ SIN FALLBACKS - Que falle claramente para debugging
                self.logger.error(f"‚ùå [MASTER] Intenci√≥n no reconocida: {intention.intention_type}")
                raise ValueError(f"Intenci√≥n no reconocida: {intention.intention_type}")

        except Exception as e:
            self.logger.error(f"‚ùå Error delegando al especialista: {e}")
            # üßπ SIN FALLBACKS - Que falle claramente para debugging
            raise

    def _process_specialist_feedback(self, intention, result):
        """üéØ PROCESAR RETROALIMENTACI√ìN DEL ESPECIALISTA"""
        try:
            if result:
                # Actualizar memoria de interacciones
                self.interaction_memory.update({
                    "last_specialist": self._get_specialist_for_intention(intention.intention_type),
                    "last_result_summary": f"Acci√≥n: {result.action}",
                    "conversation_flow": f"{intention.intention_type} ‚Üí {result.action}",
                    "specialist_feedback": "Completado exitosamente",
                    "awaiting_continuation": getattr(result, 'awaiting_continuation', False),
                    "continuation_type": getattr(result, 'continuation_type', None)
                })

                self.logger.info(f"üîÑ [MASTER] Memoria actualizada:")
                self.logger.info(f"   ‚îú‚îÄ‚îÄ Especialista: {self.interaction_memory['last_specialist']}")
                self.logger.info(f"   ‚îú‚îÄ‚îÄ Resultado: {self.interaction_memory['last_result_summary']}")
                self.logger.info(f"   ‚îî‚îÄ‚îÄ Flujo: {self.interaction_memory['conversation_flow']}")
            else:
                self.logger.warning(f"‚ö†Ô∏è [MASTER] No se recibi√≥ resultado del especialista")

        except Exception as e:
            self.logger.error(f"‚ùå Error procesando retroalimentaci√≥n: {e}")

    # üóëÔ∏è M√âTODOS DE AMBIG√úEDAD ELIMINADOS - SIMPLIFICACI√ìN ARQUITECTURAL
    # Ya no necesitamos verificar ambig√ºedades por separado
    # El IntentionDetector maneja todo el an√°lisis

    def _handle_ambiguous_query(self, context: InterpretationContext, intention) -> Optional[InterpretationResult]:
        """
        ü§î MANEJA CONSULTAS AMBIGUAS - PIDE ACLARACI√ìN AL USUARIO DE FORMA SIMPLE
        """
        try:
            self.logger.info("ü§î [MASTER] Consulta ambigua detectada - pidiendo aclaraci√≥n simple")

            # Crear respuesta de aclaraci√≥n simple
            from app.core.ai.interpretation.base_interpreter import InterpretationResult

            human_response = f"ü§î Tu consulta '{context.user_message}' no es lo suficientemente clara para m√≠. ¬øPodr√≠as ser m√°s espec√≠fico sobre qu√© informaci√≥n necesitas?"

            return InterpretationResult(
                action="aclaracion_requerida",
                parameters={
                    "message": human_response,
                    "original_query": context.user_message,
                    "human_response": human_response
                },
                confidence=intention.confidence
            )

        except Exception as e:
            self.logger.error(f"‚ùå Error manejando consulta ambigua: {e}")
            return None



    def _get_specialist_for_intention(self, intention_type: str) -> str:
        """üéØ OBTENER ESPECIALISTA PARA INTENCI√ìN"""
        for specialist, config in self.system_map.items():
            if intention_type in config["handles"]:
                return specialist
        return "Unknown"

    # üóëÔ∏è M√âTODO ELIMINADO: _create_ambiguity_analysis_prompt
    # Ya no necesitamos an√°lisis de ambig√ºedad por separado

    # üóëÔ∏è M√âTODOS ELIMINADOS: _parse_ambiguity_response, _generate_clarification_question
    # Ya no necesitamos an√°lisis de ambig√ºedad por separado

    def _should_ask_user_about_results(self, result: 'InterpretationResult', user_query: str) -> bool:
        """
        üß† MASTER ANALIZA RESULTADOS: ¬øDeber√≠a preguntar al usuario?
        Decide si los resultados del Student requieren aclaraci√≥n del usuario
        """
        try:
            if not result or not result.parameters:
                return False

            row_count = result.parameters.get('row_count', 0)
            action = result.action

            # üö® CASOS DONDE EL MASTER DEBER√çA PREGUNTAR:

            # 1. Constancias con m√∫ltiples candidatos
            if 'constancia' in user_query.lower() and row_count > 1:
                self.logger.info(f"üîÑ [MASTER] Constancia con {row_count} candidatos - necesita selecci√≥n")
                return True

            # 2. B√∫squedas muy amplias (m√°s de 50 resultados)
            if 'buscar' in user_query.lower() and row_count > 50:
                self.logger.info(f"üîÑ [MASTER] B√∫squeda muy amplia ({row_count} resultados) - ofrecer filtros")
                return True

            # 3. Sin resultados - ofrecer ayuda
            if row_count == 0:
                self.logger.info(f"üîÑ [MASTER] Sin resultados - ofrecer alternativas")
                return True

            # Para b√∫squedas normales como "buscar garcia" con 21 resultados: NO preguntar
            self.logger.info(f"üîÑ [MASTER] Resultados normales ({row_count}) - mostrar directamente")
            return False

        except Exception as e:
            self.logger.error(f"Error analizando si preguntar al usuario: {e}")
            return False

    def _handle_results_analysis(self, context, intention, result: 'InterpretationResult') -> 'InterpretationResult':
        """
        üß† MASTER MANEJA AN√ÅLISIS DE RESULTADOS
        Procesa los resultados del Student y decide qu√© preguntar al usuario
        """
        try:
            self.logger.info("üîÑ [MASTER] Analizando resultados para comunicaci√≥n")

            row_count = result.parameters.get('row_count', 0)
            user_query = context.user_message

            # Determinar tipo de pregunta basado en los resultados
            if 'constancia' in user_query.lower() and row_count > 1:
                return self._create_candidate_selection_question(result, context)
            elif 'buscar' in user_query.lower() and row_count > 50:
                return self._create_filter_suggestion_question(result, context)
            elif row_count == 0:
                return self._create_no_results_help_question(result, context)
            else:
                # No deber√≠a llegar aqu√≠, pero por seguridad
                return result

        except Exception as e:
            self.logger.error(f"Error analizando resultados: {e}")
            return result

    def _create_candidate_selection_question(self, result: 'InterpretationResult', context) -> 'InterpretationResult':
        """Crea pregunta para seleccionar candidato para constancia"""
        try:
            data = result.parameters.get('data', [])
            candidates = []

            for item in data[:5]:  # M√°ximo 5 candidatos
                candidates.append({
                    'nombre': item.get('nombre', 'N/A'),
                    'grado': f"{item.get('grado', 'N/A')}¬∞{item.get('grupo', '')}"
                })

            message = f"üîç Encontr√© {len(data)} candidatos para la constancia. ¬øCu√°l necesitas?\n\n"
            for i, candidate in enumerate(candidates, 1):
                message += f"**{i}.** {candidate['nombre']} ({candidate['grado']})\n"

            message += f"\nüí° Responde con el n√∫mero de la opci√≥n que necesitas."

            return InterpretationResult(
                action="solicitar_seleccion_constancia",
                parameters={
                    "message": message,
                    "candidates": candidates,
                    "original_query": context.user_message,
                    "waiting_for": "selection",
                    "original_data": data
                },
                confidence=0.9
            )

        except Exception as e:
            self.logger.error(f"Error creando pregunta de selecci√≥n: {e}")
            return result

    def _create_filter_suggestion_question(self, result: 'InterpretationResult', context) -> 'InterpretationResult':
        """Crea pregunta para sugerir filtros en b√∫squedas amplias"""
        try:
            row_count = result.parameters.get('row_count', 0)

            message = f"üîç Encontr√© {row_count} resultados. ¬øBuscabas a todos o necesitas filtrar por algo espec√≠fico como grado, grupo o turno?"

            return InterpretationResult(
                action="solicitar_filtros",
                parameters={
                    "message": message,
                    "original_query": context.user_message,
                    "result_count": row_count,
                    "waiting_for": "filter_specification",
                    "original_data": result.parameters.get('data', [])
                },
                confidence=0.9
            )

        except Exception as e:
            self.logger.error(f"Error creando pregunta de filtros: {e}")
            return result

    def _create_no_results_help_question(self, result: 'InterpretationResult', context) -> 'InterpretationResult':
        """Crea pregunta de ayuda cuando no hay resultados"""
        try:
            message = f"ü§î No encontr√© resultados para '{context.user_message}'. ¬øQuieres que busque con otros criterios o necesitas ayuda?"

            return InterpretationResult(
                action="solicitar_ayuda_busqueda",
                parameters={
                    "message": message,
                    "original_query": context.user_message,
                    "waiting_for": "search_help"
                },
                confidence=0.8
            )

        except Exception as e:
            self.logger.error(f"Error creando pregunta de ayuda: {e}")
            return result

    # üóëÔ∏è M√âTODOS OBSOLETOS ELIMINADOS: COMUNICACI√ìN BIDIRECCIONAL LEGACY
    # RAZ√ìN: Student ya no env√≠a feedback bidireccional - Master analiza resultados directamente
    #
    # M√©todos eliminados:
    # - _needs_bidirectional_communication() ‚Üí Reemplazado por _should_ask_user_about_results()
    # - _handle_student_feedback() ‚Üí Ya no es necesario, Student no env√≠a feedback
    # - _handle_multiple_results_feedback() ‚Üí Integrado en _handle_results_analysis()
    # - _handle_multiple_candidates_feedback() ‚Üí Integrado en _create_candidate_selection_question()
    # - _handle_ambiguity_feedback() ‚Üí Manejado en an√°lisis previo
    # - _handle_validation_feedback() ‚Üí Integrado en _handle_results_analysis()
    # - _handle_generic_feedback() ‚Üí Ya no es necesario

    # üóëÔ∏è M√âTODOS OBSOLETOS ELIMINADOS: FEEDBACK HANDLERS LEGACY
    # RAZ√ìN: Student ya no env√≠a feedback bidireccional - Master analiza resultados directamente
    #
    # M√©todos eliminados:
    # - _handle_multiple_results_feedback() ‚Üí Integrado en _create_filter_suggestion_question()
    # - _handle_multiple_candidates_feedback() ‚Üí Integrado en _create_candidate_selection_question()
    # - _handle_ambiguity_feedback() ‚Üí Manejado en an√°lisis previo con _check_for_ambiguities()
    # - _handle_validation_feedback() ‚Üí Integrado en _create_no_results_help_question()
    # - _handle_generic_feedback() ‚Üí Ya no es necesario

    def _log_detailed_strategic_context(self):
        """üîç MOSTRAR CONTEXTO ESTRAT√âGICO COMPLETO EN LOGS"""
        try:
            self.logger.info("=" * 80)
            self.logger.info("üîç [MASTER] CONTEXTO ESTRAT√âGICO DETALLADO:")
            self.logger.info("=" * 80)

            # 1. SYSTEM MAP COMPLETO
            self.logger.info("üìã 1. SYSTEM MAP (Especialistas y Capacidades):")
            for specialist, config in self.system_map.items():
                self.logger.info(f"   üéØ {specialist}:")
                self.logger.info(f"      ‚îú‚îÄ‚îÄ Rol: {config.get('description', 'No definido')}")
                self.logger.info(f"      ‚îú‚îÄ‚îÄ Maneja: {config.get('handles', [])}")
                self.logger.info(f"      ‚îú‚îÄ‚îÄ Sub-intenciones: {config.get('sub_intentions', [])}")
                self.logger.info(f"      ‚îî‚îÄ‚îÄ Capacidades: {config.get('capabilities', 'No definidas')}")

            # 2. MEMORIA DE INTERACCIONES
            self.logger.info("")
            self.logger.info("üí≠ 2. MEMORIA DE INTERACCIONES:")
            for key, value in self.interaction_memory.items():
                self.logger.info(f"      ‚îú‚îÄ‚îÄ {key}: {value}")

            # 3. CONTEXTO DEL SISTEMA ESCOLAR
            sistema_context = {
                "tipo": "Direcci√≥n de Escuela Primaria PROF. MAXIMO GAMIZ FERNANDEZ",
                "estudiantes_total": 211,
                "areas_disponibles": ["Consultas de Alumnos", "Ayuda T√©cnica"]
            }
            self.logger.info("")
            self.logger.info("üè´ 3. CONTEXTO DEL SISTEMA ESCOLAR:")
            for key, value in sistema_context.items():
                self.logger.info(f"      ‚îú‚îÄ‚îÄ {key}: {value}")

            # 4. TIPOS DE CONSULTAS ESPERADAS
            tipos_consultas = {
                "busquedas": "buscar Garc√≠a, alumnos de 2do A, estudiantes matutinos",
                "estadisticas": "cu√°ntos alumnos hay, promedio general, distribuciones",
                "documentos": "constancia para Juan, certificado de calificaciones",
                "transformaciones": "convertir constancia, cambiar formato",
                "ayuda": "qu√© puedes hacer, c√≥mo buscar alumnos"
            }
            self.logger.info("")
            self.logger.info("üìù 4. TIPOS DE CONSULTAS ESPERADAS:")
            for tipo, ejemplos in tipos_consultas.items():
                self.logger.info(f"      ‚îú‚îÄ‚îÄ {tipo}: {ejemplos}")

            # 5. ESTADO DE INICIALIZACI√ìN (COMPONENTES B√ÅSICOS)
            self.logger.info("")
            self.logger.info("‚úÖ 5. ESTADO DE INICIALIZACI√ìN:")
            self.logger.info(f"      ‚îú‚îÄ‚îÄ Gemini Client: {'‚úÖ Conectado' if self.gemini_client else '‚ùå No disponible'}")
            self.logger.info(f"      ‚îú‚îÄ‚îÄ Intention Detector: {'‚úÖ Inicializado' if self.intention_detector else '‚ùå No disponible'}")
            self.logger.info(f"      ‚îú‚îÄ‚îÄ Student Interpreter: ‚è≥ Se inicializar√° despu√©s")
            self.logger.info(f"      ‚îî‚îÄ‚îÄ Help Interpreter: ‚è≥ Se inicializar√° despu√©s")

            self.logger.info("=" * 80)
            self.logger.info("üéØ [MASTER] CONTEXTO ESTRAT√âGICO CARGADO Y VERIFICADO")
            self.logger.info("=" * 80)

        except Exception as e:
            self.logger.error(f"‚ùå Error mostrando contexto detallado: {e}")

    def _handle_expected_response(self, context: InterpretationContext, conversation_state: dict) -> Optional[InterpretationResult]:
        """
        Maneja respuestas esperadas basadas en el estado conversacional
        Versi√≥n simplificada que usa el Context Manager
        """
        waiting_for = conversation_state.get('waiting_for')
        user_message = context.user_message.lower().strip()

        # üÜï DETECTAR CONFIRMACIONES DESDE CONFIGURACI√ìN CENTRALIZADA
        confirmations = Config.RESPONSES['confirmation_words']

        if waiting_for == "confirmacion_constancia_estudios" and user_message in confirmations:
            return self._handle_confirmation(context, conversation_state)

        # Aqu√≠ se pueden agregar otros tipos de respuestas esperadas
        # elif waiting_for == "seleccion_alumno":
        #     return self._handle_selection(context, conversation_state)

        return None

    def _generate_master_response(self, student_result: 'InterpretationResult', user_query: str) -> 'InterpretationResult':
        """
        üéØ MASTER COMO VOCERO: Genera respuesta final basada en reporte del Student

        Args:
            student_result: Resultado t√©cnico del Student
            user_query: Consulta original del usuario

        Returns:
            InterpretationResult con respuesta final del Master
        """
        try:
            self.logger.info("üó£Ô∏è [MASTER] Generando respuesta final como vocero...")

            # Extraer datos t√©cnicos del Student
            student_data = student_result.parameters
            action_used = student_result.action

            # üéØ EXTRAER CRITERIOS DE B√öSQUEDA DIN√ÅMICAMENTE DESPU√âS DE LA EJECUCI√ìN
            search_criteria = self._extract_search_criteria_for_display(student_data)

            # üéØ AGREGAR CRITERIOS A STUDENT_DATA PARA LAS FUNCIONES DE RESPUESTA
            student_data["search_criteria"] = search_criteria

            # üéØ MASTER GENERA RESPUESTA FINAL USANDO PROMPT ESPECIALIZADO
            master_response = self._generate_master_response_with_llm(student_data, user_query, action_used)

            # üîß CASOS ESPECIALES QUE REQUIEREN PROCESAMIENTO ADICIONAL
            if action_used == "seleccion_realizada":
                # Respuesta de selecci√≥n - mostrar datos del elemento seleccionado
                elemento_seleccionado = student_data.get("elemento_seleccionado")
                posicion = student_data.get("posicion", "N/A")

                if elemento_seleccionado:
                    # Preparar datos para mostrar en la interfaz
                    nombre = elemento_seleccionado.get('nombre', 'N/A')
                    master_response = f"üë§ Informaci√≥n del alumno en posici√≥n {posicion}: **{nombre}**"

                    # Agregar los datos del elemento seleccionado para que se muestren en la interfaz
                    student_data["data"] = [elemento_seleccionado]
                    student_data["row_count"] = 1
                    student_data["human_response"] = master_response
                else:
                    master_response = student_data.get("message", "Selecci√≥n procesada exitosamente")

            elif action_used == "transformation_preview":
                # üîÑ RESPUESTA ESPEC√çFICA PARA TRANSFORMACIONES (mantener por ahora)
                transformation_info = student_data.get("transformation_info", {})
                if transformation_info:
                    tipo_constancia = (transformation_info.get("tipo_constancia") or
                                     transformation_info.get("tipo_transformacion") or
                                     student_data.get("tipo_constancia", "constancia"))
                    alumno_info = (transformation_info.get("alumno") or
                                 student_data.get("alumno", {}))
                    alumno_nombre = alumno_info.get("nombre", "el alumno")

                    master_response = (f"‚úÖ **Transformaci√≥n completada exitosamente**\n\n"
                                     f"He convertido tu PDF a una constancia de **{tipo_constancia}** para **{alumno_nombre}**.\n\n"
                                     f"üìÑ **En el panel derecho puedes:**\n\n"
                                     f"Ver la vista previa, comparar con el original, revisar datos extra√≠dos y abrir en navegador para imprimir.\n\n"
                                     f"üí° ¬øNecesitas hacer alg√∫n ajuste o tienes otra consulta?")

            # üéØ CREAR RESULTADO FINAL CON RESPUESTA DEL MASTER
            final_result = InterpretationResult(
                action=student_result.action,
                parameters={
                    **student_data,  # Mantener datos t√©cnicos del Student
                    "human_response": master_response,  # Respuesta final del Master
                    "master_generated": True,  # Flag para indicar que Master gener√≥ la respuesta
                    "student_action": action_used,  # Acci√≥n original del Student
                    "search_criteria": search_criteria,  # üÜï Criterios para mostrar en listado
                },
                confidence=student_result.confidence
            )

            self.logger.info(f"‚úÖ [MASTER] Respuesta final: '{master_response[:50]}...'")
            return final_result

        except Exception as e:
            self.logger.error(f"‚ùå [MASTER] Error generando respuesta final: {e}")
            # Fallback: retornar resultado original del Student
            return student_result

    def _extract_search_criteria_for_display(self, student_data: dict) -> dict:
        """üéØ EXTRAE CRITERIOS DE B√öSQUEDA DIN√ÅMICAMENTE DEL SQL EJECUTADO"""
        try:
            # üîç DEBUG: Ver qu√© datos llegan
            self.logger.info(f"üîç [DEBUG] student_data keys: {list(student_data.keys())}")

            # üöÄ ENFOQUE DIN√ÅMICO: Analizar el SQL real que se ejecut√≥
            sql_query = student_data.get("sql_executed", "") or student_data.get("sql_query", "")
            search_description = ""
            relevant_fields = []

            self.logger.info(f"üîç [DEBUG] sql_query encontrado: '{sql_query}'")
            self.logger.info(f"üîç [DEBUG] ¬øsql_executed existe? {'sql_executed' in student_data}")
            self.logger.info(f"üîç [DEBUG] ¬øsql_query existe? {'sql_query' in student_data}")

            if sql_query:
                # Extraer campos de WHERE clause din√°micamente
                import re

                # üéØ PATRONES COMPLETOS PARA TODOS LOS CRITERIOS POSIBLES
                where_patterns = [
                    # üìÖ FECHAS
                    (r'fecha_nacimiento\s+LIKE\s+[\'"]%(\d{4})%[\'"]', 'fecha_nacimiento', 'nacidos en {}'),
                    (r'fecha_nacimiento\s+BETWEEN\s+[\'"](\d{4}-\d{2}-\d{2})[\'"].*[\'"](\d{4}-\d{2}-\d{2})[\'"]', 'fecha_nacimiento', 'nacidos entre {} y {}'),
                    (r'fecha_nacimiento\s*=\s*[\'"]([^\'\"]+)[\'"]', 'fecha_nacimiento', 'nacidos el {}'),

                    # üéì DATOS ESCOLARES
                    (r'grado\s*=\s*[\'"](\w+)[\'"]', 'grado', '{}¬∞ grado'),
                    (r'grupo\s*=\s*[\'"](\w+)[\'"]', 'grupo', 'grupo {}'),
                    (r'turno\s*=\s*[\'"](\w+)[\'"]', 'turno', 'turno {}'),

                    # üë§ IDENTIFICADORES
                    (r'matricula\s*=\s*[\'"]([^\'\"]+)[\'"]', 'matricula', 'matr√≠cula {}'),
                    (r'curp\s*=\s*[\'"]([^\'\"]+)[\'"]', 'curp', 'CURP {}'),
                    (r'nombre\s+LIKE\s+[\'"]%([^%\'\"]+)%[\'"]', 'nombre', 'con nombre que contiene "{}"'),
                    (r'nombre\s*=\s*[\'"]([^\'\"]+)[\'"]', 'nombre', 'llamado {}'),

                    # üìä CALIFICACIONES
                    (r'calificaciones\s+IS\s+NOT\s+NULL', 'calificaciones_status', 'con calificaciones'),
                    (r'calificaciones\s+IS\s+NULL', 'calificaciones_status', 'sin calificaciones'),
                    (r'JSON_EXTRACT\([^,]+,\s*[\'"][^\'\"]*promedio[^\'\"]*[\'\"]\)\s*>\s*(\d+(?:\.\d+)?)', 'promedio', 'con promedio mayor a {}'),
                    (r'JSON_EXTRACT\([^,]+,\s*[\'"][^\'\"]*promedio[^\'\"]*[\'\"]\)\s*<\s*(\d+(?:\.\d+)?)', 'promedio', 'con promedio menor a {}'),
                    (r'JSON_EXTRACT\([^,]+,\s*[\'"][^\'\"]*promedio[^\'\"]*[\'\"]\)\s*=\s*(\d+(?:\.\d+)?)', 'promedio', 'con promedio de {}'),

                    # üè† DATOS PERSONALES
                    (r'telefono\s*=\s*[\'"]([^\'\"]+)[\'"]', 'telefono', 'con tel√©fono {}'),
                    (r'direccion\s+LIKE\s+[\'"]%([^%\'\"]+)%[\'"]', 'direccion', 'que viven en {}'),
                    (r'email\s*=\s*[\'"]([^\'\"]+)[\'"]', 'email', 'con email {}'),

                    # üî¢ RANGOS NUM√âRICOS
                    (r'edad\s*>\s*(\d+)', 'edad', 'mayores de {} a√±os'),
                    (r'edad\s*<\s*(\d+)', 'edad', 'menores de {} a√±os'),
                    (r'edad\s*=\s*(\d+)', 'edad', 'de {} a√±os'),
                ]

                for pattern, field, description_template in where_patterns:
                    matches = re.findall(pattern, sql_query, re.IGNORECASE)
                    if matches:
                        relevant_fields.append(field)
                        if isinstance(matches[0], tuple):
                            # M√∫ltiples grupos (ej: BETWEEN)
                            search_description += description_template.format(*matches[0]) + " "
                        else:
                            # Un solo grupo
                            search_description += description_template.format(matches[0]) + " "

                self.logger.info(f"üîç [DYNAMIC] SQL analizado: {sql_query[:100]}...")
                self.logger.info(f"üîç [DYNAMIC] Campos extra√≠dos: {relevant_fields}")
                self.logger.info(f"üîç [DYNAMIC] Descripci√≥n: {search_description.strip()}")

            # Si no hay SQL o no se encontraron patrones, usar fallback inteligente
            if not relevant_fields:
                # Analizar par√°metros de la acci√≥n como fallback
                action_params = student_data.get("action_params", {})
                criterio_principal = action_params.get("criterio_principal", {})
                campo = criterio_principal.get("campo", "")

                if campo:
                    relevant_fields.append(campo)
                    search_description = f"b√∫squeda por {campo}"
                    self.logger.info(f"üîç [FALLBACK] Campo del criterio principal: {campo}")

            # Siempre incluir campos b√°sicos
            basic_fields = ['nombre', 'curp']
            all_fields = basic_fields + [field for field in relevant_fields if field not in basic_fields]

            return {
                "fields_to_show": all_fields,
                "search_description": search_description.strip(),
                "has_specific_criteria": len(relevant_fields) > 0
            }

        except Exception as e:
            self.logger.error(f"Error extrayendo criterios din√°micamente: {e}")
            return {
                "fields_to_show": ['nombre', 'curp', 'turno'],  # Fallback por defecto
                "search_description": "",
                "has_specific_criteria": False
            }

    # üóëÔ∏è M√âTODO ELIMINADO: _generate_count_response
    # RAZ√ìN: Ahora el Student genera respuestas din√°micas directamente con el prompt mejorado

    # üóëÔ∏è M√âTODO ELIMINADO: _generate_count_response_from_filters
    # RAZ√ìN: Ahora el Student genera respuestas din√°micas directamente con el prompt mejorado

    # üóëÔ∏è M√âTODO ELIMINADO: _generate_search_response
    # RAZ√ìN: Ahora el Student genera respuestas din√°micas directamente con el prompt mejorado



    def _generate_master_response_with_llm(self, student_data: dict, user_query: str, action_used: str) -> str:
        """
        üéØ GENERA RESPUESTA FINAL USANDO LLM ESPECIALIZADO DEL MASTER

        El Master usa su propio prompt especializado en comunicaci√≥n para generar
        respuestas humanizadas bas√°ndose en los datos t√©cnicos del Student.
        """
        try:
            # Crear prompt especializado para respuesta del Master
            master_prompt = self._create_master_response_prompt(student_data, user_query, action_used)

            # Llamar al LLM para generar respuesta humanizada
            response = self.gemini_client.send_prompt_sync(master_prompt)

            if response and response.strip():
                self.logger.info(f"‚úÖ Master gener√≥ respuesta humanizada exitosamente")
                return response.strip()
            else:
                self.logger.warning(f"‚ùå Master LLM no gener√≥ respuesta, usando fallback")
                return self._generate_fallback_response(student_data, action_used)

        except Exception as e:
            self.logger.error(f"Error generando respuesta con Master LLM: {e}")
            return self._generate_fallback_response(student_data, action_used)

    def _generate_fallback_response(self, student_data: dict, action_used: str) -> str:
        """Genera respuesta de fallback si el LLM del Master falla"""
        row_count = student_data.get("row_count", 0)

        if action_used in ["BUSCAR_UNIVERSAL", "GENERAR_LISTADO_COMPLETO"]:
            if row_count == 0:
                return "No encontr√© resultados para tu b√∫squeda. ¬øPodr√≠as intentar con otros criterios?"
            elif row_count == 1:
                return "Encontr√© un resultado que coincide con tu b√∫squeda."
            else:
                return f"Encontr√© {row_count} resultados que coinciden con tu b√∫squeda."
        elif action_used in ["CONTAR_ALUMNOS", "CONTAR_UNIVERSAL"]:
            # Extraer el valor real del conteo desde los datos
            data = student_data.get("data", [])
            if data and isinstance(data, list) and len(data) > 0 and isinstance(data[0], dict):
                total_count = data[0].get("total", row_count)
                return f"El conteo se complet√≥ exitosamente: {total_count} elementos."
            else:
                return f"El conteo se complet√≥ exitosamente: {row_count} elementos."
        else:
            return "Consulta procesada exitosamente."

    def _create_master_response_prompt(self, student_data: dict, user_query: str, action_used: str) -> str:
        """
        üéØ CREA PROMPT ESPECIALIZADO DIN√ÅMICO SEG√öN TIPO DE CONSULTA

        Diferentes tipos de consulta requieren diferentes enfoques de respuesta.
        """
        # Detectar tipo de consulta
        query_type = self._detect_query_type(action_used, student_data, user_query)

        # Crear prompt espec√≠fico seg√∫n el tipo
        if query_type == "search":
            return self._create_search_response_prompt(student_data, user_query, action_used)
        elif query_type == "constancia":
            return self._create_constancia_response_prompt(student_data, user_query, action_used)
        elif query_type == "transformation":
            return self._create_transformation_response_prompt(student_data, user_query, action_used)
        elif query_type == "statistics":
            return self._create_statistics_response_prompt(student_data, user_query, action_used)
        elif query_type == "help":
            return self._create_help_response_prompt(student_data, user_query, action_used)
        else:
            return self._create_generic_response_prompt(student_data, user_query, action_used)

    def _detect_query_type(self, action_used: str, student_data: dict, user_query: str) -> str:
        """Detecta el tipo espec√≠fico de consulta para usar el prompt correcto"""
        # üéØ AYUDA DEL SISTEMA (SIMPLIFICADO A 2 ACCIONES)
        if action_used in ["AYUDA_CAPACIDADES", "AYUDA_TUTORIAL"] or student_data.get("query_category") == "ayuda_sistema":
            return "help"

        # Constancias
        if action_used in ["constancia_generada", "PREPARAR_DATOS_CONSTANCIA"] or "constancia" in user_query.lower():
            return "constancia"

        # Transformaciones
        if action_used in ["transformation_completed", "transformation_preview"] or "transform" in user_query.lower():
            return "transformation"

        # Estad√≠sticas
        if action_used in ["CONTAR_ALUMNOS", "CONTAR_UNIVERSAL", "CALCULAR_ESTADISTICA"] or any(word in user_query.lower() for word in ["cu√°ntos", "total", "estad√≠stica", "conteo"]):
            return "statistics"

        # B√∫squedas (por defecto)
        return "search"

    def _create_search_response_prompt(self, student_data: dict, user_query: str, action_used: str) -> str:
        """Prompt especializado para b√∫squedas y listados"""
        row_count = student_data.get("row_count", 0)
        data = student_data.get("data", [])
        ambiguity_level = student_data.get("ambiguity_level", "low")

        # üîß MANEJO SEGURO DE DATOS - verificar que data sea una lista
        data_context = ""
        if data and isinstance(data, list) and len(data) > 0:
            if len(data) <= 3:
                data_context = "RESULTADOS ENCONTRADOS:\n"
                for i, item in enumerate(data, 1):
                    if isinstance(item, dict):
                        # üéØ MANEJO DIN√ÅMICO DE CAMPOS - usar los campos que realmente existen
                        item_info = []
                        if "nombre" in item:
                            item_info.append(item["nombre"])
                        if "matricula" in item:
                            item_info.append(f"Matr√≠cula: {item['matricula']}")
                        if "grado" in item and "grupo" in item:
                            item_info.append(f"{item['grado']}¬∞ {item['grupo']}")
                        elif "grado" in item:
                            item_info.append(f"Grado: {item['grado']}")
                        elif "grupo" in item:
                            item_info.append(f"Grupo: {item['grupo']}")
                        if "curp" in item:
                            item_info.append(f"CURP: {item['curp']}")

                        # Si no hay campos reconocidos, mostrar todos los disponibles
                        if not item_info:
                            item_info = [f"{k}: {v}" for k, v in item.items() if v is not None]

                        data_context += f"{i}. {' - '.join(item_info)}\n"
            else:
                data_context = f"PRIMEROS 3 DE {len(data)} RESULTADOS:\n"
                for i in range(min(3, len(data))):
                    item = data[i]
                    if isinstance(item, dict):
                        # üéØ MANEJO DIN√ÅMICO DE CAMPOS - usar los campos que realmente existen
                        item_info = []
                        if "nombre" in item:
                            item_info.append(item["nombre"])
                        if "matricula" in item:
                            item_info.append(f"Matr√≠cula: {item['matricula']}")
                        if "grado" in item and "grupo" in item:
                            item_info.append(f"{item['grado']}¬∞ {item['grupo']}")
                        elif "grado" in item:
                            item_info.append(f"Grado: {item['grado']}")
                        elif "grupo" in item:
                            item_info.append(f"Grupo: {item['grupo']}")
                        if "curp" in item:
                            item_info.append(f"CURP: {item['curp']}")

                        # Si no hay campos reconocidos, mostrar todos los disponibles
                        if not item_info:
                            item_info = [f"{k}: {v}" for k, v in item.items() if v is not None]

                        data_context += f"{i+1}. {' - '.join(item_info)}\n"

        # Detectar si hay contexto conversacional previo
        reflexion = student_data.get("auto_reflexion", {})
        datos_recordar = reflexion.get("datos_recordar", {})
        conversation_context = datos_recordar.get("context", "")
        query_anterior = datos_recordar.get("query", "")

        # üéØ MEJORAR DETECCI√ìN DE CONTINUACI√ìN
        # Verificar m√∫ltiples fuentes para detectar continuaci√≥n
        master_intention = student_data.get("master_intention", {})
        categoria_master = master_intention.get("categoria", "")

        # Es continuaci√≥n si:
        # 1. Hay contexto conversacional previo, O
        # 2. El Master categoriz√≥ como "continuacion", O
        # 3. La consulta tiene palabras de referencia contextual
        palabras_continuacion = ["ellos", "esos", "esas", "de ellos", "de esas", "ahora", "tambi√©n"]
        tiene_referencia = any(palabra in user_query.lower() for palabra in palabras_continuacion)

        es_continuacion = bool(
            conversation_context or
            query_anterior or
            categoria_master == "continuacion" or
            tiene_referencia
        )

        return f"""
Eres el asistente amigable y entusiasta de la escuela "PROF. MAXIMO GAMIZ FERNANDEZ" üè´

üéØ SITUACI√ìN:
- CONSULTA: "{user_query}"
- RESULTADOS: {row_count} estudiantes encontrados
- AMBIG√úEDAD: {ambiguity_level}
- ES CONTINUACI√ìN: {es_continuacion}
- CONTEXTO PREVIO: {conversation_context}
- CONSULTA ANTERIOR: {query_anterior}

{data_context}

üé≠ TU PERSONALIDAD:
- Entusiasta y humano (usa emojis apropiados)
- Profesional pero cercano
- Emp√°tico y comprensivo
- Proactivo en sugerencias

üéØ TU TAREA PARA B√öSQUEDAS:
Generar una respuesta HUMANA y CONECTADA que:

1. üéâ SALUDA con entusiasmo apropiado
2. üìä PRESENTA los resultados de manera atractiva
3. üîç EXPLICA qu√© buscaste de forma natural
4. ü§î MANEJA la ambig√ºedad con empat√≠a
5. üí° SUGIERE pr√≥ximos pasos √∫tiles
6. üîÑ CONECTA con el contexto conversacional si existe

üéØ MANEJO DE AMBIG√úEDAD CON EMPAT√çA:
- HIGH (10+ resultados): "¬°Encontr√© muchos estudiantes! üòä Como [apellido] es com√∫n, te muestro todos para que encuentres al que necesitas. ¬øPodr√≠as ser m√°s espec√≠fico con el nombre o grado?"
- MEDIUM (4-9 resultados): "¬°Perfecto! üëç Encontr√© varios estudiantes que coinciden. ¬øNecesitas informaci√≥n espec√≠fica de alguno?"
- LOW (1-3 resultados): "¬°Excelente! ‚úÖ Aqu√≠ tienes [lo que encontr√©]..."

üîÑ CONTINUIDAD CONVERSACIONAL (MUY IMPORTANTE):
- Si ES_CONTINUACI√ìN = True: NUNCA digas "¬°Hola!" - usa "¬°Perfecto! üëç", "¬°Excelente! ‚úÖ", "Siguiendo con tu b√∫squeda anterior..."
- Si ES_CONTINUACI√ìN = False: Puedes saludar con "¬°Hola! üëã"
- SIEMPRE conecta con la consulta anterior cuando hay contexto
- Menciona espec√≠ficamente qu√© filtros se aplicaron sobre los datos previos

‚úÖ ENFOQUE HUMANO:
- Resultados presentados con entusiasmo
- Criterios explicados naturalmente
- Sugerencias √∫tiles y emp√°ticas
- Tono conversacional y amigable

üìù FORMATO HUMANO:
- Saludo apropiado con emoji
- M√°ximo 3-4 l√≠neas pero con personalidad
- Cierre que invite a continuar la conversaci√≥n

RESPONDE √öNICAMENTE con la respuesta conversacional final.
"""

    def _create_constancia_response_prompt(self, student_data: dict, user_query: str, action_used: str) -> str:
        """Prompt especializado para constancias generadas"""
        # üîß MANEJO SEGURO DE DATOS - puede ser lista o string
        data = student_data.get("data", [])
        if isinstance(data, list) and len(data) > 0:
            alumno_data = data[0]
        elif isinstance(data, dict):
            alumno_data = data
        else:
            alumno_data = {}

        # Obtener nombre del alumno de m√∫ltiples fuentes posibles
        alumno_nombre = (
            alumno_data.get("nombre") or
            student_data.get("alumno", {}).get("nombre") if isinstance(student_data.get("alumno"), dict) else
            student_data.get("alumno") if isinstance(student_data.get("alumno"), str) else
            "el estudiante"
        )

        tipo_constancia = student_data.get("tipo_constancia", "constancia")

        # Detectar contexto conversacional
        reflexion = student_data.get("reflexion_conversacional", {})
        conversation_context = reflexion.get("datos_recordar", {}).get("context", "")

        return f"""
Eres el asistente amigable y entusiasta de la escuela "PROF. MAXIMO GAMIZ FERNANDEZ" üè´

üéØ SITUACI√ìN:
- CONSTANCIA GENERADA: {tipo_constancia}
- PARA ESTUDIANTE: {alumno_nombre}
- CONSULTA ORIGINAL: "{user_query}"
- CONTEXTO PREVIO: {conversation_context}

üé≠ TU PERSONALIDAD:
- Entusiasta y celebrativo (usa emojis de √©xito)
- Profesional pero cercano
- Gu√≠a claro y √∫til
- Emp√°tico y comprensivo

üéØ TU TAREA PARA CONSTANCIAS:
Generar una respuesta HUMANA y CELEBRATIVA que:

1. üéâ CELEBRA el √©xito de la generaci√≥n
2. üì± EXPLICA el panel derecho de manera amigable
3. üéõÔ∏è MENCIONA botones espec√≠ficos √∫tiles
4. üí° GU√çA pr√≥ximos pasos claramente
5. üîÑ CONECTA con contexto conversacional si existe

üéõÔ∏è FUNCIONALIDADES DEL PANEL (explica amigablemente):
- Bot√≥n superior izquierdo: "puedes abrir/cerrar el panel"
- Vista previa: "visor PDF con zoom para revisar tu constancia"
- "Ver datos del alumno": "revisa la informaci√≥n extra√≠da"
- "Quitar PDF": "si quieres subir otro documento"
- "Abrir navegador/imprimir": "para guardar o imprimir"
- IMPORTANTE: "Solo vista previa - para guardar usa el navegador"

üîÑ CONTINUIDAD CONVERSACIONAL:
- Si hay contexto previo, recon√≥celo: "¬°Perfecto! Siguiendo con [contexto]..."
- Si es nueva constancia, celebra: "¬°Excelente! üéâ"
- Siempre invita a continuar: "¬øNecesitas algo m√°s?"

üìù FORMATO HUMANO Y CELEBRATIVO:
- Confirmaci√≥n entusiasta con emojis
- Explicaci√≥n clara pero amigable del panel
- M√°ximo 4-5 l√≠neas con personalidad
- Cierre que invite a continuar

RESPONDE √öNICAMENTE con la respuesta conversacional final.
"""

    def _create_transformation_response_prompt(self, student_data: dict, user_query: str, action_used: str) -> str:
        """Prompt especializado para transformaciones de PDF"""
        transformation_info = student_data.get("transformation_info", {})
        tipo_constancia = transformation_info.get("tipo_constancia", "constancia")
        alumno_info = transformation_info.get("alumno", {})
        alumno_nombre = alumno_info.get("nombre", "el alumno")

        return f"""
Eres el asistente de la escuela especializado en TRANSFORMACI√ìN DE PDFs.

üéØ SITUACI√ìN:
- TRANSFORMACI√ìN COMPLETADA: PDF ‚Üí {tipo_constancia}
- PARA ESTUDIANTE: {alumno_nombre}
- CONSULTA ORIGINAL: "{user_query}"

üéØ TU TAREA ESPEC√çFICA PARA TRANSFORMACIONES:
Generar una respuesta ENFOCADA EN COMPARACI√ìN que:

1. ‚úÖ CONFIRME que la transformaci√≥n se complet√≥
2. üîÑ EXPLIQUE las funciones de comparaci√≥n
3. üì± MENCIONE botones espec√≠ficos de transformaci√≥n
4. üí° GU√çE sobre c√≥mo comparar y decidir

üîÑ FUNCIONALIDADES ESPEC√çFICAS DE TRANSFORMACI√ìN:
- Todo lo del panel normal M√ÅS:
- "Ver PDF original": muestra el que subiste
- "Ver PDF transformado": muestra el resultado
- Comparaci√≥n r√°pida: alternar entre ambos
- Misma l√≥gica: solo vista previa, guardar desde navegador

üìù FORMATO PARA TRANSFORMACIONES:
- Confirmaci√≥n de transformaci√≥n exitosa
- Explicaci√≥n de comparaci√≥n
- Gu√≠a para decidir pr√≥ximos pasos
- M√°ximo 4-5 l√≠neas

RESPONDE √öNICAMENTE con la respuesta conversacional final.
"""

    def _create_statistics_response_prompt(self, student_data: dict, user_query: str, action_used: str) -> str:
        """Prompt especializado para estad√≠sticas y conteos"""
        row_count = student_data.get("row_count", 0)

        # üîç DEBUG: Analizar datos recibidos del Student
        data = student_data.get("data", [])
        self.logger.info(f"üîç [MASTER-STATS] Analizando datos del Student:")
        self.logger.info(f"    ‚îú‚îÄ‚îÄ row_count: {row_count}")
        self.logger.info(f"    ‚îú‚îÄ‚îÄ data type: {type(data)}")
        self.logger.info(f"    ‚îú‚îÄ‚îÄ data length: {len(data) if isinstance(data, list) else 'N/A'}")
        if isinstance(data, list) and len(data) > 0:
            self.logger.info(f"    ‚îú‚îÄ‚îÄ data[0]: {data[0]}")
            self.logger.info(f"    ‚îî‚îÄ‚îÄ data[0] keys: {list(data[0].keys()) if isinstance(data[0], dict) else 'N/A'}")

        # üéØ DETECTAR TIPO DE ESTAD√çSTICA BASADO EN ESTRUCTURA DE DATOS
        is_distribution = False
        total_sum = 0

        if data and isinstance(data, list) and len(data) > 0 and isinstance(data[0], dict):
            # üéØ DETECTAR DISTRIBUCIONES: m√∫ltiples registros con campo de agrupaci√≥n + cantidad
            distribution_fields = ['grado', 'grupo', 'turno', 'ciclo_escolar']
            has_distribution_field = any(field in data[0] for field in distribution_fields)
            has_cantidad = 'cantidad' in data[0]

            if len(data) > 1 and has_distribution_field and has_cantidad:
                is_distribution = True
                total_sum = sum(item.get('cantidad', 0) for item in data)

                # Detectar tipo de distribuci√≥n
                distribution_type = next((field for field in distribution_fields if field in data[0]), 'campo')
                self.logger.info(f"üîç [MASTER-STATS] DISTRIBUCI√ìN detectada: {len(data)} {distribution_type}s, {total_sum} alumnos total")
            else:
                # Conteo simple
                actual_count = data[0].get("total", row_count)
                self.logger.info(f"üîç [MASTER-STATS] CONTEO SIMPLE: {actual_count}")
        else:
            actual_count = row_count
            self.logger.info(f"üîç [MASTER-STATS] usando row_count como actual_count: {actual_count}")

        # Preparar datos para el prompt
        if is_distribution:
            # Para distribuciones, usar datos completos
            distribution_summary = f"{len(data)} grados con {total_sum} alumnos total"
            self.logger.info(f"üîç [MASTER-STATS] Resumen distribuci√≥n: {distribution_summary}")
        else:
            # Para conteos simples, usar valor individual
            total_alumnos = 211  # Valor conocido de la base de datos
            porcentaje = round((actual_count / total_alumnos) * 100, 1) if total_alumnos > 0 else 0

        if is_distribution:
            # üéØ DETECTAR TIPO DE DISTRIBUCI√ìN (SIN INCLUIR DATOS EN EL PROMPT)
            distribution_type = next((field for field in ['grado', 'grupo', 'turno', 'ciclo_escolar'] if field in data[0]), 'campo')

            return f"""
Eres el asistente amigable y entusiasta de la escuela "PROF. MAXIMO GAMIZ FERNANDEZ" üè´

üéØ SITUACI√ìN:
- CONSULTA: "{user_query}"
- TIPO: DISTRIBUCI√ìN por {distribution_type}s
- RESULTADOS: {len(data)} {distribution_type}s diferentes
- TOTAL ALUMNOS: {total_sum} estudiantes

üé≠ TU PERSONALIDAD:
- Entusiasta y humano (usa emojis apropiados)
- Profesional pero cercano
- Emp√°tico y comprensivo
- Celebra los datos interesantes

üéØ TU TAREA PARA DISTRIBUCIONES:
Generar una respuesta HUMANA y ENTUSIASTA que:

1. üéâ SALUDA con entusiasmo apropiado
2. üìä PRESENTA la distribuci√≥n de manera atractiva
3. üî¢ DESTACA datos interesantes (total de estudiantes y categor√≠as)
4. üí° INVITA a ver los detalles visuales abajo

‚úÖ PATRONES DE RESPUESTA HUMANA:
- "¬°Perfecto! üìä Aqu√≠ tienes la distribuci√≥n..."
- "¬°Excelente consulta! üëç Te muestro c√≥mo se distribuyen..."
- "¬°Genial! üéØ Los {total_sum} estudiantes se reparten en {len(data)} categor√≠as..."
- "¬°Qu√© buena pregunta! ü§© Aqu√≠ est√° la informaci√≥n..."

‚ùå EVITA LENGUAJE T√âCNICO:
- "La distribuci√≥n de alumnos por [campo] nos muestra..."
- "Los datos detallados se presentan a continuaci√≥n"
- "Tenemos un total de X [categor√≠as] distintos"

üìù FORMATO HUMANO Y ENTUSIASTA:
- Saludo entusiasta con emoji apropiado
- Presentaci√≥n natural de los n√∫meros clave
- Invitaci√≥n amigable a explorar los detalles
- M√°ximo 2-3 l√≠neas con personalidad aut√©ntica
- Adapta el lenguaje al tipo de distribuci√≥n autom√°ticamente

RESPONDE √öNICAMENTE con la respuesta conversacional final.
"""
        else:
            return f"""
Eres el asistente de la escuela especializado en ESTAD√çSTICAS Y CONTEOS.

üéØ SITUACI√ìN:
- CONSULTA: "{user_query}"
- RESULTADO: {actual_count} alumnos
- PORCENTAJE: {porcentaje}% del total ({total_alumnos} alumnos)
- TIPO: Conteo simple

üéØ TU TAREA ESPEC√çFICA PARA CONTEOS:
Generar una respuesta ENFOCADA EN N√öMEROS que:

1. üìä PRESENTE el resultado claramente
2. üîç CONTEXTUALICE el n√∫mero (qu√© significa)
3. üí° SUGIERA an√°lisis relacionados
4. üéØ MANTENGA enfoque en datos

üìù FORMATO CONCISO:
- Resultado directo
- Contexto breve
- M√°ximo 2-3 l√≠neas

RESPONDE √öNICAMENTE con la respuesta conversacional final.
"""

    def _create_generic_response_prompt(self, student_data: dict, user_query: str, action_used: str) -> str:
        """Prompt gen√©rico para casos no espec√≠ficos"""
        message = student_data.get("message", "Consulta procesada exitosamente")

        return f"""
Eres el asistente de la escuela "PROF. MAXIMO GAMIZ FERNANDEZ".

üéØ SITUACI√ìN:
- CONSULTA: "{user_query}"
- ACCI√ìN: {action_used}
- MENSAJE: {message}

üéØ TU TAREA:
Generar una respuesta profesional y √∫til basada en la informaci√≥n disponible.

üìù FORMATO:
- Respuesta clara y directa
- Tono profesional pero amigable
- M√°ximo 2-3 l√≠neas

RESPONDE √öNICAMENTE con la respuesta conversacional final.
"""

    def _create_help_response_prompt(self, student_data: dict, user_query: str, action_used: str) -> str:
        """Prompt especializado para respuestas de ayuda del sistema"""
        help_data = student_data.get("data", {})
        help_type = help_data.get("tipo", "ayuda_general")
        titulo = help_data.get("titulo", "Ayuda del Sistema")
        contenido = help_data.get("contenido", {})

        # üéØ EXTRAER INFORMACI√ìN ESPEC√çFICA DEL HELPINTERPRETER
        info_especifica = ""
        if help_type == "capacidades_sistema":
            # üéØ EXTRAER TODAS LAS CAPACIDADES DETALLADAS
            busquedas_apellido = contenido.get("busquedas_por_apellido", {})
            busquedas_nombre = contenido.get("busquedas_por_nombre_completo", {})
            busquedas_criterios = contenido.get("busquedas_por_criterios_academicos", {})
            constancias = contenido.get("constancias_pdf_completas", {})
            estadisticas = contenido.get("estadisticas_y_conteos", {})
            continuaciones = contenido.get("continuaciones_contextuales", {})
            filtros_calif = contenido.get("filtros_de_calificaciones", {})

            info_especifica = f"""
üìä CAPACIDADES COMPLETAS DEL SISTEMA (PROBADAS):

üîç **B√öSQUEDAS POR APELLIDO**: {busquedas_apellido.get('descripcion', '')}
  Ejemplos: {', '.join(busquedas_apellido.get('ejemplos_reales', [])[:2])}

üë§ **B√öSQUEDAS POR NOMBRE COMPLETO**: {busquedas_nombre.get('descripcion', '')}
  Ejemplos: {', '.join(busquedas_nombre.get('ejemplos_reales', [])[:2])}

üéì **B√öSQUEDAS POR CRITERIOS ACAD√âMICOS**: {busquedas_criterios.get('descripcion', '')}
  Ejemplos: {', '.join(busquedas_criterios.get('ejemplos_reales', [])[:2])}

üìÑ **CONSTANCIAS PDF**: {constancias.get('descripcion', '')}
  Ejemplos: {', '.join(constancias.get('ejemplos_reales', [])[:2])}

üìä **ESTAD√çSTICAS Y CONTEOS**: {estadisticas.get('descripcion', '')}
  Ejemplos: {', '.join(estadisticas.get('ejemplos_reales', [])[:2])}

üîÑ **CONTINUACIONES CONTEXTUALES**: {continuaciones.get('descripcion', '')}
  Ejemplo: {continuaciones.get('ejemplos_reales', [''])[0] if continuaciones.get('ejemplos_reales') else ''}

üìù **FILTROS DE CALIFICACIONES**: {filtros_calif.get('descripcion', '')}
  Ejemplos: {', '.join(filtros_calif.get('ejemplos_reales', [])[:2])}
"""

        elif help_type == "tutorial_uso":
            pasos = contenido.get("pasos", [])
            consejos = contenido.get("consejos", [])

            pasos_info = ""
            for paso in pasos[:4]:  # M√°ximo 4 pasos
                titulo = paso.get("titulo", "")
                descripcion = paso.get("descripcion", "")
                ejemplos = paso.get("ejemplos_reales", [])
                pasos_info += f"- {titulo}: {descripcion}\n  Ejemplos: {', '.join(ejemplos[:2])}\n"

            info_especifica = f"""
üìö TUTORIAL PASO A PASO - CASOS REALES PROBADOS:
{pasos_info}
üí° CONSEJOS IMPORTANTES:
{chr(10).join(consejos[:3])}
"""

        # üóëÔ∏è TIPOS ELIMINADOS - SOLO MANTENEMOS CAPACIDADES Y TUTORIAL

        return f"""
Eres el asistente amigable y experto de la escuela "PROF. MAXIMO GAMIZ FERNANDEZ" üè´

üéØ SITUACI√ìN:
- CONSULTA: "{user_query}"
- TIPO DE AYUDA: {help_type}
- ACCI√ìN: {action_used}
- T√çTULO: {titulo}

{info_especifica}

üé≠ TU TAREA ESPEC√çFICA:
Generar una respuesta √öTIL Y ESPEC√çFICA que:

1. üëã SALUDA de manera apropiada
2. üìö EXPLICA la informaci√≥n REAL con ejemplos espec√≠ficos
3. üí° USA √öNICAMENTE los ejemplos concretos proporcionados arriba
4. üéØ INVITA a probar con ejemplos espec√≠ficos

‚úÖ PATRONES DE RESPUESTA SEG√öN TIPO (SIMPLIFICADO):
**Para capacidades_sistema:**
- "¬°Hola! üëã ¬°Perfecto! Te explico qu√© puedo hacer..."
- "¬°Excelente pregunta! ü§î Estas son mis capacidades principales..."

**Para tutorial_uso:**
- "¬°Hola! üëã ¬°Perfecto! Te explico c√≥mo usar el sistema paso a paso..."
- "¬°Excelente! ü§î Aqu√≠ tienes un tutorial con casos reales probados..."

üìù FORMATO ESPEC√çFICO Y OBLIGATORIO:
- Saludo entusiasta apropiado
- ENUMERA TODAS las capacidades de la informaci√≥n espec√≠fica arriba
- INCLUYE AL MENOS 1 EJEMPLO de cada tipo de b√∫squeda/funcionalidad
- MENCIONA los tipos espec√≠ficos: apellido, nombre completo, criterios acad√©micos, etc.
- USA los nombres reales de los ejemplos (MARTINEZ TORRES, SOPHIA ROMERO GARCIA, etc.)
- Menciona que son casos PROBADOS y validados
- Invitaci√≥n a probar con ejemplos concretos espec√≠ficos
- Tono conversacional y humano
- INCLUYE SALTOS DE L√çNEA entre cada capacidad para mejor legibilidad
- M√°ximo 8-10 l√≠neas para incluir TODOS los tipos

üö® OBLIGATORIO - INCLUYE TODOS LOS TIPOS CON SALTOS DE L√çNEA:
- B√öSQUEDAS POR APELLIDO: Al menos 1 ejemplo + SALTO DE L√çNEA
- B√öSQUEDAS POR NOMBRE COMPLETO: Al menos 1 ejemplo + SALTO DE L√çNEA
- B√öSQUEDAS POR CRITERIOS ACAD√âMICOS: Al menos 1 ejemplo + SALTO DE L√çNEA
- CONSTANCIAS PDF: Al menos 1 ejemplo + SALTO DE L√çNEA
- ESTAD√çSTICAS: Al menos 1 ejemplo + SALTO DE L√çNEA
- CONTINUACIONES: Al menos 1 ejemplo + SALTO DE L√çNEA
- FILTROS DE CALIFICACIONES: Al menos 1 ejemplo + SALTO DE L√çNEA
- FORMATEA con n√∫meros (1., 2., 3., etc.) y SALTO DE L√çNEA despu√©s de cada punto

RESPONDE √öNICAMENTE con la respuesta conversacional final.
"""

    def _detect_user_interaction_needed(self, action_used: str, student_data: dict) -> bool:
        """
        üéØ DETECTA SI EL STUDENT INDICA QUE NECESITA INTERACCI√ìN CON EL USUARIO

        Analiza la respuesta del Student para determinar si requiere:
        - Aclaraciones
        - Confirmaciones
        - Selecciones
        - Especificaciones adicionales
        """
        # 1. ACCIONES QUE EXPL√çCITAMENTE REQUIEREN INTERACCI√ìN
        interactive_actions = [
            "constancia_requiere_aclaracion",
            "seleccion_requerida",
            "confirmacion_requerida",
            "especificacion_requerida"
        ]

        if action_used in interactive_actions:
            return True

        # 2. VERIFICAR SI EL STUDENT INDICA ESPERA DE CONTINUACI√ìN
        reflexion = student_data.get("reflexion_conversacional", {})
        if reflexion.get("espera_continuacion", False):
            continuation_type = reflexion.get("tipo_esperado", "")
            if continuation_type in ["confirmation", "specification", "selection"]:
                return True

        # 3. VERIFICAR PATRONES EN EL MENSAJE QUE INDICAN PREGUNTA
        message = student_data.get("human_response", "")
        question_patterns = [
            "¬øcu√°l necesitas?",
            "¬øte refieres a",
            "necesito que especifiques",
            "¬øqu√© tipo de",
            "¬øconfirmas que",
            "¬øest√°s seguro"
        ]

        for pattern in question_patterns:
            if pattern.lower() in message.lower():
                return True

        return False

    def _handle_user_interaction_request(self, action_used: str, student_data: dict, base_response: str) -> str:
        """
        üéØ MANEJA SOLICITUDES DE INTERACCI√ìN CON EL USUARIO

        Mejora la respuesta del Student cuando necesita interacci√≥n,
        agregando contexto y opciones claras para el usuario.
        """
        reflexion = student_data.get("reflexion_conversacional", {})
        continuation_type = reflexion.get("tipo_esperado", "")

        # MEJORAR RESPUESTA SEG√öN EL TIPO DE INTERACCI√ìN NECESARIA
        if continuation_type == "confirmation":
            return f"{base_response}\n\nüí° **Responde 's√≠' o 'no' para continuar.**"

        elif continuation_type == "specification":
            return f"{base_response}\n\nüí° **Por favor especifica los detalles que necesitas.**"

        elif continuation_type == "selection":
            data = student_data.get("data", [])
            if data and len(data) > 1:
                return f"{base_response}\n\nüí° **Puedes referenciar por posici√≥n (ej: 'el segundo', 'n√∫mero 3') o por nombre.**"
            else:
                return f"{base_response}\n\nüí° **Por favor especifica cu√°l necesitas.**"

        else:
            # Caso gen√©rico - agregar instrucci√≥n de ayuda
            return f"{base_response}\n\nüí° **¬øNecesitas ayuda con algo espec√≠fico?**"

    def _handle_confirmation(self, context: InterpretationContext, conversation_state: dict) -> Optional[InterpretationResult]:
        """
        Maneja confirmaciones del usuario para diferentes tipos de acciones pendientes
        """
        waiting_for = conversation_state.get('waiting_for')
        context_data = conversation_state.get('context_data', {})

        if waiting_for == "confirmacion_constancia_estudios":
            # Usuario confirm√≥ generar constancia de estudios como alternativa
            alumno_nombre = context_data.get('alumno')
            if alumno_nombre:
                self.logger.info(f"Confirmaci√≥n recibida: generar constancia de estudios para {alumno_nombre}")

                # Crear consulta para generar constancia de estudios
                constancia_query = f"generar constancia de estudios para {alumno_nombre}"
                new_context = InterpretationContext(user_message=constancia_query)
                return self.student_interpreter.interpret(new_context)

        # Aqu√≠ se pueden agregar otros tipos de confirmaci√≥n:
        # elif waiting_for == "confirmacion_eliminar_alumno":
        #     return self._handle_delete_confirmation(context_data)
        # elif waiting_for == "confirmacion_actualizar_datos":
        #     return self._handle_update_confirmation(context_data)

        return None

    def _handle_clarification(self, context: InterpretationContext, conversation_state: dict) -> Optional[InterpretationResult]:
        """Maneja solicitudes de aclaraci√≥n del usuario"""
        return self.student_interpreter.interpret(context)

    def _handle_selection(self, context: InterpretationContext, conversation_state: dict) -> Optional[InterpretationResult]:
        """Maneja selecciones del usuario cuando hay m√∫ltiples opciones"""
        return self.student_interpreter.interpret(context)

    def _handle_related_question(self, context: InterpretationContext, conversation_state: dict) -> Optional[InterpretationResult]:
        """Maneja preguntas relacionadas al contexto actual de la conversaci√≥n"""
        if self.help_interpreter:
            return self.help_interpreter.interpret(context)
        return self.student_interpreter.interpret(context)

    def get_available_modules(self) -> dict:
        """Retorna informaci√≥n sobre los m√≥dulos disponibles"""
        return {
            "consulta_alumnos": {
                "disponible": True,
                "descripcion": "Consultas sobre informaci√≥n de estudiantes",
                "ejemplos": ["cu√°ntos alumnos hay", "buscar a Juan", "alumnos de 3er grado"]
            },
            "transformacion_pdf": {
                "disponible": True,
                "descripcion": "Transformaci√≥n de constancias entre formatos",
                "ejemplos": ["convertir constancia", "cambiar formato PDF", "transformar a estudios"]
            },
            "ayuda_sistema": {
                "disponible": True,
                "descripcion": "Ayuda sobre el uso del sistema",
                "ejemplos": ["c√≥mo usar el sistema", "qu√© puedo hacer", "ayuda con consultas"]
            },
            "conversacion_general": {
                "disponible": False,
                "descripcion": "Chat general y conversaci√≥n casual",
                "ejemplos": ["hola", "¬øc√≥mo est√°s?"]
            }
        }
