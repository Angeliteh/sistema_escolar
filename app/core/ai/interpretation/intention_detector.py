"""
Detector de intenci√≥n maestro - Clasifica consultas para dirigir a diferentes int√©rpretes
"""
import json
import re
from typing import Dict, Any, Optional
from dataclasses import dataclass
from app.core.logging import get_logger
from app.core.config import Config

@dataclass
class IntentionResult:
    """Resultado de la detecci√≥n de intenci√≥n POTENCIADO"""
    intention_type: str  # "consulta_alumnos", "ayuda_sistema", "conversacion_general"
    sub_intention: str   # "busqueda_simple", "generar_constancia", "transformar_pdf", "consulta_avanzada", etc.
    confidence: float
    reasoning: str
    detected_entities: Dict[str, Any]

class IntentionDetector:
    """Detector maestro de intenciones para el sistema escolar"""

    def __init__(self, gemini_client):
        self.gemini_client = gemini_client
        self.logger = get_logger(__name__)

    def detect_intention(self, user_query: str) -> IntentionResult:
        """
        PROMPT MAESTRO POTENCIADO: Detecta intenci√≥n + sub-intenci√≥n + contexto completo
        """
        try:
            # Crear prompt maestro de detecci√≥n POTENCIADO
            master_prompt = f"""
Eres un detector de intenciones maestro AVANZADO para un sistema escolar integral.
Tu trabajo es clasificar consultas Y extraer contexto completo para dirigir eficientemente a los m√≥dulos especializados.

üè´ CONTEXTO DEL SISTEMA:
- Escuela primaria "PROF. MAXIMO GAMIZ FERNANDEZ"
- Base de datos: 7 alumnos con informaci√≥n completa (nombres, CURPs, matr√≠culas, grados, grupos, turnos)
- Capacidades: consultas SQL, generaci√≥n de constancias, transformaci√≥n de PDFs, ayuda contextual
- Usuarios: personal administrativo, maestros, directivos

üìù CONSULTA DEL USUARIO: "{user_query}"

üéØ CLASIFICACI√ìN INTELIGENTE CON SUB-INTENCIONES:

1. "consulta_alumnos" - GESTI√ìN COMPLETA DE ESTUDIANTES:

   SUB-INTENCIONES ESPEC√çFICAS:
   a) "busqueda_simple" - Buscar informaci√≥n b√°sica:
      - "buscar a Juan", "cu√°ntos alumnos hay", "alumnos de 3er grado"
      - "dame la CURP de Mar√≠a", "estudiantes del turno matutino"

   b) "generar_constancia" - Crear documentos oficiales:
      - "constancia de estudios para Juan", "certificado de calificaciones"
      - "generar constancia de traslado", "necesito constancia para Mar√≠a"

   c) "transformar_pdf" - Convertir documentos existentes:
      - "transformar esta constancia", "convertir PDF al nuevo formato"
      - "cambiar formato de constancia", "actualizar documento"

   d) "consulta_avanzada" - Estad√≠sticas y an√°lisis:
      - "estad√≠sticas por grado", "promedio de calificaciones"
      - "distribuci√≥n por turnos", "an√°lisis acad√©mico"

2. "ayuda_sistema" - COMPRENSI√ìN DE CAPACIDADES:
   a) "entender_capacidades" - Qu√© puede hacer el sistema
   b) "tutorial_paso_a_paso" - C√≥mo usar funcionalidades
   c) "solucion_problema" - Resolver errores o problemas
   d) "ejemplo_practico" - Solicitar ejemplos espec√≠ficos

3. "conversacion_general" - CHAT CASUAL:
   - "hola", "buenos d√≠as", "gracias", "¬øc√≥mo est√°s?"

üß† AN√ÅLISIS CONTEXTUAL AVANZADO:
Para cada consulta, extrae:
- Nombres de alumnos mencionados
- Tipos de constancia solicitados (estudios, calificaciones, traslado)
- Acciones espec√≠ficas (buscar, generar, transformar, consultar)
- Contexto de datos (desde BD, desde PDF, desde conversaci√≥n previa)
- Par√°metros adicionales (grados, grupos, turnos, fechas)



RESPONDE √öNICAMENTE con un JSON siguiendo este formato:
{{
    "intention_type": "consulta_alumnos|ayuda_sistema|conversacion_general",
    "sub_intention": "busqueda_simple|generar_constancia|transformar_pdf|consulta_avanzada|entender_capacidades|tutorial_paso_a_paso|solucion_problema|ejemplo_practico|chat_casual",
    "confidence": 0.0-1.0,
    "reasoning": "Explicaci√≥n espec√≠fica del an√°lisis realizado",
    "detected_entities": {{
        "nombres": ["lista de nombres detectados"],
        "tipo_constancia": "estudios|calificaciones|traslado|null",
        "accion_principal": "acci√≥n espec√≠fica detectada",
        "fuente_datos": "base_datos|pdf_cargado|conversacion_previa|null",
        "contexto_especifico": "contexto adicional relevante",
        "filtros": ["filtros detectados como grado, grupo, turno"],
        "parametros_extra": {{"cualquier par√°metro adicional relevante"}}
    }}
}}
"""

            # Enviar al LLM
            response = self.gemini_client.send_prompt_sync(master_prompt)

            if response:
                print(f"üéØ Respuesta detecci√≥n maestro: {response}")

                # Parsear respuesta
                intention_data = self._parse_intention_response(response)

                if intention_data:
                    return IntentionResult(
                        intention_type=intention_data.get('intention_type', 'conversacion_general'),
                        sub_intention=intention_data.get('sub_intention', 'chat_casual'),  # ‚Üê NUEVO
                        confidence=intention_data.get('confidence', 0.5),
                        reasoning=intention_data.get('reasoning', ''),
                        detected_entities=intention_data.get('detected_entities', {})
                    )
                else:
                    # Fallback a conversaci√≥n general
                    return IntentionResult(
                        intention_type='conversacion_general',
                        sub_intention='chat_casual',  # ‚Üê NUEVO
                        confidence=Config.INTERPRETATION['confidence_thresholds']['low'],
                        reasoning='No se pudo parsear la respuesta del detector',
                        detected_entities={}
                    )
            else:
                # Fallback a conversaci√≥n general
                return IntentionResult(
                    intention_type='conversacion_general',
                    sub_intention='chat_casual',  # ‚Üê NUEVO
                    confidence=Config.INTERPRETATION['confidence_thresholds']['low'],
                    reasoning='No se recibi√≥ respuesta del detector',
                    detected_entities={}
                )

        except Exception as e:
            self.logger.error(f"Error en detecci√≥n de intenci√≥n: {e}")
            # Fallback a conversaci√≥n general
            return IntentionResult(
                intention_type='conversacion_general',
                sub_intention='chat_casual',  # ‚Üê NUEVO
                confidence=Config.INTERPRETATION['confidence_thresholds']['fallback'],
                reasoning=f'Error en detecci√≥n: {str(e)}',
                detected_entities={}
            )

    def _parse_intention_response(self, response: str) -> Optional[Dict[str, Any]]:
        """Parsea la respuesta JSON del detector de intenci√≥n"""
        try:
            # Limpiar la respuesta
            clean_response = response.strip()

            # Buscar JSON en la respuesta
            json_patterns = [
                r'```json\s*(.*?)\s*```',
                r'```\s*(.*?)\s*```',
                r'(\{.*?\})'
            ]

            for pattern in json_patterns:
                matches = re.findall(pattern, clean_response, re.DOTALL)
                if matches:
                    try:
                        intention_data = json.loads(matches[0])
                        print(f"‚úÖ Intenci√≥n parseada: {intention_data}")
                        return intention_data
                    except json.JSONDecodeError:
                        continue

            # Si no encuentra JSON, intentar parsear directamente
            try:
                intention_data = json.loads(clean_response)
                return intention_data
            except json.JSONDecodeError:
                print(f"‚ùå No se pudo parsear JSON de intenci√≥n: {clean_response}")
                return None

        except Exception as e:
            print(f"Error parseando intenci√≥n: {e}")
            return None
