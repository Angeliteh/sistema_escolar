"""
üéØ COORDINADOR PRINCIPAL DEL STUDENT QUERY INTERPRETER

RESPONSABILIDAD: Coordinar el flujo principal y delegar a componentes especializados
TAMA√ëO OBJETIVO: ~200 l√≠neas (solo coordinaci√≥n)

ARQUITECTURA REFACTORIZADA:
‚îú‚îÄ‚îÄ StudentQueryInterpreter (COORDINADOR - este archivo)
‚îú‚îÄ‚îÄ QueryAnalyzer (An√°lisis de consultas)
‚îú‚îÄ‚îÄ ContinuationHandler (Manejo de continuaciones)
‚îú‚îÄ‚îÄ ResponseBuilder (Construcci√≥n de respuestas)
‚îú‚îÄ‚îÄ DataValidator (Validaci√≥n de datos)
‚îî‚îÄ‚îÄ ConstanciaProcessor (Ya existe)

FLUJO PRINCIPAL:
1. Recibir instrucciones del Master
2. Delegar an√°lisis a QueryAnalyzer
3. Ejecutar acciones via ActionExecutor
4. Construir respuesta via ResponseBuilder
5. Retornar resultado al Master
"""
import json
import re
import os
from typing import Dict, Any, Optional, List, Tuple

from .base_interpreter import BaseInterpreter, InterpretationContext, InterpretationResult
from .database_analyzer import DatabaseAnalyzer
from .sql_executor import SQLExecutor
from .response_parser import ResponseParser
from ..prompts.student_query_prompt_manager import StudentQueryPromptManager
from app.core.logging import get_logger

# ‚úÖ CLASES ESPECIALIZADAS (ARQUITECTURA MODULAR COMPLETADA)
# üóëÔ∏è ELIMINADO: ContinuationDetector - Student ahora obedece decisiones del Master
from .student_query.student_identifier import StudentIdentifier
from .student_query.constancia_processor import ConstanciaProcessor
from .student_query.data_normalizer import DataNormalizer
from .student_query.response_generator import ResponseGenerator
from .utils.json_parser import JSONParser

# üÜï NUEVOS COMPONENTES REFACTORIZADOS (ARQUITECTURA LIMPIA)
from .student_query.query_analyzer import QueryAnalyzer
from .student_query.continuation_handler import ContinuationHandler
from .student_query.response_builder import ResponseBuilder

class StudentQueryInterpreter(BaseInterpreter):
    """Interpretador especializado en consultas de alumnos/estudiantes usando LLM"""

    def __init__(self, db_path: str, gemini_client=None):
        super().__init__("SQL_Interpreter", priority=10)  # Alta prioridad

        # üÜï LOGGING CENTRALIZADO
        self.logger = get_logger(__name__)

        self.db_path = db_path
        # üÜï ANALIZADOR DIN√ÅMICO DE BASE DE DATOS
        from app.core.database.database_analyzer import DatabaseAnalyzer
        self.database_analyzer = DatabaseAnalyzer(db_path)
        self.sql_executor = SQLExecutor(db_path)
        self.response_parser = ResponseParser()
        self.gemini_client = gemini_client

        # üÜï FIELD MAPPER PARA MAPEO DIN√ÅMICO DE CAMPOS
        from app.core.database.field_mapper import FieldMapper
        self.field_mapper = FieldMapper()

        # PromptManager centralizado para contexto escolar unificado
        self.prompt_manager = StudentQueryPromptManager()
        self.logger.debug("StudentQueryPromptManager inicializado")

        # Cache del contexto SQL
        self._sql_context = None

        # ‚úÖ INICIALIZAR CLASES ESPECIALIZADAS (ARQUITECTURA MODULAR COMPLETADA)
        # üóëÔ∏è ELIMINADO: ContinuationDetector - Student ahora obedece decisiones del Master
        self.student_identifier = StudentIdentifier()
        self.constancia_processor = ConstanciaProcessor(gemini_client)
        self.data_normalizer = DataNormalizer()
        self.response_generator = ResponseGenerator(gemini_client, self.prompt_manager)
        self.json_parser = JSONParser()

        # üÜï INICIALIZAR NUEVOS COMPONENTES REFACTORIZADOS
        self.query_analyzer = QueryAnalyzer(self.database_analyzer, gemini_client)
        self.continuation_handler = ContinuationHandler(self.database_analyzer, self.sql_executor, gemini_client)
        self.response_builder = ResponseBuilder(self.prompt_manager, gemini_client)

        self.logger.debug("‚úÖ Clases especializadas inicializadas (Arquitectura modular completada)")
        self.logger.debug("‚úÖ Nuevos componentes refactorizados inicializados")

        # üéØ INICIALIZACI√ìN COMPLETADA
        self.logger.info("üéØ [STUDENT] CONTEXTO T√âCNICO CARGADO Y VERIFICADO")

        # üîç DETECTAR SI DEBUG PAUSES EST√Å HABILITADO
        import sys
        self.debug_pauses_enabled = '--debug-pauses' in sys.argv or os.environ.get('DEBUG_PAUSES', 'false').lower() == 'true'

    def _debug_pause_if_enabled(self, message: str):
        """üõë PAUSA DE DEBUG CONTROLADA POR VARIABLE DE ENTORNO"""
        if os.environ.get('DEBUG_PAUSES', 'false').lower() == 'true':
            input(f"üõë {message}")

    def _generate_contextual_response(self, user_query: str, total_count: int, filtered_count: int,
                                    filter_type: str, conversation_stack: list) -> str:
        """
        üÜï GENERA RESPUESTA CONTEXTUAL PARA AN√ÅLISIS SIN FILTROS
        """
        try:
            user_lower = user_query.lower()

            # Detectar tipo de an√°lisis solicitado
            if 'promedio' in user_lower:
                if filtered_count == 0:
                    return f"De los **{total_count} estudiantes** del contexto anterior, ninguno tiene calificaciones registradas para calcular promedio. üìä"
                else:
                    return f"Analizando el promedio de calificaciones de los **{filtered_count} estudiantes** del contexto anterior... üìä"

            elif 'estad√≠stica' in user_lower or 'distribuci√≥n' in user_lower:
                return f"Generando estad√≠sticas de los **{filtered_count} estudiantes** del contexto anterior... üìà"

            elif 'an√°lisis' in user_lower:
                return f"Realizando an√°lisis de los **{filtered_count} estudiantes** del contexto anterior... üîç"

            else:
                return f"Procesando informaci√≥n de los **{filtered_count} estudiantes** del contexto anterior... ‚úÖ"

        except Exception as e:
            self.logger.error(f"Error generando respuesta contextual: {e}")
            return f"Procesando informaci√≥n de {filtered_count} estudiantes... ‚úÖ"

    def _generate_dynamic_filter_response(self, user_query: str, total_count: int, filtered_count: int,
                                        filter_criteria: dict, conversation_stack: list) -> str:
        """
        üÜï GENERA RESPUESTA PARA FILTROS DIN√ÅMICOS APLICADOS
        """
        try:
            # Extraer criterios aplicados para la respuesta
            criterios = filter_criteria.get('criterios', [])
            criterios_texto = []

            for criterio in criterios:
                campo = criterio.get('campo', '')
                operador = criterio.get('operador', '')
                valor = criterio.get('valor', '')

                if campo == 'promedio_general' and operador == 'mayor_que':
                    criterios_texto.append(f"promedio mayor a {valor}")
                elif campo == 'grupo':
                    criterios_texto.append(f"grupo {valor}")
                elif campo == 'turno':
                    criterios_texto.append(f"turno {valor.lower()}")
                elif campo == 'grado':
                    criterios_texto.append(f"{valor}¬∞ grado")
                else:
                    criterios_texto.append(f"{campo} {operador} {valor}")

            if criterios_texto:
                criterios_str = ", ".join(criterios_texto)
                if filtered_count == 0:
                    return f"De los **{total_count} estudiantes** del contexto anterior, ninguno cumple con los criterios: {criterios_str}. üìä"
                elif filtered_count == 1:
                    return f"De los **{total_count} estudiantes** del contexto anterior, encontr√© **1 estudiante** que cumple con: {criterios_str}. ‚úÖ"
                else:
                    return f"De los **{total_count} estudiantes** del contexto anterior, encontr√© **{filtered_count} estudiantes** que cumplen con: {criterios_str}. ‚úÖ"
            else:
                return f"Filtr√© los **{total_count} estudiantes** del contexto anterior y obtuve **{filtered_count} resultados**. ‚úÖ"

        except Exception as e:
            self.logger.error(f"Error generando respuesta de filtro din√°mico: {e}")
            return f"De {total_count} estudiantes, {filtered_count} cumplen los criterios. ‚úÖ"

    def _get_supported_actions(self):
        """M√©todo requerido por BaseInterpreter - mantenido por compatibilidad"""
        return ["consulta_sql_exitosa", "consulta_sql_fallida"]

    def can_handle(self, context: InterpretationContext) -> bool:
        """M√©todo abstracto requerido - siempre True porque se usa desde MasterInterpreter"""
        return True  # El MasterInterpreter ya decidi√≥ que somos el int√©rprete correcto

    def interpret(self, context: InterpretationContext, current_pdf=None) -> Optional[InterpretationResult]:
        """
        üéØ M√âTODO PRINCIPAL SIMPLIFICADO - SOLO DIRIGE AL FLUJO UNIFICADO

        TODAS las consultas (b√∫squedas, estad√≠sticas, constancias, continuaciones)
        usan el MISMO flujo principal unificado de 4 prompts.
        """
        try:
            # üéì [STUDENT] Recibiendo instrucciones del Master
            from app.core.logging import debug_detailed
            debug_detailed(self.logger, f"üîß [STUDENT] Informaci√≥n del Master recibida:")
            if hasattr(context, 'intention_info') and context.intention_info:
                debug_detailed(self.logger, f"üîß [STUDENT] Categor√≠a: {context.intention_info.get('categoria', 'N/A')}")
                debug_detailed(self.logger, f"üîß [STUDENT] Sub-tipo: {context.intention_info.get('sub_tipo', 'N/A')}")
                debug_detailed(self.logger, f"üîß [STUDENT] Complejidad: {context.intention_info.get('complejidad', 'N/A')}")

            # üõë PAUSA ESTRAT√âGICA #2: STUDENT RECIBE INFORMACI√ìN DEL MASTER
            import os
            if os.environ.get('DEBUG_PAUSES', 'false').lower() == 'true':
                print(f"\nüõë [STUDENT] RECIBE DEL MASTER:")
                print(f"    ‚îú‚îÄ‚îÄ üìù Consulta: '{context.user_message}'")
                print(f"    ‚îú‚îÄ‚îÄ üéØ Intenci√≥n: {context.intention_info.get('intention_type', 'N/A') if hasattr(context, 'intention_info') and context.intention_info else 'NO HAY'}")
                print(f"    ‚îú‚îÄ‚îÄ üîç Sub-intenci√≥n: {context.intention_info.get('sub_intention', 'N/A') if hasattr(context, 'intention_info') and context.intention_info else 'NO HAY'}")
                if hasattr(context, 'intention_info') and context.intention_info:
                    entities = context.intention_info.get('detected_entities', {})
                    print(f"    ‚îú‚îÄ‚îÄ üìä Entidades detectadas: {len(entities)}")
                    for key, value in entities.items():
                        if isinstance(value, list) and len(value) > 2:
                            print(f"    ‚îÇ   ‚îú‚îÄ‚îÄ {key}: {value[:2]}... (+{len(value)-2} m√°s)")
                        else:
                            print(f"    ‚îÇ   ‚îú‚îÄ‚îÄ {key}: {value}")
                if hasattr(context, 'conversation_stack') and context.conversation_stack:
                    print(f"    ‚îú‚îÄ‚îÄ üîç Contexto conversacional: {len(context.conversation_stack)} niveles")
                    ultimo_nivel = context.conversation_stack[-1]
                    print(f"    ‚îÇ   ‚îî‚îÄ‚îÄ √öltimo: '{ultimo_nivel.get('query', 'N/A')}' ({ultimo_nivel.get('row_count', 0)} elementos)")
                else:
                    print(f"    ‚îú‚îÄ‚îÄ üîç Contexto conversacional: VAC√çO (consulta nueva)")
                print(f"    ‚îî‚îÄ‚îÄ Presiona ENTER para que Student procese...")
                input()

            self.logger.info(f"üîÑ [STUDENT] Iniciando procesamiento: '{context.user_message}'")

            # üéØ GUARDAR CONTEXTO PARA USO EN M√âTODOS INTERNOS
            self._current_context = context

            # üóëÔ∏è ELIMINADO: Verificaci√≥n de respuesta a aclaraci√≥n
            # RAZ√ìN: El Master maneja todas las aclaraciones, Student solo obedece

            # üÜï INICIALIZAR ESTRUCTURAS SI NO EXISTEN
            if not hasattr(context, 'conversation_history') or context.conversation_history is None:
                context.conversation_history = []
            if not hasattr(context, 'conversation_stack') or context.conversation_stack is None:
                context.conversation_stack = []

            # üéØ PROCESAMIENTO CON CONTEXTO CONVERSACIONAL PRESERVADO
            # üéì [STUDENT] Procesando consulta
            from app.core.logging import debug_detailed
            if context.conversation_stack:
                debug_detailed(self.logger, f"üîß [STUDENT] PROCESANDO CON CONTEXTO - {len(context.conversation_stack)} niveles disponibles")
            else:
                debug_detailed(self.logger, "üîß [STUDENT] PROCESANDO CONSULTA INDIVIDUAL")

            # PREPARAR CONTEXTO CONVERSACIONAL
            conversation_context = ""
            if context.conversation_stack:
                conversation_context = self._format_conversation_stack_for_llm(context.conversation_stack)
                debug_detailed(self.logger, f"üîß [STUDENT] Contexto conversacional disponible: {len(context.conversation_stack)} niveles")

            # üÜï USAR INFORMACI√ìN CONSOLIDADA DEL MASTER
            # Ya no necesitamos detectar intenci√≥n espec√≠fica - viene del Master
            master_intention = context.intention_info
            if not master_intention:
                self.logger.error("   ‚îî‚îÄ‚îÄ ‚ùå No se recibi√≥ informaci√≥n de intenci√≥n del Master")
                return None

            self.logger.info(f"   ‚îú‚îÄ‚îÄ ‚úÖ Informaci√≥n del Master recibida:")
            self.logger.info(f"   ‚îú‚îÄ‚îÄ    Categor√≠a: {master_intention.get('categoria')}")
            self.logger.info(f"   ‚îú‚îÄ‚îÄ    Sub-tipo: {master_intention.get('sub_tipo')}")
            self.logger.info(f"   ‚îî‚îÄ‚îÄ    Complejidad: {master_intention.get('complejidad')}")

            categoria = master_intention.get('categoria', 'busqueda')
            flujo_optimo = master_intention.get('flujo_optimo', 'sql_directo')
            self.logger.info(f"   ‚îî‚îÄ‚îÄ ‚úÖ Intenci√≥n consolidada: {categoria} ‚Üí {flujo_optimo}")

            # üéì [STUDENT] Iniciando procesamiento con informaci√≥n del Master
            self._debug_pause("üéì [STUDENT] RECIBIENDO ORDEN DEL MASTER", {
                "categoria": categoria,
                "sub_tipo": master_intention.get('sub_tipo'),
                "complejidad": master_intention.get('complejidad'),
                "flujo_optimo": flujo_optimo,
                "entidades_detectadas": len(master_intention.get('detected_entities', {}))
            })

            return self._execute_main_3_prompt_flow(context, master_intention, conversation_context, current_pdf)

        except Exception as e:
            self.logger.error(f"‚ùå Error en StudentQueryInterpreter: {e}")
            import traceback
            self.logger.error(traceback.format_exc())

            return InterpretationResult(
                action="consulta_sql_fallida",
                parameters={
                    "error": f"Error interno: {str(e)}",
                    "message": "‚ùå Error procesando tu consulta. Intenta reformularla.",
                    "exception": str(e)
                },
                confidence=0.1
            )

    # üéØ FLUJO PRINCIPAL UNIFICADO DE 4 PROMPTS

    def _execute_main_3_prompt_flow(self, context, master_intention: Dict[str, Any], conversation_context: str, current_pdf=None) -> Optional[InterpretationResult]:
        """
        üéØ FLUJO PRINCIPAL OPTIMIZADO DE 3 PROMPTS (PROMPT 1 ELIMINADO)

        PROP√ìSITO: Maneja TODAS las consultas usando informaci√≥n consolidada del Master
        ARQUITECTURA: PROMPT 2 ‚Üí EJECUCI√ìN ‚Üí PROMPT 3
        EJEMPLOS: "buscar garcia", "promedio de calificaciones", "constancia para luis"

        FLUJO OPTIMIZADO:
        - INFORMACI√ìN DEL MASTER: Categor√≠a, sub-tipo, complejidad ya detectados
        - PROMPT 2: Selecci√≥n de acciones (BUSCAR_UNIVERSAL, CALCULAR_ESTADISTICA, etc.)
        - EJECUCI√ìN: ActionExecutor ejecuta la acci√≥n seleccionada
        - PROMPT 3: Validaci√≥n + respuesta + auto-reflexi√≥n
        """
        try:
            # üîß CR√çTICO: Almacenar master_intention para que ActionExecutor pueda accederla
            self.master_intention = master_intention

            # üéì [STUDENT] Ejecutando flujo de 3 prompts con informaci√≥n del Master
            from app.core.logging import debug_detailed
            categoria = master_intention.get('categoria', 'busqueda')
            self.logger.info(f"üéì [STUDENT] Ejecutando: {master_intention.get('flujo_optimo', 'procesamiento')}")
            debug_detailed(self.logger, f"üîß [STUDENT] Categor√≠a: {categoria} ‚Üí {master_intention.get('flujo_optimo')}")

            # üóëÔ∏è ELIMINADO: Verificaci√≥n de transformaci√≥n
            # RAZ√ìN: Los m√©todos _is_transformation_request, _is_external_pdf_loaded y _process_constancia_from_pdf
            # fueron eliminados porque violan el principio Master-Student

            # PROMPT 2: Selecci√≥n de acciones (ahora es PROMPT 1 del Student)
            self.logger.info("   ‚îú‚îÄ‚îÄ PROMPT 1 (Student): Selecci√≥n de acciones...")

            # üõë PAUSA ESTRAT√âGICA #4: STUDENT MAPEO DE CAMPOS CON CONTEXTO DB
            import os
            if os.environ.get('DEBUG_PAUSES', 'false').lower() == 'true':
                print(f"\nüõë [STUDENT] MAPEO DE CAMPOS CON BASE DE DATOS:")
                print(f"    ‚îú‚îÄ‚îÄ üìù Consulta: '{context.user_message}'")
                print(f"    ‚îú‚îÄ‚îÄ üß† Filtros del Master: {master_intention.get('detected_entities', {}).get('filtros', [])}")
                print(f"    ‚îú‚îÄ‚îÄ üóÉÔ∏è Estructura de DB disponible para mapeo:")

                # Mostrar estructura de DB
                if hasattr(self, 'database_analyzer'):
                    structure = self.database_analyzer.get_database_structure()
                    for table_name, table_info in structure.get('tables', {}).items():
                        if table_name in ['alumnos', 'datos_escolares']:
                            columns = list(table_info.get('columns', {}).keys())
                            print(f"    ‚îÇ   ‚îú‚îÄ‚îÄ {table_name}: {', '.join(columns[:6])}{'...' if len(columns) > 6 else ''}")
                else:
                    print(f"    ‚îÇ   ‚îú‚îÄ‚îÄ alumnos: id, curp, nombre, matricula, fecha_nacimiento")
                    print(f"    ‚îÇ   ‚îî‚îÄ‚îÄ datos_escolares: grado, grupo, turno, ciclo_escolar")

                print(f"    ‚îú‚îÄ‚îÄ üß† Student analizar√° y mapear√° campos inteligentemente")
                print(f"    ‚îî‚îÄ‚îÄ Presiona ENTER para que Student procese con contexto DB...")
                input()

            # üîß PASAR CONVERSATION_STACK Y MASTER_INTENTION AL M√âTODO
            self.conversation_stack = context.conversation_stack  # ‚úÖ ASIGNAR PARA QUE getattr() FUNCIONE
            # ‚úÖ USAR INFORMACI√ìN DEL MASTER CORRECTAMENTE
            self.master_intention = master_intention  # Ya tenemos master_intention como par√°metro
            action_request = self._select_action_strategy(context.user_message, categoria, conversation_context)

            if not action_request:
                self.logger.error("   ‚îî‚îÄ‚îÄ ‚ùå No se pudo determinar estrategia de acci√≥n")
                return None

            self.logger.info(f"   ‚îú‚îÄ‚îÄ ‚úÖ Estrategia seleccionada: {action_request.get('estrategia')}")
            self.logger.info(f"   ‚îî‚îÄ‚îÄ ‚úÖ Acci√≥n principal: {action_request.get('accion_principal')}")

            # EJECUCI√ìN: ActionExecutor
            self.logger.info("   ‚îú‚îÄ‚îÄ EJECUCI√ìN: ActionExecutor...")
            execution_result = self._execute_selected_action(action_request, current_pdf)

            if not execution_result or not execution_result.get('success'):
                self.logger.error(f"   ‚îî‚îÄ‚îÄ ‚ùå Error en ejecuci√≥n: {execution_result.get('message') if execution_result else 'Sin resultado'}")
                return None

            self.logger.info(f"   ‚îú‚îÄ‚îÄ ‚úÖ Ejecuci√≥n exitosa: {execution_result.get('row_count')} resultados")

            # üéØ STUDENT SOLO REPORTA RESULTADOS - NO TOMA DECISIONES DE COMUNICACI√ìN
            # El Master decidir√° si necesita comunicaci√≥n bidireccional basado en los resultados

            # üîß VERIFICAR SI ES CONTINUACI√ìN PROCESADA - NO LLAMAR _validate_and_generate_response()
            if action_request.get('accion_principal') == 'CONTINUACION_PROCESADA':
                self.logger.info("   ‚îú‚îÄ‚îÄ üéØ CONTINUACI√ìN PROCESADA - Usando resultado directo sin validaci√≥n adicional")

                # Preparar resultado final
                final_result = InterpretationResult(
                    action=execution_result.get('action_used', 'seleccion_realizada'),
                    parameters={
                        # üéØ PRESERVAR TODOS LOS PAR√ÅMETROS DE LA CONVERSI√ìN
                        **execution_result,  # Incluir TODOS los par√°metros del execution_result
                        "master_intention": master_intention,
                        "execution_summary": f"Continuaci√≥n procesada: {action_request.get('accion_principal')} ‚Üí {execution_result.get('row_count', 0)} resultados",
                        "requires_master_response": True,
                        "student_action": action_request.get('accion_principal'),
                        "query_category": categoria
                    },
                    confidence=0.9
                )



                return final_result

            # PROMPT 3: Validaci√≥n + respuesta + auto-reflexi√≥n (ahora es PROMPT 2 del Student)
            self.logger.info("   ‚îú‚îÄ‚îÄ PROMPT 2 (Student): Validaci√≥n + respuesta...")
            final_response = self._validate_and_generate_response(
                context.user_message,
                execution_result.get('sql_executed', ''),
                execution_result.get('data', []),
                execution_result.get('row_count', 0),
                context.conversation_stack
            )

            if not final_response:
                self.logger.error("   ‚îî‚îÄ‚îÄ ‚ùå No se pudo generar respuesta final")
                return None

            self.logger.info("   ‚îî‚îÄ‚îÄ ‚úÖ Respuesta final generada exitosamente")

            # Crear resultado final - SOLO DATOS T√âCNICOS PARA EL MASTER
            action_used = execution_result.get('action_used', 'consulta_procesada')

            # üéØ CASO ESPECIAL: PRESERVAR PAR√ÅMETROS DE TRANSFORMACI√ìN
            if action_used == 'transformation_preview':
                # Preservar todos los par√°metros espec√≠ficos de transformaci√≥n
                parameters = {
                    # üéØ DATOS T√âCNICOS PARA EL MASTER (NO RESPUESTA FINAL)
                    "technical_response": final_response.get("respuesta_usuario", "Consulta procesada"),
                    "reflexion_conversacional": final_response.get("reflexion_conversacional", {}),
                    "data": execution_result.get('data', []),
                    "row_count": execution_result.get('row_count', 0),
                    "sql_executed": execution_result.get('sql_executed', ''),
                    "master_intention": master_intention,  # üÜï Incluir informaci√≥n del Master
                    "execution_summary": f"Flujo de 3 prompts completado: {categoria} ‚Üí {action_request.get('accion_principal')} ‚Üí {execution_result.get('row_count')} resultados",
                    # üö® FLAG PARA MASTER: Indica que debe generar respuesta final
                    "requires_master_response": True,
                    "student_action": action_request.get('accion_principal'),
                    "query_category": categoria,
                    # üéØ PRESERVAR PAR√ÅMETROS ESPEC√çFICOS DE TRANSFORMACI√ìN
                    "files": execution_result.get('files', []),
                    "alumno": execution_result.get('alumno', {}),
                    "transformation_info": execution_result.get('transformation_info', {}),
                    "human_response": final_response.get("respuesta_usuario", "Vista previa de transformaci√≥n generada")
                }
            else:
                # Par√°metros normales para otras acciones
                parameters = {
                    # üéØ DATOS T√âCNICOS PARA EL MASTER (NO RESPUESTA FINAL)
                    "technical_response": final_response.get("respuesta_usuario", "Consulta procesada"),
                    "reflexion_conversacional": final_response.get("reflexion_conversacional", {}),
                    "data": execution_result.get('data', []),
                    "row_count": execution_result.get('row_count', 0),
                    "sql_executed": execution_result.get('sql_executed', ''),
                    "master_intention": master_intention,  # üÜï Incluir informaci√≥n del Master
                    "execution_summary": f"Flujo de 3 prompts completado: {categoria} ‚Üí {action_request.get('accion_principal')} ‚Üí {execution_result.get('row_count')} resultados",
                    # üö® FLAG PARA MASTER: Indica que debe generar respuesta final
                    "requires_master_response": True,
                    "student_action": action_request.get('accion_principal'),
                    "query_category": categoria
                }

            # üîß DEBUG: Mostrar reporte que se env√≠a al Master
            self._debug_pause("üì§ [STUDENT] ENVIANDO REPORTE AL MASTER", {
                "action_ejecutada": action_request.get('accion_principal'),
                "resultados_obtenidos": execution_result.get('row_count', 0),
                "sql_ejecutado": execution_result.get('sql_executed', '')[:100] + "..." if execution_result.get('sql_executed') else "N/A",
                "requiere_respuesta_master": True,
                "datos_tecnicos_incluidos": ["data", "row_count", "sql_executed", "master_intention"]
            })

            return InterpretationResult(
                action=action_used,
                parameters=parameters,
                confidence=0.9
            )

        except Exception as e:
            self.logger.error(f"‚ùå Error en flujo de 3 prompts: {e}")
            import traceback
            self.logger.error(f"Traceback: {traceback.format_exc()}")
            return None



    # üéØ M√âTODOS DEL SISTEMA DE ACCIONES

    def _select_action_strategy(self, user_query: str, categoria: str, conversation_context: str = "") -> Optional[Dict[str, Any]]:
        """
        üÜï NUEVO PROMPT 2: Selecciona estrategia de acciones
        REEMPLAZA: _generate_sql_with_strategy_centralized()
        üéØ NUEVA FUNCIONALIDAD: Detecta consultas de seguimiento y usa BUSCAR_UNIVERSAL con composici√≥n
        """
        try:
            # üéØ PASO 1: OBEDECER DECISI√ìN DEL MASTER SOBRE CONTEXTO
            # Obtener informaci√≥n del Master desde los atributos asignados previamente
            master_intention = getattr(self, 'master_intention', {})

            # üîß VERIFICACI√ìN DE TIPO: Asegurar que master_intention es un diccionario
            if not isinstance(master_intention, dict):
                self.logger.warning(f"‚ö†Ô∏è master_intention no es dict: {type(master_intention)} - Usando diccionario vac√≠o")
                master_intention = {}

            requiere_contexto = master_intention.get('requiere_contexto', False)

            conversation_stack = getattr(self, 'conversation_stack', [])

            # üéØ STUDENT OBEDECE AL MASTER - NO TOMA DECISIONES PROPIAS
            # Normalizar el valor (puede venir como string o boolean)
            requiere_contexto_normalizado = bool(requiere_contexto)

            # üéØ VERIFICAR SI MASTER YA RESOLVI√ì LA REFERENCIA
            detected_entities = master_intention.get('detected_entities', {})
            alumno_resuelto = detected_entities.get('alumno_resuelto')

            if alumno_resuelto:
                self.logger.info(f"‚úÖ MASTER YA RESOLVI√ì ALUMNO: {alumno_resuelto['nombre']} (ID: {alumno_resuelto['id']})")
                # üîß CREAR ACTION_REQUEST PARA EL ALUMNO RESUELTO (NO EJECUTAR AQU√ç)
                sub_intention = master_intention.get('sub_intention')
                self.logger.info(f"üîç Sub-intenci√≥n para alumno resuelto: {sub_intention}")

                action_request = self._create_action_request_for_resolved_student(sub_intention, alumno_resuelto, detected_entities)
                if action_request:
                    self.logger.info(f"üéØ Action request creado para flujo normal: {action_request.get('accion_principal')} con par√°metros: {action_request.get('parametros')}")
                    # üéØ DEVOLVER ACTION_REQUEST PARA QUE EL FLUJO NORMAL LO EJECUTE
                    return action_request
                else:
                    self.logger.warning(f"‚ùå No se pudo crear action_request para sub_intention: {sub_intention}")
                    return None

            elif requiere_contexto_normalizado and conversation_stack:
                self.logger.info(f"‚úÖ MASTER DECIDI√ì: Usar contexto - {len(conversation_stack)} niveles disponibles")
                return self._process_continuation_with_master_guidance(user_query, conversation_stack)

            else:
                self.logger.info("‚úÖ MASTER DECIDI√ì: NO usar contexto - Procesando como consulta individual")

            # üéØ CONSULTA NORMAL - USAR PROMPT TRADICIONAL
            # üÜï INCLUIR INFORMACI√ìN DEL MASTER EN EL PROMPT
            master_intention = getattr(self, 'master_intention', {})
            master_filters = master_intention.get('detected_entities', {}).get('filtros', [])

            # Construir informaci√≥n adicional del Master para el prompt
            master_info = ""
            if master_filters:
                master_info = f"""
üß† INFORMACI√ìN ADICIONAL DEL MASTER:
El Master detect√≥ los siguientes filtros espec√≠ficos en la consulta:
{master_filters}

üéØ IMPORTANTE: Usa estos filtros como criterios separados:
"""
                for filtro in master_filters:
                    if ':' in filtro:
                        campo, valor = filtro.split(':', 1)
                        campo = campo.strip()
                        valor = valor.strip()
                        # Mapeo din√°mico de campos usando FieldMapper
                        mapped_field = self.field_mapper.map_user_field_to_db(campo.lower())
                        if mapped_field:
                            tabla = mapped_field.get('tabla', 'datos_escolares')
                            campo_db = mapped_field.get('campo', campo.lower())
                            master_info += f"- Criterio {campo}: {{'tabla': '{tabla}', 'campo': '{campo_db}', 'operador': '=', 'valor': '{valor.upper()}'}}\n"
                        else:
                            # Fallback para campos no mapeados
                            master_info += f"- Criterio {campo}: {{'tabla': 'datos_escolares', 'campo': '{campo.lower()}', 'operador': '=', 'valor': '{valor.upper()}'}}\n"

                master_info += "\nüîß USAR ESTOS COMO CRITERIOS SEPARADOS, NO COMBINADOS.\n"

            # Usar nuevo prompt de selecci√≥n de acciones con informaci√≥n del Master
            action_prompt = self.prompt_manager.get_action_selection_prompt(
                user_query, categoria, conversation_context + master_info,
                master_intention  # üîß PASAR INFORMACI√ìN DEL MASTER
            )

            # üéì [STUDENT] Preparando prompt de selecci√≥n de acciones
            self.logger.info("üß† [STUDENT-RAZONAMIENTO] Iniciando an√°lisis basado en descripciones")
            self.logger.info(f"   ‚îú‚îÄ‚îÄ Sub-intenci√≥n recibida: {master_intention.get('sub_intention', 'N/A')}")
            self.logger.info(f"   ‚îú‚îÄ‚îÄ Consulta a analizar: '{user_query}'")
            self.logger.info(f"   ‚îî‚îÄ‚îÄ Usando razonamiento humano (no ejemplos literales)")

            # üéì [STUDENT] Enviando prompt al LLM
            response = self.gemini_client.send_prompt_sync(action_prompt)

            if response:
                # üîç DEBUG: Mostrar respuesta del LLM para diagnosticar problema
                self.logger.info(f"üîç [DEBUG] Respuesta del LLM: {response[:500]}...")
                action_request = self._parse_action_response(response)

                # üîç DEBUG: Verificar tipo de action_request
                self.logger.info(f"üîç [DEBUG] Tipo de action_request: {type(action_request)}")
                if action_request:
                    self.logger.info(f"üîç [DEBUG] action_request contenido: {action_request}")

                # üß† [STUDENT-RAZONAMIENTO] Analizar decisi√≥n del LLM
                if action_request and isinstance(action_request, dict):
                    campos_solicitados = action_request.get('parametros', {}).get('campos_solicitados', [])
                    if campos_solicitados:
                        self.logger.info(f"üß† [STUDENT-RAZONAMIENTO] LLM decidi√≥ usar campos espec√≠ficos: {campos_solicitados}")
                        self.logger.info("   ‚îú‚îÄ‚îÄ ‚ö†Ô∏è VERIFICAR: ¬øEs esto correcto para 'informaci√≥n completa'?")
                        if any(campo.lower() in ['informacion_completa', 'datos_completos', 'toda_la_informacion'] for campo in campos_solicitados):
                            self.logger.warning("   ‚îî‚îÄ‚îÄ ‚ùå ERROR: LLM interpret√≥ mal - estos NO son campos reales de BD")
                    else:
                        self.logger.info("üß† [STUDENT-RAZONAMIENTO] LLM NO especific√≥ campos_solicitados")
                        self.logger.info("   ‚îî‚îÄ‚îÄ ‚úÖ CORRECTO: Para informaci√≥n completa, usar todos los campos")

                if action_request and isinstance(action_request, dict):
                    accion_principal = action_request.get('accion_principal', 'unknown')
                    estrategia = action_request.get('estrategia', 'simple')
                    razonamiento = action_request.get('razonamiento', 'N/A')
                    parametros = action_request.get('parametros', {})

                    # üéì [STUDENT] Estrategia seleccionada
                    self.logger.info(f"üéì [STUDENT] Mapeando: \"{user_query}\" ‚Üí {accion_principal} ({estrategia})")

                    # üõë PAUSA ESTRAT√âGICA: MOSTRAR MAPEO INTELIGENTE
                    import os
                    if os.environ.get('DEBUG_PAUSES', 'false').lower() == 'true':
                        criterio_principal = parametros.get('criterio_principal', {})
                        if criterio_principal:
                            print(f"\nüõë [STUDENT] MAPEO INTELIGENTE REALIZADO:")
                            print(f"    ‚îú‚îÄ‚îÄ üìù Filtros del Master: {master_info.split('filtros: ')[1].split('\\n')[0] if 'filtros: ' in master_info else 'N/A'}")
                            print(f"    ‚îú‚îÄ‚îÄ üß† Razonamiento: {razonamiento}")
                            print(f"    ‚îú‚îÄ‚îÄ üéØ Mapeo resultante:")
                            print(f"    ‚îÇ   ‚îú‚îÄ‚îÄ Tabla: {criterio_principal.get('tabla', 'N/A')}")
                            print(f"    ‚îÇ   ‚îú‚îÄ‚îÄ Campo: {criterio_principal.get('campo', 'N/A')}")
                            print(f"    ‚îÇ   ‚îú‚îÄ‚îÄ Operador: {criterio_principal.get('operador', 'N/A')}")
                            print(f"    ‚îÇ   ‚îî‚îÄ‚îÄ Valor: {criterio_principal.get('valor', 'N/A')}")
                            print(f"    ‚îî‚îÄ‚îÄ Presiona ENTER para ejecutar acci√≥n...")
                            input()

                    return action_request
                elif action_request:
                    self.logger.error(f"‚ùå action_request no es un diccionario: {type(action_request)} - Contenido: {action_request}")
                    return None
                else:
                    self.logger.warning("‚ùå No se pudo parsear respuesta de selecci√≥n de acci√≥n")
                    return None
            else:
                self.logger.warning("‚ùå No se recibi√≥ respuesta del LLM para selecci√≥n de acci√≥n")
                return None

        except Exception as e:
            self.logger.error(f"Error seleccionando estrategia de acci√≥n: {e}")
            return None

    # üóëÔ∏è M√âTODO ELIMINADO: _is_follow_up_query
    # RAZ√ìN: Hardcoding innecesario - Master ya decide si usar contexto con LLM

    # üóëÔ∏è M√âTODO ELIMINADO: _analyze_context_relevance_with_llm
    # Ya no se usa - reemplazado por ContinuationDetector con LLM inteligente

    def _execute_selected_action(self, action_request: Dict[str, Any], current_pdf=None) -> Optional[Dict[str, Any]]:
        """
        üéØ Ejecuta la acci√≥n seleccionada por el LLM usando ActionExecutor
        """
        try:
            # üîç DEBUG: Solo mostrar con --debug-pauses
            if hasattr(self, 'debug_pauses_enabled') and self.debug_pauses_enabled:
                self.logger.info(f"üîç [DEBUG] _execute_selected_action llamado:")
                self.logger.info(f"    ‚îú‚îÄ‚îÄ accion_principal: {action_request.get('accion_principal')}")
                self.logger.info(f"    ‚îî‚îÄ‚îÄ resultado_directo existe: {bool(action_request.get('resultado_directo'))}")

            # üéØ CASO ESPECIAL: CONTINUACI√ìN YA PROCESADA
            if action_request.get('accion_principal') == 'CONTINUACION_PROCESADA':
                self.logger.info("üéØ CONTINUACI√ìN YA PROCESADA - Extrayendo resultado directo")

                continuation_result = action_request.get('resultado_directo')

                if continuation_result and hasattr(continuation_result, 'parameters'):
                    # Convertir InterpretationResult a formato de execution result
                    result = {
                        "success": True,
                        "data": continuation_result.parameters.get('data', []),
                        "row_count": continuation_result.parameters.get('row_count', 0),
                        "action_used": continuation_result.action,
                        "message": continuation_result.parameters.get('message', 'Continuaci√≥n procesada'),
                        "sql_executed": continuation_result.parameters.get('sql_executed', ''),
                        "human_response": continuation_result.parameters.get('human_response', '')
                    }

                    # üîß AGREGAR TODOS LOS PAR√ÅMETROS ADICIONALES DEL RESULTADO ORIGINAL
                    for key, value in continuation_result.parameters.items():
                        if key not in result:  # No sobrescribir los ya establecidos
                            result[key] = value

                    return result
                else:
                    self.logger.error("‚ùå Resultado de continuaci√≥n inv√°lido")
                    return {
                        "success": False,
                        "data": [],
                        "row_count": 0,
                        "action_used": "CONTINUACION_ERROR",
                        "message": "Error procesando continuaci√≥n"
                    }

            # üéØ CASO NORMAL: EJECUTAR CON ACTIONEXECUTOR
            # Importar y crear ActionExecutor
            from app.core.ai.actions import ActionExecutor
            action_executor = ActionExecutor(self.sql_executor, self)

            # üîß AGREGAR L√çMITE DEL MASTER AL ACTION_REQUEST
            limite_master = self._get_master_limit()
            if limite_master and action_request.get("accion_principal") == "BUSCAR_UNIVERSAL":
                if "parametros" not in action_request:
                    action_request["parametros"] = {}
                action_request["parametros"]["limit"] = limite_master
                self.logger.info(f"‚úÖ L√≠mite del Master aplicado a BUSCAR_UNIVERSAL: {limite_master}")

            # Ejecutar la acci√≥n
            if current_pdf:
                action_request["current_pdf"] = current_pdf
                # Para TRANSFORMAR_PDF, agregar current_pdf a los par√°metros de la acci√≥n
                if action_request.get("accion_principal") == "TRANSFORMAR_PDF":
                    if "parametros" not in action_request:
                        action_request["parametros"] = {}
                    action_request["parametros"]["current_pdf"] = current_pdf
                    self.logger.info(f"‚úÖ current_pdf agregado a par√°metros de TRANSFORMAR_PDF: {current_pdf[:50] if current_pdf else 'None'}...")
            result = action_executor.execute_action_request(action_request)

            # üìä [RESULT] Acci√≥n ejecutada
            row_count = result.get('row_count', 0)
            action_used = result.get('action_used', 'N/A')
            self.logger.info(f"üìä [RESULT] {row_count} resultados encontrados")

            return result

        except Exception as e:
            self.logger.error(f"Error ejecutando acci√≥n seleccionada: {e}")
            return {
                "success": False,
                "data": [],
                "row_count": 0,
                "action_used": "ERROR",
                "message": f"Error interno: {str(e)}"
            }

    def _parse_action_response(self, response: str) -> Optional[Dict[str, Any]]:
        """Parsea la respuesta JSON del LLM para selecci√≥n de acciones"""
        try:
            import json
            import re

            # Limpiar la respuesta
            clean_response = response.strip()

            # Buscar JSON en la respuesta
            json_patterns = [
                r'```json\s*(.*?)\s*```',
                r'```\s*(.*?)\s*```',
                r'(\{.*?\})'
            ]

            for pattern in json_patterns:
                matches = re.findall(pattern, clean_response, re.DOTALL)
                if matches:
                    try:
                        action_request = json.loads(matches[0])
                        return action_request
                    except json.JSONDecodeError:
                        continue

            # Si no encuentra JSON, intentar parsear directamente
            try:
                action_request = json.loads(clean_response)
                return action_request
            except json.JSONDecodeError:
                return None

        except Exception as e:
            self.logger.error(f"Error parseando respuesta de acci√≥n: {e}")
            return None

    # ‚úÖ PLANTILLAS SQL ELIMINADAS - INTEGRADAS EN PROMPTS DEL PROMPTMANAGER

    def _process_continuation_with_master_guidance(self, user_query: str, conversation_stack: list) -> Optional[Dict[str, Any]]:
        """
        üéØ PROCESA CONTINUACI√ìN SIGUIENDO INSTRUCCIONES DEL MASTER
        Master ya resolvi√≥ el contexto, Student solo ejecuta
        """
        try:
            self.logger.info("üéØ PROCESANDO CONTINUACI√ìN CON GU√çA DEL MASTER")

            # Obtener informaci√≥n del Master
            master_intention = getattr(self, 'master_intention', {})
            detected_entities = master_intention.get('detected_entities', {})
            sub_intention = master_intention.get('sub_intention', '')

            # üéØ CASO 1: MASTER RESOLVI√ì ALUMNO ESPEC√çFICO
            alumno_resuelto = detected_entities.get('alumno_resuelto')
            if alumno_resuelto:
                self.logger.info(f"‚úÖ MASTER RESOLVI√ì ALUMNO: {alumno_resuelto}")
                # üîß DEVOLVER ACTION_REQUEST, NO RESULTADO EJECUTADO
                action_request = self._create_action_request_for_resolved_student(sub_intention, alumno_resuelto, detected_entities)
                self.logger.info(f"üéØ [DEBUG] Action request creado en _process_continuation_with_master_guidance: {action_request}")
                return action_request

            # üóëÔ∏è ELIMINADO: L√≥gica hardcodeada de referencias posicionales
            # RAZ√ìN: VIOLA PRINCIPIO MASTER-STUDENT - Student no debe tomar decisiones hardcodeadas
            # El Master ya maneja todas las referencias con LLM sem√°ntico

            # üéØ CASO 3: USAR BUSCAR_UNIVERSAL CON CONTEXTO PARA CONTINUACI√ìN
            self.logger.info("üîÑ USANDO BUSCAR_UNIVERSAL CON CONTEXTO PARA CONTINUACI√ìN")

            # Crear action_request directamente para evitar bucle infinito
            # Usar BUSCAR_UNIVERSAL con los IDs del contexto
            if conversation_stack:
                ultimo_nivel = conversation_stack[-1]
                context_data = ultimo_nivel.get('data', [])

                if context_data:
                    # Extraer IDs del contexto
                    ids = []
                    for item in context_data:
                        if isinstance(item, dict) and item.get('id'):
                            ids.append(str(item['id']))

                    if ids:
                        # üîß USAR FILTROS DIN√ÅMICOS DEL MASTER
                        filtros_master = self._get_master_filters()
                        filtros_adicionales = self._convert_master_filters_to_sql(filtros_master)

                        # üîß OBTENER L√çMITE DEL MASTER
                        limite_master = self._get_master_limit()

                        action_request = {
                            'accion_principal': 'BUSCAR_UNIVERSAL',
                            'estrategia': 'simple',
                            'parametros': {
                                'criterio_principal': {
                                    'tabla': 'alumnos',
                                    'campo': 'id',
                                    'operador': 'IN',
                                    'valor': f"({','.join(ids)})"
                                }
                            },
                            'razonamiento': f"Continuaci√≥n con contexto: filtrar {len(ids)} alumnos del contexto usando filtros del Master: {filtros_master}"
                        }

                        # üîß AGREGAR FILTROS ADICIONALES SI EXISTEN
                        if filtros_adicionales:
                            action_request['parametros']['filtros_adicionales'] = filtros_adicionales
                            self.logger.info(f"‚úÖ Filtros del Master aplicados: {filtros_adicionales}")

                        # üîß AGREGAR L√çMITE SI EXISTE
                        if limite_master:
                            action_request['parametros']['limit'] = limite_master
                            self.logger.info(f"‚úÖ L√≠mite del Master aplicado: {limite_master}")

                        return action_request

            self.logger.warning("No se pudo generar action_request para continuaci√≥n con contexto")
            return None

        except Exception as e:
            self.logger.error(f"Error procesando continuaci√≥n con Master: {e}")
            return None

    def _create_action_request_for_resolved_student(self, sub_intention: str, alumno_resuelto: Dict, detected_entities: Dict) -> Optional[Dict[str, Any]]:
        """Crea action_request para alumno ya resuelto por Master (NO ejecuta)"""
        try:
            if sub_intention == 'generar_constancia':
                # Normalizar tipo de constancia
                tipo_constancia_raw = detected_entities.get('tipo_constancia', 'estudios')
                tipo_constancia = 'estudio' if tipo_constancia_raw == 'estudios' else tipo_constancia_raw

                # üéØ USAR NOMBRE COMPLETO COMO IDENTIFICADOR (Student mapea a BD)
                # ‚úÖ PRIORIZAR NOMBRE - es m√°s confiable que ID en contexto
                alumno_identificador = alumno_resuelto.get('nombre')

                if not alumno_identificador:
                    # Fallback solo si no hay nombre
                    alumno_id = alumno_resuelto.get('id')
                    if alumno_id:
                        alumno_identificador = str(alumno_id)
                    else:
                        self.logger.error(f"‚ùå alumno_resuelto no tiene nombre ni ID: {alumno_resuelto}")
                        return None

                action_request = {
                    'accion_principal': 'GENERAR_CONSTANCIA_COMPLETA',
                    'estrategia': 'simple',
                    'parametros': {
                        'alumno_identificador': alumno_identificador,
                        'tipo_constancia': tipo_constancia,
                        'incluir_foto': detected_entities.get('incluir_foto', 'false') == 'true',
                        'preview_mode': True
                    },
                    'razonamiento': f"Master resolvi√≥ alumno: {alumno_resuelto.get('nombre')} ‚Üí usando nombre completo como identificador"
                }

                return action_request

            elif sub_intention == 'transformacion_pdf':
                # üîß NUEVO: Manejar transformaci√≥n de PDF
                self.logger.info("üîÑ TRANSFORMACI√ìN PDF - Procesando con PDF cargado")

                # Normalizar tipo de constancia
                tipo_constancia_raw = detected_entities.get('tipo_constancia', 'estudios')
                tipo_constancia = 'estudio' if tipo_constancia_raw == 'estudios' else tipo_constancia_raw

                action_request = {
                    'accion_principal': 'TRANSFORMAR_PDF',  # ‚úÖ CORRECTO
                    'estrategia': 'simple',
                    'parametros': {
                        'tipo_constancia': tipo_constancia,
                        'incluir_foto': detected_entities.get('incluir_foto', 'false') == 'true',
                        'guardar_alumno': detected_entities.get('guardar_alumno', 'false') == 'true'
                    },
                    'razonamiento': f"Transformando PDF cargado a constancia de {tipo_constancia}"
                }

                return action_request

            elif sub_intention == 'busqueda_simple':
                # üéØ NUEVO: Manejar b√∫squeda simple para alumno espec√≠fico resuelto
                self.logger.info("üîç B√öSQUEDA SIMPLE - Informaci√≥n completa del alumno resuelto")
                action_request = {
                    'accion_principal': 'BUSCAR_UNIVERSAL',
                    'estrategia': 'simple',
                    'parametros': {
                        'criterio_principal': {
                            'tabla': 'alumnos',
                            'campo': 'id',
                            'operador': '=',
                            'valor': str(alumno_resuelto.get('id'))
                        }
                    },
                    'razonamiento': f"Master resolvi√≥ alumno espec√≠fico: {alumno_resuelto.get('nombre')} (ID: {alumno_resuelto.get('id')}) - Obteniendo informaci√≥n completa"
                }
                return action_request

            else:
                self.logger.warning(f"Sub-intenci√≥n no implementada para alumno resuelto: {sub_intention}")
                return None

        except Exception as e:
            self.logger.error(f"Error creando action_request para alumno resuelto: {e}")
            return None

    # üóëÔ∏è M√âTODO ELIMINADO: _execute_action_for_resolved_student
    # RAZ√ìN: M√âTODO LEGACY que causaba doble ejecuci√≥n
    # El flujo normal ya maneja todo correctamente con action_requests

   


    def _get_master_filters(self) -> list:
        """
        üß† OBTENER FILTROS DEL MASTER
        Accede a la informaci√≥n que el Master ya detect√≥ con LLM
        """
        try:
            master_intention = getattr(self, 'master_intention', {})
            if master_intention:
                detected_entities = master_intention.get('detected_entities', {})
                filtros = detected_entities.get('filtros', [])
                if filtros:
                    self.logger.info(f"üß† Filtros del Master encontrados: {filtros}")
                    return filtros

            self.logger.info("üîç No se encontraron filtros del Master")
            return []

        except Exception as e:
            self.logger.error(f"Error obteniendo filtros del Master: {e}")
            return []

    def _get_master_limit(self) -> int:
        """
        üß† OBTENER L√çMITE DE RESULTADOS DEL MASTER
        Accede al l√≠mite que el Master detect√≥ (ej: "dame 3 alumnos")
        """
        try:
            master_intention = getattr(self, 'master_intention', {})
            if master_intention:
                detected_entities = master_intention.get('detected_entities', {})
                limite = detected_entities.get('limite_resultados')
                if limite and str(limite).isdigit():
                    limite_num = int(limite)
                    self.logger.info(f"üß† L√≠mite del Master encontrado: {limite_num}")
                    return limite_num

            self.logger.info("üîç No se encontr√≥ l√≠mite del Master")
            return None

        except Exception as e:
            self.logger.error(f"Error obteniendo l√≠mite del Master: {e}")
            return None

    def _convert_master_filters_to_sql(self, filtros_master: list) -> list:
        """
        üîß CONVIERTE FILTROS DEL MASTER A FORMATO SQL
        Mapea filtros como ['grupo: A'] a [{'tabla': 'datos_escolares', 'campo': 'grupo', 'operador': '=', 'valor': 'A'}]
        """
        try:
            filtros_sql = []

            for filtro in filtros_master:
                if ':' in filtro:
                    campo, valor = filtro.split(':', 1)
                    campo = campo.strip().lower()
                    valor = valor.strip()

                    # üîß MAPEO DIN√ÅMICO DE CAMPOS USANDO FIELD_MAPPER
                    mapped_field = self.field_mapper.map_user_field_to_db(campo)
                    if mapped_field:
                        tabla = mapped_field.get('tabla', 'datos_escolares')
                        campo_db = mapped_field.get('campo', campo)
                        filtros_sql.append({
                            'tabla': tabla,
                            'campo': campo_db,
                            'operador': '=',
                            'valor': valor.upper() if campo in ['turno', 'grupo'] else valor
                        })
                        self.logger.info(f"‚úÖ Campo mapeado din√°micamente: {campo} ‚Üí {tabla}.{campo_db}")
                    else:
                        # Fallback para campos no mapeados
                        filtros_sql.append({
                            'tabla': 'datos_escolares',
                            'campo': campo,
                            'operador': '=',
                            'valor': valor.upper()
                        })
                        self.logger.warning(f"‚ö†Ô∏è Campo no mapeado, usando fallback: {campo}")

            if filtros_sql:
                self.logger.info(f"‚úÖ Filtros convertidos a SQL: {filtros_sql}")

            return filtros_sql

        except Exception as e:
            self.logger.error(f"Error convirtiendo filtros del Master a SQL: {e}")
            return []


    def _format_conversation_stack_for_llm(self, conversation_stack: list) -> str:
        """Formatea la pila conversacional para el LLM CON IDs PARA SQL"""
        if not conversation_stack:
            return "PILA VAC√çA"

        context = ""
        for i, level in enumerate(conversation_stack, 1):
            context += f"""
NIVEL {i}:
- Consulta: "{level.get('query', 'N/A')}"
- Datos disponibles: {level.get('row_count', 0)} elementos
- Esperando: {level.get('awaiting', 'N/A')}
- Timestamp: {level.get('timestamp', 'N/A')}
"""
            # üÜï MOSTRAR IDs ESPEC√çFICOS PARA SQL
            if level.get('data') and len(level.get('data', [])) > 0:
                data_items = level['data']

                # üîß VERIFICAR TIPO DE DATOS ANTES DE HACER SLICE
                if isinstance(data_items, list):
                    context += f"- Total elementos: {len(data_items)}\n"
                    context += f"- Primeros 3 elementos: {data_items[:3]}\n"
                elif isinstance(data_items, dict):
                    context += f"- Datos estructurados: {len(data_items)} campos\n"
                    context += f"- Campos disponibles: {list(data_items.keys())[:3]}\n"
                else:
                    context += f"- Datos: {type(data_items).__name__}\n"
                    context += f"- Contenido: {str(data_items)[:100]}...\n"

                # üéØ EXTRAER IDs PARA FILTROS SQL
                ids = []
                if isinstance(data_items, list):
                    for item in data_items:
                        if isinstance(item, dict) and item.get('id'):
                            ids.append(str(item['id']))
                elif isinstance(data_items, dict) and data_items.get('id'):
                    # Si data_items es un diccionario con ID directo
                    ids.append(str(data_items['id']))

                if ids:
                    # üîß MOSTRAR TODOS LOS IDs, NO SOLO LOS PRIMEROS 5
                    context += f"- IDs disponibles para filtros SQL: [{', '.join(ids)}]\n"
                    context += f"- Ejemplo SQL con contexto: WHERE a.id IN ({', '.join(ids)})\n"
                    # üéì [STUDENT] Contexto: IDs disponibles para nivel
                    self.logger.info(f"üéì [STUDENT] Contexto: {len(ids)} IDs disponibles para nivel {i}")

        return context

    def _parse_json_response(self, response: str) -> Optional[Dict[str, Any]]:
        """
        Parsea respuesta JSON del LLM
        ‚úÖ MIGRADO: Usa JSONParser centralizado
        """
        try:
            result = self.json_parser.parse_llm_response(response)

            if result:
                self.logger.debug(f"‚úÖ JSON parseado exitosamente con JSONParser")
                return result
            else:
                self.logger.warning(f"‚ùå JSONParser no pudo parsear respuesta: {response[:100]}...")
                return None

        except Exception as e:
            self.logger.error(f"Error usando JSONParser: {e}")
            return None

    def _process_selection_continuation(self, user_query: str, elemento_referenciado: int, conversation_stack: list) -> Optional[InterpretationResult]:
        """Procesa continuaci√≥n de tipo SELECCI√ìN (ej: 'del quinto', 'n√∫mero 3')"""
        try:
            # Obtener el √∫ltimo nivel con datos de lista
            ultimo_nivel = None
            for level in reversed(conversation_stack):
                if level.get('data') and len(level.get('data', [])) > 0:
                    ultimo_nivel = level
                    break

            if not ultimo_nivel:
                return InterpretationResult(
                    action="continuacion_error",
                    parameters={
                        "error": "No hay datos de lista disponibles en la pila conversacional",
                        "message": "No encuentro una lista previa para hacer la selecci√≥n. ¬øPodr√≠as hacer una nueva consulta?"
                    },
                    confidence=0.3
                )

            # Verificar que el elemento existe
            datos = ultimo_nivel.get('data', [])
            if not elemento_referenciado or elemento_referenciado < 1 or elemento_referenciado > len(datos):
                return InterpretationResult(
                    action="continuacion_error",
                    parameters={
                        "error": f"Elemento {elemento_referenciado} no existe en la lista",
                        "message": f"La lista tiene {len(datos)} elementos. ¬øPodr√≠as especificar un n√∫mero entre 1 y {len(datos)}?"
                    },
                    confidence=0.3
                )

            # Obtener el elemento seleccionado (√≠ndice base 1)
            elemento_seleccionado = datos[elemento_referenciado - 1]

            # üîß ELIMINADO: Detecci√≥n hardcodeada de constancias
            # RAZ√ìN: VIOLA PRINCIPIO - Student no debe interpretar intenciones
            # El Master ya detect√≥ la intenci√≥n y tipo de constancia

            # üéØ USAR INFORMACI√ìN DEL MASTER DIRECTAMENTE
            detected_entities = self.master_intention.get('detected_entities', {})
            tipo_constancia = detected_entities.get('tipo_constancia', 'estudio')

            self.logger.info(f"üéØ USANDO TIPO DE CONSTANCIA DEL MASTER: {tipo_constancia}")
            self.logger.info(f"   - Alumno seleccionado: {elemento_seleccionado.get('nombre', 'N/A')}")

            # üîß OBTENER DATOS COMPLETOS DEL ALUMNO (incluyendo ID)
            alumno_completo = self._get_complete_student_data(elemento_seleccionado)

            if not alumno_completo:
                    return InterpretationResult(
                        action="constancia_error",
                        parameters={
                            "message": f"‚ùå No se pudieron obtener los datos completos de {elemento_seleccionado.get('nombre', 'N/A')}",
                            "error": "incomplete_student_data"
                        },
                        confidence=0.3
                    )

            # üöÄ GENERAR CONSTANCIA DIRECTAMENTE (SIN SQL)
            self.logger.info("üöÄ GENERANDO CONSTANCIA DIRECTAMENTE DESDE SELECCI√ìN")
            return self._generate_constancia_for_student(alumno_completo, tipo_constancia, user_query)

        except Exception as e:
            self.logger.error(f"Error en selecci√≥n: {e}")
            return None



    def _identify_student_using_master_entities(self, context, conversation_stack: list) -> Optional[Dict[str, Any]]:
        """
        üéØ IDENTIFICA ALUMNO USANDO ENTIDADES DEL MASTER

        Usa la informaci√≥n que ya detect√≥ el Master en lugar de hacer extracci√≥n propia.
        Esta es la forma correcta de colaboraci√≥n Master-Student.
        """
        try:
            # üéØ OBTENER ENTIDADES DEL MASTER
            intention_info = getattr(context, 'intention_info', {})
            detected_entities = intention_info.get('detected_entities', {})
            nombres_master = detected_entities.get('nombres', [])

            if not nombres_master:
                self.logger.info("‚ùå Master no detect√≥ nombres espec√≠ficos")
                return None

            nombre_buscado = nombres_master[0]  # Primer nombre detectado por Master
            self.logger.info(f"üéØ Master detect√≥ nombre: '{nombre_buscado}'")

            # üîç BUSCAR EN EL CONTEXTO CONVERSACIONAL
            if not conversation_stack:
                self.logger.warning("‚ùå No hay contexto conversacional disponible")
                return None

            # Buscar en el √∫ltimo nivel del contexto
            ultimo_nivel = conversation_stack[-1]
            context_data = ultimo_nivel.get('data', [])

            if not context_data:
                self.logger.warning("‚ùå No hay datos en el contexto")
                return None

            # üéØ BUSCAR COINCIDENCIA POR NOMBRE EN EL CONTEXTO
            nombre_buscado_lower = nombre_buscado.lower()

            for alumno in context_data:
                alumno_normalizado = self._normalize_student_data_structure(alumno)
                if not alumno_normalizado:
                    continue

                nombre_alumno = alumno_normalizado.get('nombre', '').lower()

                # Buscar coincidencia parcial (nombre o apellido)
                if nombre_buscado_lower in nombre_alumno:
                    self.logger.info(f"‚úÖ COINCIDENCIA ENCONTRADA: '{nombre_buscado}' ‚Üí {alumno_normalizado.get('nombre')}")
                    return alumno_normalizado

            self.logger.warning(f"‚ùå No se encontr√≥ '{nombre_buscado}' en el contexto de {len(context_data)} alumnos")
            return None

        except Exception as e:
            self.logger.error(f"Error identificando alumno con entidades del Master: {e}")
            return None

    def _identify_student_from_context(self, user_query: str, conversation_stack: list) -> Optional[Dict[str, Any]]:
        """
        Identifica al alumno correcto usando el contexto conversacional y referencias en la consulta
        üÜï MIGRADO: Usa StudentIdentifier centralizado (Refactorizaci√≥n completada)
        """
        try:
            result = self.student_identifier.identify_student_from_context(
                user_query, conversation_stack
            )

            if result:
                self.logger.debug(f"‚úÖ Alumno identificado exitosamente con StudentIdentifier: {result.get('nombre', 'N/A')}")
                return result
            else:
                self.logger.warning(f"‚ùå StudentIdentifier no pudo identificar alumno")
                return None

        except Exception as e:
            self.logger.error(f"Error usando StudentIdentifier: {e}")
            return None



    def _normalize_student_data_structure(self, item: Dict) -> Optional[Dict]:
        """
        Normaliza diferentes estructuras de datos de alumnos a un formato est√°ndar
        ‚úÖ MIGRADO: Usa DataNormalizer centralizado
        """
        try:
            result = self.data_normalizer.normalize_student_data(item)

            if result:
                self.logger.debug(f"‚úÖ Datos normalizados exitosamente con DataNormalizer: {result.get('nombre', 'N/A')}")
                return result
            else:
                self.logger.warning(f"‚ùå DataNormalizer no pudo normalizar estructura: {list(item.keys())}")
                return None

        except Exception as e:
            self.logger.error(f"Error usando DataNormalizer: {e}")
            return None

    def _get_complete_student_data(self, alumno_parcial: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """Obtiene los datos completos del alumno desde la base de datos"""
        try:
            # Si ya tiene ID, verificar que tenga todos los datos necesarios
            if alumno_parcial.get('id'):
                self.logger.info(f"‚úÖ Alumno ya tiene ID: {alumno_parcial.get('id')}")
                return alumno_parcial

            # Si no tiene ID, buscar por nombre
            nombre_alumno = alumno_parcial.get('nombre', '')
            if not nombre_alumno:
                self.logger.warning("‚ùå No se puede buscar alumno sin nombre")
                return None

            self.logger.info(f"üîç Buscando datos completos para: {nombre_alumno}")

            from app.core.service_provider import ServiceProvider
            service_provider = ServiceProvider.get_instance()
            alumno_service = service_provider.alumno_service

            # Buscar alumno por nombre exacto
            alumnos_encontrados = alumno_service.buscar_alumnos(nombre_alumno)

            if not alumnos_encontrados:
                self.logger.warning(f"‚ùå No se encontr√≥ alumno con nombre: {nombre_alumno}")
                return None

            # Si hay m√∫ltiples coincidencias, buscar coincidencia exacta
            for alumno in alumnos_encontrados:
                alumno_dict = alumno.to_dict() if hasattr(alumno, 'to_dict') else alumno
                if alumno_dict.get('nombre', '').upper() == nombre_alumno.upper():
                    self.logger.info(f"‚úÖ Datos completos obtenidos para: {alumno_dict.get('nombre')} (ID: {alumno_dict.get('id')})")
                    return alumno_dict

            # Si no hay coincidencia exacta, tomar el primero
            primer_alumno = alumnos_encontrados[0]
            alumno_dict = primer_alumno.to_dict() if hasattr(primer_alumno, 'to_dict') else primer_alumno

            self.logger.info(f"‚úÖ Usando primer resultado: {alumno_dict.get('nombre')} (ID: {alumno_dict.get('id')})")
            return alumno_dict

        except Exception as e:
            self.logger.error(f"Error obteniendo datos completos del alumno: {e}")
            return None

    def _generate_constancia_for_student(self, alumno: Dict, tipo_constancia: str, user_query: str) -> InterpretationResult:
        """
        Genera constancia directamente para un alumno espec√≠fico
        ‚úÖ MIGRADO: Usa ConstanciaProcessor centralizado
        """
        try:
            result = self.constancia_processor.process_constancia_request(
                alumno, tipo_constancia, user_query
            )

            if result:
                self.logger.debug(f"‚úÖ Constancia procesada exitosamente con ConstanciaProcessor: {result.action}")
                return result
            else:
                self.logger.warning(f"‚ùå ConstanciaProcessor no pudo procesar constancia")
                return InterpretationResult(
                    action="constancia_error",
                    parameters={
                        "message": f"‚ùå Error procesando constancia para {alumno.get('nombre', 'N/A')}",
                        "error": "processor_failed"
                    },
                    confidence=0.3
                )

        except Exception as e:
            self.logger.error(f"Error usando ConstanciaProcessor: {e}")
            return InterpretationResult(
                action="constancia_error",
                parameters={
                    "message": f"‚ùå Error interno procesando constancia para {alumno.get('nombre', 'N/A')}",
                    "error": "internal_error"
                },
                confidence=0.1
            )



    def _generate_unified_continuation_response(self, user_query: str, continuation_type: str,
                                              ultimo_nivel: Dict, conversation_stack: list) -> str:
        """
        ‚úÖ IMPLEMENTADO: Respuesta unificada para continuaciones usando PromptManager

        REEMPLAZA:
        - _generate_action_response()
        - _generate_selection_response()

        TIPOS:
        - action: "constancia para √©l", "CURP de ese"
        - selection: "del segundo", "n√∫mero 5"
        - confirmation: "s√≠", "correcto"
        """
        try:
            # üÜï USAR PROMPT MANAGER para respuesta unificada
            continuation_prompt = self.prompt_manager.get_unified_continuation_prompt(
                user_query, continuation_type, ultimo_nivel, conversation_stack
            )

            response = self.gemini_client.send_prompt_sync(continuation_prompt)
            # üßπ SIN FALLBACKS - Si no hay respuesta, que falle claramente
            return response.strip()

        except Exception as e:
            self.logger.error(f"Error en respuesta unificada: {e}")
            # üßπ SIN FALLBACKS - Que falle claramente para debugging
            raise

    def _generate_sql_for_action_continuation(self, user_query: str, ultimo_nivel: Dict) -> Optional[str]:
        """
        Genera SQL para continuaci√≥n bas√°ndose en datos previos
        ‚úÖ USA PromptManager centralizado
        """
        try:
            previous_data = ultimo_nivel.get('data', [])
            previous_query = ultimo_nivel.get('query', '')

            if not previous_data:
                return None

            # üÜï USAR PROMPT MANAGER en lugar de prompt hardcodeado
            continuation_sql_prompt = self.prompt_manager.get_sql_continuation_prompt(
                user_query, previous_data, previous_query, self._get_sql_context()
            )

            response = self.gemini_client.send_prompt_sync(continuation_sql_prompt)

            if response:
                # Limpiar y extraer SQL
                sql_query = response.strip()

                # Remover markdown si existe
                if "```sql" in sql_query:
                    sql_query = sql_query.split("```sql")[1].split("```")[0].strip()
                elif "```" in sql_query:
                    sql_query = sql_query.split("```")[1].strip()

                self.logger.debug(f"SQL de continuaci√≥n generado: {sql_query}")
                return sql_query

            return None

        except Exception as e:
            self.logger.error(f"Error generando SQL de continuaci√≥n: {e}")
            return None





    def _generate_initial_query_response(self, user_query: str, row_count: int,
                                       data: List[Dict], espera_continuacion: bool,
                                       conversation_stack: list = None) -> str:
        """
        üéØ GENERA RESPUESTA CONVERSACIONAL CON CONTEXTO CONVERSACIONAL

        Args:
            user_query: Consulta del usuario
            row_count: Cantidad de resultados
            data: Datos encontrados
            espera_continuacion: Si se espera continuaci√≥n
            conversation_stack: Pila conversacional para contexto

        Returns:
            Respuesta conversacional natural con referencia al contexto
        """
        try:
            user_lower = user_query.lower()
            conversation_stack = conversation_stack or []

            is_follow_up = False  # Master ya decidi√≥ la estrategia

            # üîç DEBUG: Logging simplificado
            self.logger.info(f"üîç DEBUG - _generate_initial_query_response:")
            self.logger.info(f"   - Query: '{user_query}'")
            self.logger.info(f"   - conversation_stack length: {len(conversation_stack)}")
            self.logger.info(f"   - Master ya decidi√≥ estrategia, Student obedece")

            if is_follow_up and conversation_stack:
                # üéØ RESPUESTA PARA CONSULTA DE SEGUIMIENTO CON CONTEXTO
                self.logger.info(f"üéØ USANDO _generate_follow_up_response")
                return self._generate_follow_up_response(user_query, row_count, data, conversation_stack)

            # üéØ DETECTAR TIPO DE CONSULTA Y GENERAR RESPUESTA APROPIADA

            if row_count == 0:
                # Sin resultados
                if "grado" in user_lower:
                    return "No encontr√© alumnos en ese grado. ¬øQuiz√°s te refieres a otro grado? ü§î"
                else:
                    return "No encontr√© alumnos que coincidan con tu b√∫squeda. ¬øPodr√≠as ser m√°s espec√≠fico? üîç"

            elif row_count == 1:
                # üîç VERIFICAR SI ES RESULTADO DE CONTEO O ALUMNO INDIVIDUAL
                resultado = data[0] if data else {}

                # ‚úÖ DETECTAR RESULTADO DE CONTEO
                if isinstance(resultado, dict) and 'total' in resultado:
                    cantidad = resultado['total']

                    # üîß RESPUESTA COMPLETAMENTE DIN√ÅMICA
                    response = f"üìä Total de alumnos encontrados: **{cantidad}**"

                    # Agregar sugerencia √∫til din√°mica
                    if cantidad > 0:
                        response += f"\n\nüí° Si necesitas ver la lista de estos alumnos, puedes preguntarme: 'mu√©strame esos alumnos'"

                    return response

                # ‚úÖ ALUMNO INDIVIDUAL (comportamiento original)
                else:
                    alumno = resultado
                    nombre = alumno.get('nombre', 'el alumno')
                    grado = alumno.get('grado', 'N/A')

                    tiene_calificaciones = (alumno.get('calificaciones') and
                                          alumno.get('calificaciones') not in ['', '[]', None])

                    if tiene_calificaciones:
                        response = f"Encontr√© a **{nombre}** de {grado}¬∞ grado con calificaciones registradas. üìä"
                        response += "\n\n¬øTe gustar√≠a generar una constancia o necesitas m√°s informaci√≥n? üìÑ"
                    else:
                        response = f"Encontr√© a **{nombre}** de {grado}¬∞ grado, pero a√∫n no tiene calificaciones registradas. üìù"
                        response += "\n\n¬øTe gustar√≠a generar una constancia de estudios? üìÑ"

                    return response

            else:
                # M√∫ltiples alumnos - VERIFICAR SI ES SEGUIMIENTO PRIMERO
                if is_follow_up and conversation_stack:
                    # üéØ ES CONSULTA DE SEGUIMIENTO - Usar respuesta contextual
                    return self._generate_follow_up_response(user_query, row_count, data, conversation_stack)
                else:
                    # üéØ ES CONSULTA INICIAL - Detectar contexto espec√≠fico
                    response = self._generate_specific_context_response(user_query, row_count, data)

                    # Agregar sugerencias basadas en la cantidad SOLO para consultas iniciales
                    if espera_continuacion:
                        if row_count <= 10:
                            response += "\n\n¬øNecesitas informaci√≥n espec√≠fica de alguno de ellos o quieres generar constancias? ü§î"
                        elif row_count <= 30:
                            response += "\n\n¬øQuieres que filtre esta lista por alg√∫n criterio espec√≠fico? Por ejemplo, por calificaciones, turno, o grupo. üîç"
                        else:
                            response += "\n\n¬øTe ayudo a filtrar esta lista? Puedo buscar por calificaciones, turno, grupo, o cualquier otro criterio. üîç"
                    else:
                        response += "\n\n¬øNecesitas algo m√°s? üí≠"

                    return response

        except Exception as e:
            self.logger.error(f"Error generando respuesta inicial: {e}")
            # Fallback a respuesta b√°sica
            return f"‚úÖ Encontr√© {row_count} alumnos que cumplen con tu consulta."

    def _get_sql_context(self) -> str:
        """Obtiene el contexto SQL (con cache)"""
        if self._sql_context is None:
            self._sql_context = self.database_analyzer.generate_sql_context()
        return self._sql_context



    def _parse_intention_response(self, intention_response: str) -> Optional[Dict[str, Any]]:
        """Parsea la respuesta de detecci√≥n de intenci√≥n"""
        try:
            # Limpiar la respuesta
            clean_response = intention_response.strip()

            # Buscar JSON en la respuesta
            json_patterns = [
                r'```json\s*(.*?)\s*```',
                r'```\s*(.*?)\s*```',
                r'(\{.*?\})'
            ]

            for pattern in json_patterns:
                matches = re.findall(pattern, clean_response, re.DOTALL)
                if matches:
                    try:
                        import json
                        intention = json.loads(matches[0])
                        return intention
                    except json.JSONDecodeError:
                        continue

            # Si no encuentra JSON, intentar parsear directamente
            try:
                import json
                intention = json.loads(clean_response)
                return intention
            except json.JSONDecodeError:
                return None

        except Exception as e:
            return None

    def _validate_and_generate_response(self, user_query: str, sql_query: str, data: List[Dict], row_count: int, conversation_stack: list = None) -> Optional[Dict]:
        """
        PROMPT 3 SIMPLIFICADO: BUSCAR_UNIVERSAL ya hizo el trabajo, solo generar respuesta
        CON CONTEXTO CONVERSACIONAL para respuestas de seguimiento
        """
        try:
            # üéØ BUSCAR_UNIVERSAL YA FILTR√ì CORRECTAMENTE - NO APLICAR FILTROS ADICIONALES
            filtered_data = data

            # üéì [STUDENT] B√∫squeda completada exitosamente

            # BUSCAR_UNIVERSAL siempre resuelve la consulta correctamente
            # No aplicar filtros adicionales que puedan interferir

            # Usar los datos filtrados para el resto del proceso
            final_data = filtered_data
            final_row_count = len(filtered_data)

            # üéØ AUTO-REFLEXI√ìN INTELIGENTE SIN LLM EXTRA (r√°pida y efectiva)

            # Determinar si espera continuaci√≥n basado en el tipo de consulta y resultados
            espera_continuacion, tipo_esperado, nota_estrategica = self._determine_continuation_expectation(
                user_query, final_row_count, final_data
            )

            # üéØ GENERAR RESPUESTA CONVERSACIONAL CON CONTEXTO CORRECTO
            # USAR conversation_stack pasado como par√°metro (viene del MessageProcessor)
            # self.conversation_stack NO EXISTE en StudentQueryInterpreter
            context_stack = conversation_stack if conversation_stack is not None else []

            # üéì [STUDENT] Validando y generando respuesta

            # üéØ STUDENT RETORNA DATOS T√âCNICOS PARA EL MASTER
            technical_summary = f"Consulta procesada: {final_row_count} resultados obtenidos"

            self.logger.info(f"üéØ Datos t√©cnicos preparados para Master: {final_row_count} resultados")

            return {
                "technical_response": technical_summary,  # üéØ RESUMEN T√âCNICO PARA EL MASTER
                "reflexion_conversacional": {
                    "espera_continuacion": espera_continuacion,
                    "tipo_esperado": tipo_esperado,
                    "nota_para_master": nota_estrategica,  # üéØ NOTA ESTRAT√âGICA DETALLADA
                    "datos_recordar": {
                        "query": user_query,
                        "data": final_data,  # üîß USAR TODOS LOS DATOS para contexto conversacional
                        "row_count": final_row_count,
                        "context": f"Lista de {final_row_count} alumnos disponible",
                        "filter_applied": "N/A"
                    },
                    "razonamiento": nota_estrategica  # Mantener compatibilidad
                },
                "data": final_data,  # üéØ DATOS COMPLETOS PARA EL MASTER
                "row_count": final_row_count,
                "sql_executed": sql_query,  # üéØ SQL PARA QUE MASTER SEPA QU√â CRITERIOS SE USARON
                "user_query": user_query,  # üéØ CONSULTA ORIGINAL
                "query_type": "search" if final_row_count > 0 else "no_results",
                "ambiguity_level": "high" if final_row_count > 10 else "low" if final_row_count <= 3 else "medium"
            }

        except Exception as e:
            self.logger.error(f"Error en validaci√≥n con auto-reflexi√≥n: {e}")
            return None

    def _determine_continuation_expectation(self, user_query: str, row_count: int, data: List[Dict]) -> tuple:
        """
        üß† GENERA NOTA ESTRAT√âGICA DETALLADA PARA MASTER

        Analiza la consulta y resultados para generar informaci√≥n estrat√©gica
        que ayude a Master a detectar continuaciones inteligentemente.

        Returns:
            tuple: (espera_continuacion: bool, tipo_esperado: str, nota_estrategica: str)
        """
        try:
            # üéØ GENERAR NOTA ESTRAT√âGICA DETALLADA PARA MASTER

            # Analizar datos para generar informaci√≥n estrat√©gica
            grados_disponibles = set()
            grupos_disponibles = set()
            turnos_disponibles = set()

            for alumno in data[:10]:  # Analizar primeros 10 para eficiencia
                if 'grado' in alumno and alumno['grado']:
                    grados_disponibles.add(str(alumno['grado']))
                if 'grupo' in alumno and alumno['grupo']:
                    grupos_disponibles.add(str(alumno['grupo']))
                if 'turno' in alumno and alumno['turno']:
                    turnos_disponibles.add(str(alumno['turno']))

            # Construir nota estrat√©gica detallada
            if row_count >= 2:
                if row_count <= 10:
                    nota_estrategica = f"""Mostr√© lista de {row_count} alumnos. Usuario podr√≠a querer:
- POSICI√ìN: 'del primero', 'el √∫ltimo', 'del cuarto'
- CONSTANCIA: 'constancia para [nombre/posici√≥n]'
- FILTRO: 'los de [grado/grupo/turno]'
- CONTEO: 'cu√°ntos son de [criterio]'
Grados disponibles: {sorted(grados_disponibles)}
Grupos disponibles: {sorted(grupos_disponibles)}
Turnos disponibles: {sorted(turnos_disponibles)}"""
                    return (True, "selection", nota_estrategica)

                elif row_count <= 50:
                    nota_estrategica = f"""Mostr√© {row_count} alumnos (lista mediana). Usuario podr√≠a querer:
- FILTRAR: 'de esos los de [grado/grupo/turno espec√≠fico]'
- ESTAD√çSTICAS: 'cu√°ntos son por grado', 'estad√≠sticas de ese grupo'
- CONSTANCIA: 'constancia para [criterio espec√≠fico]'
- AN√ÅLISIS: 'distribuci√≥n por [criterio]'
Datos disponibles: grados {sorted(grados_disponibles)}, grupos {sorted(grupos_disponibles)}, turnos {sorted(turnos_disponibles)}"""
                    return (True, "filter", nota_estrategica)

                else:
                    nota_estrategica = f"""Mostr√© {row_count} alumnos (lista grande). Usuario muy probablemente querr√°:
- FILTRAR: 'de esos los de [criterio]' para reducir cantidad
- ESTAD√çSTICAS: 'cu√°ntos son por [dimensi√≥n]'
- AN√ÅLISIS: 'distribuci√≥n', 'estad√≠sticas del grupo'
Dimensiones disponibles: {len(grados_disponibles)} grados, {len(grupos_disponibles)} grupos, {len(turnos_disponibles)} turnos"""
                    return (True, "filter", nota_estrategica)

            elif row_count == 1:
                alumno = data[0] if data else {}
                nombre = alumno.get('nombre', 'alumno')
                nota_estrategica = f"""Encontr√© 1 alumno espec√≠fico ({nombre}). Usuario podr√≠a querer:
- CONSTANCIA: 'constancia para √©l/ella', 'generar constancia'
- INFORMACI√ìN: 'datos completos', 'informaci√≥n adicional'
- ACCI√ìN: 'CURP de ese alumno', 'grado de ese estudiante'
Datos disponibles: informaci√≥n completa del alumno"""
                return (True, "action", nota_estrategica)

            elif row_count == 0:
                nota_estrategica = f"""No encontr√© resultados para '{user_query}'. Usuario probablemente:
- REFORMULAR√Å: con otros criterios de b√∫squeda
- PREGUNTAR√Å: por ayuda o sugerencias
- CAMBIAR√Å: estrategia de b√∫squeda"""
                return (False, "none", nota_estrategica)



            # üéØ RESPUESTA DIN√ÅMICA BASADA EN RESULTADOS
            nota_estrategica = f"""Consulta resuelta ({row_count} resultados). Usuario podr√≠a:
- Hacer nueva consulta independiente
- Continuar con estos resultados si son √∫tiles
- Solicitar m√°s informaci√≥n espec√≠fica
Datos disponibles: {row_count} elementos procesados"""
            # Permitir continuaci√≥n por defecto (Master decidir√° si es apropiado)

            # Caso por defecto
            nota_estrategica = f"""Consulta general con {row_count} resultados. Contexto disponible para:
- REFERENCIAS: 'de esos', 'del grupo anterior', 'de la lista'
- FILTROS: aplicar criterios adicionales
- ACCIONES: sobre elementos espec√≠ficos
Mantengo contexto activo para posibles continuaciones."""
            return (True, "analysis", nota_estrategica)

        except Exception as e:
            self.logger.error(f"Error determinando expectativa de continuaci√≥n: {e}")
            # Fallback conservador: siempre esperar continuaci√≥n
            return (True, "analysis",
                   f"Error en an√°lisis, pero mantengo contexto disponible para {row_count} resultados.")

    def _format_data_for_validation_prompt(self, data: List[Dict], row_count: int, sql_query: str) -> str:
        """
        Formatea los datos espec√≠ficamente para el prompt de validaci√≥n
        """
        try:
            # Detectar si es una consulta COUNT
            if 'count(' in sql_query.lower() or any(key.lower() in ['total', 'count(*)', 'count', 'cantidad'] for row in data for key in row.keys()):
                if data and len(data) > 0:
                    first_row = data[0]
                    for key, value in first_row.items():
                        if key.lower() in ['total', 'count(*)', 'count', 'cantidad']:
                            return f"""
TIPO DE CONSULTA: COUNT (conteo)
RESULTADO NUM√âRICO: {value}
INTERPRETACI√ìN: La consulta devolvi√≥ un conteo de {value} alumnos
DATOS BRUTOS: {data}
"""

            # Para consultas SELECT normales
            return f"""
TIPO DE CONSULTA: SELECT (listado)
N√öMERO DE REGISTROS: {row_count}
DATOS OBTENIDOS: {data if row_count <= 15 else data[:10]}
{"... y " + str(row_count - 10) + " registros adicionales" if row_count > 10 else ""}
"""

        except Exception as e:
            self.logger.error(f"Error formateando datos para validaci√≥n: {e}")
            return f"DATOS: {row_count} registros obtenidos"

    def _extract_sql_from_response(self, response: str) -> Optional[str]:
        """Extrae SQL de la respuesta del LLM"""
        try:
            # Limpiar la respuesta
            clean_response = response.strip()

            # Buscar SQL en markdown
            if "```sql" in clean_response:
                sql_query = clean_response.split("```sql")[1].split("```")[0].strip()
                return sql_query
            elif "```" in clean_response:
                sql_query = clean_response.split("```")[1].strip()
                return sql_query
            else:
                # Asumir que toda la respuesta es SQL
                return clean_response

        except Exception as e:
            self.logger.error(f"Error extrayendo SQL: {e}")
            return None


    def _process_constancia_as_direct_action(self, context) -> Optional[InterpretationResult]:
        """
        üéØ CONSTANCIA COMO ACCI√ìN DIRECTA - SIN C√ìDIGO REDUNDANTE
        Usa directamente las entidades del Master y delega al ConstanciaProcessor
        """
        try:
            # üéØ OBTENER ENTIDADES DEL MASTER (YA DETECTADAS)
            intention_info = getattr(context, 'intention_info', {})
            detected_entities = intention_info.get('detected_entities', {})

            if not detected_entities:
                self.logger.error("‚ùå No hay entidades detectadas del Master")
                return InterpretationResult(
                    action="constancia_error",
                    parameters={"message": "‚ùå Error: No se detectaron entidades para la constancia"},
                    confidence=0.1
                )

            # üéØ EXTRAER INFORMACI√ìN NECESARIA
            nombre_alumno = detected_entities.get('nombres', [None])[0] if detected_entities.get('nombres') else None
            tipo_constancia = detected_entities.get('tipo_constancia', 'estudio')

            if not nombre_alumno:
                return InterpretationResult(
                    action="constancia_error",
                    parameters={"message": "‚ùå No se especific√≥ el nombre del alumno"},
                    confidence=0.1
                )

            # üéØ BUSCAR ALUMNO EN BASE DE DATOS
            alumno = self._find_student_by_name(nombre_alumno)
            if not alumno:
                return InterpretationResult(
                    action="constancia_error",
                    parameters={
                        "message": f"No encontr√© al alumno '{nombre_alumno}'. Verifica el nombre e intenta nuevamente.",
                        "error": "student_not_found"
                    },
                    confidence=0.3
                )

            # üéØ NORMALIZAR TIPO DE CONSTANCIA
            tipo_normalizado = self._normalize_constancia_type(tipo_constancia)

            # üöÄ DELEGAR DIRECTAMENTE AL CONSTANCIA PROCESSOR
            self.logger.info(f"üöÄ DELEGANDO A CONSTANCIA PROCESSOR: {alumno.get('nombre')} - {tipo_normalizado}")
            return self.constancia_processor.process_constancia_request(
                alumno, tipo_normalizado, context.user_message
            )

        except Exception as e:
            self.logger.error(f"Error en constancia como acci√≥n directa: {e}")
            return InterpretationResult(
                action="constancia_error",
                parameters={"message": "Error interno procesando la constancia"},
                confidence=0.1
            )


    def _normalize_constancia_type(self, tipo_raw: str) -> str:
        """Normaliza el tipo de constancia a los valores esperados por el servicio"""
        if not tipo_raw:
            return "estudio"

        tipo_lower = tipo_raw.lower().strip()

        # Mapeo de variaciones a tipos v√°lidos
        tipo_mapping = {
            # Estudios/Estudio
            "estudios": "estudio",
            "estudio": "estudio",
            "de estudios": "estudio",
            "de estudio": "estudio",

            # Calificaciones
            "calificaciones": "calificaciones",
            "calificacion": "calificaciones",
            "notas": "calificaciones",
            "boleta": "calificaciones",

            # Traslado
            "traslado": "traslado",
            "transferencia": "traslado",
            "cambio": "traslado"
        }

        # Buscar coincidencia exacta
        if tipo_lower in tipo_mapping:
            normalized = tipo_mapping[tipo_lower]
            self.logger.debug(f"üîß Tipo normalizado: '{tipo_raw}' ‚Üí '{normalized}'")
            return normalized

        # Buscar coincidencia parcial
        for key, value in tipo_mapping.items():
            if key in tipo_lower:
                self.logger.debug(f"üîß Tipo normalizado (parcial): '{tipo_raw}' ‚Üí '{value}'")
                return value

        # Por defecto, estudio
        self.logger.warning(f"‚ö†Ô∏è Tipo de constancia no reconocido: '{tipo_raw}', usando 'estudio' por defecto")
        return "estudio"

    def _find_student_by_name(self, nombre: str) -> Optional[Dict[str, Any]]:
        """Busca alumno por nombre con manejo inteligente de m√∫ltiples coincidencias y tolerancia a errores"""
        try:
            from app.core.service_provider import ServiceProvider
            service_provider = ServiceProvider.get_instance()
            alumno_service = service_provider.alumno_service

            # üéØ ESTRATEGIA 1: B√∫squeda exacta
            alumnos = alumno_service.buscar_alumnos(nombre)

            if not alumnos:
                # üéØ ESTRATEGIA 2: B√∫squeda con tolerancia a errores tipogr√°ficos
                self.logger.info(f"üîç No se encontr√≥ '{nombre}', intentando b√∫squeda con tolerancia a errores...")
                alumnos = self._fuzzy_search_students(nombre, alumno_service)

            if not alumnos:
                self.logger.debug(f"‚ùå No se encontraron alumnos con '{nombre}' (incluso con tolerancia a errores)")
                return None
            elif len(alumnos) == 1:
                # ‚úÖ UNA SOLA COINCIDENCIA - PERFECTO
                self.logger.debug(f"‚úÖ Alumno √∫nico encontrado: {alumnos[0].get('nombre', 'N/A')}")
                primer_alumno = alumnos[0]
                if hasattr(primer_alumno, 'to_dict'):
                    return primer_alumno.to_dict()
                else:
                    return primer_alumno
            else:
                # üîç M√öLTIPLES COINCIDENCIAS - MANEJAR INTELIGENTEMENTE
                return self._handle_multiple_students(alumnos, nombre)

        except Exception as e:
            self.logger.error(f"Error buscando alumno: {e}")
            return None

    def _fuzzy_search_students(self, nombre_buscado: str, alumno_service) -> List:
        """B√∫squeda con tolerancia a errores tipogr√°ficos"""
        try:
            # üéØ ESTRATEGIAS DE B√öSQUEDA TOLERANTE:

            # 1. Buscar por cada palabra del nombre
            palabras = nombre_buscado.split()
            candidatos = []

            for palabra in palabras:
                if len(palabra) >= 3:  # Solo palabras de 3+ caracteres
                    resultados = alumno_service.buscar_alumnos(palabra)
                    candidatos.extend(resultados)

            # 2. Buscar variaciones comunes de nombres
            variaciones = self._generate_name_variations(nombre_buscado)
            for variacion in variaciones:
                resultados = alumno_service.buscar_alumnos(variacion)
                candidatos.extend(resultados)

            # 3. Eliminar duplicados
            alumnos_unicos = []
            ids_vistos = set()

            for alumno in candidatos:
                alumno_dict = alumno.to_dict() if hasattr(alumno, 'to_dict') else alumno
                alumno_id = alumno_dict.get('id')
                if alumno_id not in ids_vistos:
                    ids_vistos.add(alumno_id)
                    alumnos_unicos.append(alumno_dict)

            # 4. Filtrar por similitud de nombre
            if alumnos_unicos:
                alumnos_filtrados = self._filter_by_name_similarity(nombre_buscado, alumnos_unicos)
                if alumnos_filtrados:
                    self.logger.info(f"‚úÖ Encontrados {len(alumnos_filtrados)} candidatos con b√∫squeda tolerante")
                    return alumnos_filtrados

            return []

        except Exception as e:
            self.logger.error(f"Error en b√∫squeda tolerante: {e}")
            return []

    def _generate_name_variations(self, nombre: str) -> List[str]:
        """Genera variaciones comunes de nombres para b√∫squeda tolerante"""
        variaciones = []
        nombre_lower = nombre.lower()

        # Correcciones comunes de nombres
        correcciones = {
            'habriela': 'gabriela',
            'habriel': 'gabriel',
            'nataly': 'natalia',
            'nathalia': 'natalia',
            'maria': 'mar√≠a',
            'jose': 'jos√©',
            'jesus': 'jes√∫s',
            'andres': 'andr√©s',
            'adrian': 'adri√°n',
            'sebastian': 'sebasti√°n'
        }

        # Aplicar correcciones
        for error, correccion in correcciones.items():
            if error in nombre_lower:
                variacion = nombre_lower.replace(error, correccion)
                variaciones.append(variacion.title())

        # Variaciones sin acentos
        sin_acentos = nombre.replace('√°', 'a').replace('√©', 'e').replace('√≠', 'i').replace('√≥', 'o').replace('√∫', 'u')
        if sin_acentos != nombre:
            variaciones.append(sin_acentos)

        # Variaciones con acentos comunes
        con_acentos = nombre.replace('a', '√°').replace('e', '√©').replace('i', '√≠').replace('o', '√≥').replace('u', '√∫')
        if con_acentos != nombre:
            variaciones.append(con_acentos)

        return list(set(variaciones))  # Eliminar duplicados

    def _handle_multiple_students(self, alumnos: List, nombre_buscado: str) -> Optional[Dict[str, Any]]:
        """Maneja m√∫ltiples coincidencias de estudiantes de forma inteligente"""
        try:
            self.logger.info(f"üîç Encontradas {len(alumnos)} coincidencias para '{nombre_buscado}'")

            # üéØ ESTRATEGIA 1: Buscar coincidencia exacta (nombre completo)
            for alumno in alumnos:
                alumno_dict = alumno.to_dict() if hasattr(alumno, 'to_dict') else alumno
                nombre_completo = alumno_dict.get('nombre', '').upper()
                if nombre_completo == nombre_buscado.upper():
                    self.logger.info(f"‚úÖ Coincidencia exacta encontrada: {nombre_completo}")
                    return alumno_dict

            # üéØ ESTRATEGIA 2: Si hay pocas coincidencias (2-5), tomar la primera y avisar
            if len(alumnos) <= 5:
                primer_alumno = alumnos[0]
                alumno_dict = primer_alumno.to_dict() if hasattr(primer_alumno, 'to_dict') else primer_alumno

                # Crear lista de nombres para mostrar al usuario
                nombres_encontrados = []
                for alumno in alumnos[:5]:
                    alumno_temp = alumno.to_dict() if hasattr(alumno, 'to_dict') else alumno
                    nombres_encontrados.append(alumno_temp.get('nombre', 'N/A'))

                self.logger.info(f"‚ö†Ô∏è M√∫ltiples coincidencias, usando primera: {alumno_dict.get('nombre', 'N/A')}")
                self.logger.info(f"üìã Opciones encontradas: {', '.join(nombres_encontrados)}")

                # Agregar informaci√≥n de m√∫ltiples coincidencias al alumno
                alumno_dict['_multiple_matches'] = {
                    'total_found': len(alumnos),
                    'options': nombres_encontrados,
                    'selected': alumno_dict.get('nombre', 'N/A'),
                    'search_term': nombre_buscado
                }

                return alumno_dict

            # üéØ ESTRATEGIA 3: Si hay muchas coincidencias (6+), devolver informaci√≥n especial
            else:
                self.logger.warning(f"‚ùå Demasiadas coincidencias ({len(alumnos)}) para '{nombre_buscado}'. Se requiere nombre m√°s espec√≠fico.")

                # Devolver diccionario especial para indicar m√∫ltiples coincidencias
                return {
                    '_too_many_matches': True,
                    'total_found': len(alumnos),
                    'search_term': nombre_buscado,
                    'message': f"Encontr√© {len(alumnos)} estudiantes con '{nombre_buscado}'. Por favor, s√© m√°s espec√≠fico con el nombre."
                }

        except Exception as e:
            self.logger.error(f"Error manejando m√∫ltiples estudiantes: {e}")
            # En caso de error, devolver el primero como fallback
            primer_alumno = alumnos[0] if alumnos else None
            if primer_alumno:
                return primer_alumno.to_dict() if hasattr(primer_alumno, 'to_dict') else primer_alumno
            return None


    def _generate_constancia_response_with_reflection(self, alumno: Dict, tipo_constancia: str, data: Dict) -> Optional[Dict]:
        """Genera respuesta con auto-reflexi√≥n espec√≠fica para constancias"""
        try:
            response_prompt = f"""
Eres un comunicador experto para sistema escolar con CAPACIDAD DE AUTO-REFLEXI√ìN especializada en CONSTANCIAS.

CONTEXTO DE CONSTANCIA GENERADA:
- Alumno: {alumno.get('nombre', 'N/A')}
- Tipo: {tipo_constancia}
- Estado: Vista previa generada exitosamente
- Archivo: {data.get('ruta_archivo', 'N/A')}

INSTRUCCIONES PRINCIPALES:
1. Genera respuesta profesional informando sobre la vista previa
2. üÜï AUTO-REFLEXIONA espec√≠ficamente sobre constancias

üß† AUTO-REFLEXI√ìN ESPECIALIZADA EN CONSTANCIAS:
Despu√©s de generar tu respuesta, reflexiona como un secretario escolar experto en documentos:

AN√ÅLISIS REFLEXIVO ESPEC√çFICO:
- ¬øAcabo de mostrar una vista previa de constancia que requiere confirmaci√≥n del usuario?
- ¬øEl usuario necesitar√° decidir qu√© hacer con esta constancia (confirmar, abrir, cancelar)?
- ¬øDeber√≠a recordar los datos de esta constancia para futuras acciones?
- ¬øQu√© tipo de respuesta esperar√≠a t√≠picamente despu√©s de mostrar una vista previa?

DECISI√ìN CONVERSACIONAL PARA CONSTANCIAS:
Si tu respuesta espera continuaci√≥n, especifica:
- Tipo esperado: "confirmation" (confirmar/abrir/cancelar)
- Datos a recordar: informaci√≥n de la constancia y alumno
- Razonamiento: por qu√© esperas confirmaci√≥n

FORMATO DE RESPUESTA:
{{
  "respuesta_usuario": "Tu respuesta profesional sobre la vista previa aqu√≠",
  "reflexion_conversacional": {{
    "espera_continuacion": true|false,
    "tipo_esperado": "confirmation|none",
    "datos_recordar": {{
      "query": "constancia generada",
      "alumno": {{"id": {alumno.get('id')}, "nombre": "{alumno.get('nombre')}"}},
      "tipo_constancia": "{tipo_constancia}",
      "archivo_temporal": "{data.get('ruta_archivo', '')}",
      "estado": "vista_previa_generada",
      "acciones_disponibles": ["confirmar", "abrir", "cancelar"]
    }},
    "razonamiento": "Explicaci√≥n de por qu√© esperas confirmaci√≥n o no"
  }}
}}
"""

            response = self.gemini_client.send_prompt_sync(response_prompt)
            return self._parse_json_response(response)

        except Exception as e:
            self.logger.error(f"Error generando respuesta de constancia: {e}")
            return None

    
    def _create_standardized_report(self, action_executed: str, result: Dict[str, Any],
                                   user_query: str, error_info: Dict = None) -> Dict[str, Any]:
        """
        üîß CREA REPORTE ESTANDARIZADO PARA EL MASTER

        Formato consistente que el Master puede interpretar f√°cilmente
        """
        try:
            # Determinar tipo de datos
            data = result.get('data', [])
            data_type = self._determine_data_type(action_executed, data)

            # Crear reporte estandarizado
            report = {
                "status": "error" if error_info else "success",
                "action_executed": action_executed,
                "technical_result": {
                    "data": data,
                    "row_count": result.get('row_count', len(data) if isinstance(data, list) else 1),
                    "sql_executed": result.get('sql_executed', ''),
                    "execution_time": result.get('execution_time', 'N/A')
                },
                "error_info": error_info,
                "metadata": {
                    "data_type": data_type,
                    "requires_user_action": self._requires_user_action(action_executed),
                    "original_query": user_query,
                    "context_ready": True
                }
            }

            self.logger.info(f"üìä [STUDENT REPORT] {action_executed}: {report['status']} - {report['technical_result']['row_count']} resultados")
            return report

        except Exception as e:
            self.logger.error(f"Error creando reporte estandarizado: {e}")
            return {
                "status": "error",
                "action_executed": action_executed,
                "error_info": {"type": "report_creation_error", "message": str(e)},
                "metadata": {"data_type": "error", "requires_user_action": False}
            }

    def _determine_data_type(self, action: str, data: Any = None) -> str:
        """Determina el tipo de datos para el Master"""
        if action in ["BUSCAR_UNIVERSAL", "BUSCAR_Y_FILTRAR"]:
            return "student_list"
        elif action in ["CALCULAR_ESTADISTICA", "CONTAR_UNIVERSAL"]:
            return "statistics"
        elif action in ["GENERAR_CONSTANCIA_COMPLETA"]:
            return "constancia_preview"
        elif action in ["TRANSFORMAR_PDF"]:
            return "transformation_preview"
        else:
            return "generic_data"

    def _requires_user_action(self, action: str) -> bool:
        """Determina si la acci√≥n requiere interacci√≥n del usuario"""
        return action in ["BUSCAR_UNIVERSAL", "CALCULAR_ESTADISTICA", "CONTAR_UNIVERSAL", "BUSCAR_Y_FILTRAR"]

    def _debug_pause(self, title: str, data: dict):
        """M√©todo de debug para mostrar informaci√≥n en --debug-pauses"""
        import os
        if os.environ.get('DEBUG_PAUSES', 'false').lower() == 'true':
            print(f"\nüõë {title}")
            for key, value in data.items():
                if isinstance(value, list) and len(value) > 3:
                    print(f"    ‚îú‚îÄ‚îÄ {key}: {value[:3]}... ({len(value)} total)")
                elif isinstance(value, str) and len(value) > 50:
                    print(f"    ‚îú‚îÄ‚îÄ {key}: {value[:50]}...")
                else:
                    print(f"    ‚îú‚îÄ‚îÄ {key}: {value}")
            print(f"    ‚îî‚îÄ‚îÄ Presiona ENTER para continuar...")
            input()

