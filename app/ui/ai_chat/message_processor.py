"""
Procesador de mensajes y comandos para la interfaz de chat
VERSIÃ“N SIMPLIFICADA CON SISTEMA DE PLANTILLAS SQL
"""
import random
from datetime import datetime
from typing import Dict, Any
from app.core.config import Config
from app.core.logging import get_logger

class MessageProcessor:
    """Procesador de mensajes simplificado con sistema de plantillas SQL"""

    def __init__(self, gemini_client=None, pdf_panel=None):
        """Inicializa el procesador de mensajes"""
        self.gemini_client = gemini_client
        self.pdf_panel = pdf_panel

        # ğŸ†• LOGGING CENTRALIZADO
        self.logger = get_logger(__name__)

        # ğŸ¯ INICIALIZAR MASTER INTERPRETER AL CARGAR EL SISTEMA
        self.logger.info("ğŸ¯ [MESSAGEPROCESSOR] Inicializando MasterInterpreter al cargar sistema...")
        from app.core.ai.interpretation.master_interpreter import MasterInterpreter
        self.master_interpreter = MasterInterpreter(self.gemini_client)
        self.logger.info("âœ… [MESSAGEPROCESSOR] MasterInterpreter inicializado y listo")

        # CONTEXTO CONVERSACIONAL SIMPLE
        self.conversation_history = []
        self.last_query_results = None

        # ğŸ”§ ATRIBUTOS REQUERIDOS PARA COMPATIBILIDAD
        self.conversation_stack = []
        self.awaiting_continuation = False

        # ğŸ†• FRASES DESDE CONFIGURACIÃ“N CENTRALIZADA
        self.greeting_phrases = Config.RESPONSES['greeting_phrases']
        self.success_phrases = Config.RESPONSES['success_phrases']

        self.logger.info("âœ… MessageProcessor inicializado con MasterInterpreter cargado")





    def process_command(self, command_data, current_pdf=None, original_query=None, conversation_context=None):
        """Procesa un comando y devuelve el resultado"""
        if not command_data:
            return False, "No se pudo entender tu solicitud. Â¿PodrÃ­as reformularla?", {}

        # AÃ±adir consulta original para el bypass SQL
        if original_query and isinstance(command_data, dict):
            command_data["original_query"] = original_query

        # NUEVO: AÃ±adir contexto conversacional
        if conversation_context and isinstance(command_data, dict):
            command_data["conversation_context"] = conversation_context

        # Procesar el comando
        accion = command_data.get("accion", "desconocida")
        parametros = command_data.get("parametros", {})

        # Si es una transformaciÃ³n y hay un PDF cargado, manejarla especialmente
        if accion == "transformar_constancia" and current_pdf:
            # Verificar si el usuario quiere guardar los datos
            if "guardar" in parametros and parametros["guardar"]:
                parametros["guardar_alumno"] = True
            elif "guardar_alumno" in parametros and parametros["guardar_alumno"]:
                # Asegurarse de que el valor sea booleano
                parametros["guardar_alumno"] = True

            # Si hay un PDF cargado, usar esa ruta
            if not parametros.get("ruta_archivo"):
                parametros["ruta_archivo"] = current_pdf

            # Para transformaciones, devolver directamente el comando sin ejecutar
            # El ChatWindow se encargarÃ¡ de manejar la transformaciÃ³n
            return True, "Iniciando transformaciÃ³n de constancia...", {
                "accion": "transformar_constancia",
                "parametros": parametros
            }

        # Si es guardar alumno desde PDF y hay un PDF cargado, usar esa ruta
        if accion == "guardar_alumno_pdf" and current_pdf:
            if not parametros.get("ruta_archivo"):
                parametros["ruta_archivo"] = current_pdf

            command_data["parametros"] = parametros

        # NUEVO FLUJO DIRECTO: Sin CommandExecutor, directo a MasterInterpreter
        return self._execute_with_master_interpreter(command_data)

    def _execute_with_master_interpreter(self, command_data):
        """Ejecuta comando con sistema de plantillas SQL (simplificado)"""
        try:
            accion = command_data.get("accion", "")
            parametros = command_data.get("parametros", {})
            original_query = command_data.get("original_query", "")
            conversation_context = command_data.get("conversation_context", {})

            self.logger.debug(f"Procesando: {accion}")
            self.logger.debug(f"Query original: {original_query}")

            # Preparar consulta para procesar
            consulta_para_procesar = original_query or parametros.get("consulta_original", "")

            if not consulta_para_procesar:
                return False, "No se pudo determinar la consulta a procesar", {}

            # ğŸ¯ FLUJO PRINCIPAL: MASTERINTERPRETER
            self.logger.info("ğŸ¯ [MESSAGEPROCESSOR] Procesando con MasterInterpreter (ya inicializado)")

            self.logger.debug(f"Enviando a MasterInterpreter: '{consulta_para_procesar}'")

            # Crear contexto de interpretaciÃ³n
            from app.core.ai.interpretation.base_interpreter import InterpretationContext

            context = InterpretationContext(
                user_message=consulta_para_procesar,
                conversation_state=conversation_context.get("conversation_state", {}),
                user_preferences={}
            )

            # ğŸ†• AGREGAR PDF_PANEL AL CONTEXTO PARA TRANSFORMACIONES
            if hasattr(self, 'pdf_panel') and self.pdf_panel:
                context.pdf_panel = self.pdf_panel

            # CORREGIDO: Agregar historial conversacional desde self.conversation_history
            if self.conversation_history:
                context.conversation_history = self.conversation_history
                self.logger.debug(f"Pasando {len(self.conversation_history)} mensajes de contexto conversacional")

            # TambiÃ©n agregar resultados de Ãºltima consulta para referencias
            if self.last_query_results:
                context.last_query_results = self.last_query_results
                self.logger.debug(f"Pasando resultados de Ãºltima consulta: '{self.last_query_results['user_query']}'")

            # Mantener contexto externo si existe
            if conversation_context.get("conversation_history"):
                context.external_conversation_history = conversation_context["conversation_history"]
            if conversation_context.get("recent_messages"):
                context.recent_messages = conversation_context["recent_messages"]

            # NUEVO: Ejecutar con MasterInterpreter pasando la pila conversacional
            result = self.master_interpreter.interpret(context, self.conversation_stack)

            if result:
                # Manejar diferentes tipos de resultados
                if result.action == "consulta_sql_exitosa":
                    message = result.parameters.get("human_response",
                                                   result.parameters.get("message", "Consulta procesada"))

                    # NUEVO: Procesar auto-reflexiÃ³n del LLM
                    auto_reflexion = result.parameters.get("auto_reflexion", {})

                    # ğŸ”§ DEBUG: Verificar si auto-reflexiÃ³n estÃ¡ llegando
                    self.logger.info(f"ğŸ§  DEBUG - Auto-reflexiÃ³n recibida: {auto_reflexion}")

                    if auto_reflexion.get("espera_continuacion", False):
                        tipo_esperado = auto_reflexion.get("tipo_esperado", "selection")
                        datos_recordar = auto_reflexion.get("datos_recordar", {})
                        razonamiento = auto_reflexion.get("razonamiento", "")

                        self.logger.info(f"âœ… LLM auto-reflexiÃ³n detectÃ³ continuaciÃ³n esperada:")
                        self.logger.info(f"   - Tipo: {tipo_esperado}")
                        self.logger.info(f"   - Razonamiento: {razonamiento}")
                        self.logger.info(f"   - Datos a recordar: {datos_recordar}")

                        # Agregar automÃ¡ticamente a la pila conversacional
                        self.add_to_conversation_stack(
                            consulta_para_procesar,
                            {
                                "data": result.parameters.get("data", []),
                                "row_count": result.parameters.get("row_count", 0),
                                "message": message,
                                "sql_query": result.parameters.get("sql_query", ""),
                                **datos_recordar  # Agregar datos adicionales de la reflexiÃ³n
                            },
                            tipo_esperado
                        )

                        self.logger.info(f"ğŸ“š PILA CONVERSACIONAL ACTUALIZADA: {len(self.conversation_stack)} niveles")
                    else:
                        self.logger.info("âŒ LLM auto-reflexiÃ³n: No espera continuaciÃ³n")

                    # ğŸ¯ CONFIGURAR DATOS ESTRUCTURADOS PARA DATADISPLAYMANAGER
                    data = result.parameters.get("data", [])
                    row_count = result.parameters.get("row_count", 0)

                    # Si hay datos, configurar para mostrar con DataDisplayManager
                    if data and row_count > 0:
                        self.logger.info(f"ğŸ¯ Datos estructurados detectados ({row_count} registros) - Configurando para DataDisplayManager")

                        # Configurar parÃ¡metros para DataDisplayManager
                        formatted_parameters = result.parameters.copy()
                        formatted_parameters["action"] = "show_data"

                        # Mantener datos en formato original para que DataDisplayManager los detecte
                        # No necesitamos agregar clave "alumnos" - DataDisplayManager lo detecta automÃ¡ticamente

                        # NUEVO: Guardar conversaciÃ³n con resultados formateados
                        self.logger.debug(f"Guardando conversaciÃ³n con datos estructurados: '{consulta_para_procesar}' -> '{message[:50]}...'")
                        self.add_to_conversation(consulta_para_procesar, message, formatted_parameters)
                        self.logger.debug(f"Total mensajes en historial: {len(self.conversation_history)}")

                        return True, message, formatted_parameters

                    else:
                        # Sin datos estructurados, procesar normalmente
                        # NUEVO: Guardar conversaciÃ³n con resultados
                        self.logger.debug(f"Guardando conversaciÃ³n: '{consulta_para_procesar}' -> '{message[:50]}...'")
                        self.add_to_conversation(consulta_para_procesar, message, result.parameters)
                        self.logger.debug(f"Total mensajes en historial: {len(self.conversation_history)}")

                        return True, message, result.parameters

                elif result.action in ["ayuda_proporcionada", "ayuda_funcionalidades", "ayuda_solucion", "ayuda_ejemplo",
                                     "conversacion_general", "estadisticas_generadas",
                                     "constancia_generada", "constancia_requiere_aclaracion"]:
                    # ğŸ› ï¸ USAR EL MENSAJE REAL GENERADO POR EL HELPINTERPRETER
                    message = result.parameters.get("message",
                                                   result.parameters.get("mensaje", "Respuesta procesada"))

                    # NUEVO: Guardar conversaciÃ³n
                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)

                    return True, message, result.parameters

                # ğŸ†• NUEVAS ACCIONES DE CONSTANCIA
                elif result.action == "constancia_preview":
                    message = result.parameters.get("message", "Vista previa de constancia generada")

                    # Procesar auto-reflexiÃ³n para constancias
                    auto_reflexion = result.parameters.get("auto_reflexion", {})
                    if auto_reflexion.get("espera_continuacion", False):
                        datos_recordar = auto_reflexion.get("datos_recordar", {})

                        self.logger.debug(f"Constancia con auto-reflexiÃ³n: {auto_reflexion.get('razonamiento', '')}")
                        self.add_to_conversation_stack(
                            consulta_para_procesar,
                            {**result.parameters, **datos_recordar},
                            "confirmation"  # Espera confirmaciÃ³n para constancia
                        )

                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)
                    return True, message, result.parameters

                elif result.action in ["constancia_confirmada", "constancia_abierta", "constancia_cancelada"]:
                    message = result.parameters.get("message", "AcciÃ³n de constancia completada")

                    # Limpiar pila conversacional despuÃ©s de acciÃ³n de constancia
                    self.clear_conversation_stack()

                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)
                    return True, message, result.parameters

                elif result.action == "transformar_constancia":
                    # Manejar transformaciÃ³n de constancia
                    data_with_action = result.parameters.copy()
                    data_with_action["accion"] = "transformar_constancia"
                    return True, result.parameters.get("message", "TransformaciÃ³n iniciada"), data_with_action

                elif result.action == "constancia_error":
                    # ğŸ†• USAR MENSAJE AMIGABLE EN LUGAR DE ERROR TÃ‰CNICO
                    error_message = result.parameters.get("message", "Error al procesar constancia")
                    return False, error_message, result.parameters

                elif result.action == "transformation_preview":
                    # ğŸ†• MANEJAR VISTA PREVIA DE TRANSFORMACIÃ“N
                    message = result.parameters.get("message", "Vista previa de transformaciÃ³n generada")
                    self._handle_transformation_preview(result.parameters)
                    return True, message, result.parameters

                elif result.action == "transformation_error":
                    # ğŸ†• MANEJAR ERRORES DE TRANSFORMACIÃ“N
                    error_message = result.parameters.get("message", "Error al transformar PDF")
                    return False, error_message, result.parameters

                # NUEVO: Manejar resultados del sistema conversacional
                elif result.action == "seleccion_realizada":
                    message = result.parameters.get("message", "SelecciÃ³n realizada")

                    # Agregar a la pila conversacional si es necesario
                    elemento_seleccionado = result.parameters.get("elemento_seleccionado", {})
                    if elemento_seleccionado:
                        self.add_to_conversation_stack(
                            consulta_para_procesar,
                            {"data": [elemento_seleccionado], "row_count": 1, "message": message},
                            "action"  # Espera acciÃ³n sobre el elemento seleccionado
                        )

                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)
                    return True, message, result.parameters

                elif result.action in ["accion_realizada", "confirmacion_realizada", "especificacion_realizada"]:
                    message = result.parameters.get("message", "AcciÃ³n procesada")
                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)
                    return True, message, result.parameters

                elif result.action == "continuacion_error":
                    # Error en continuaciÃ³n - limpiar pila y proceder normalmente
                    self.clear_conversation_stack()
                    error_message = result.parameters.get("message", "Error en continuaciÃ³n conversacional")
                    return False, error_message, result.parameters

                elif result.action == "continuacion_inteligente":
                    # NUEVO: Manejo de continuaciÃ³n inteligente
                    message = result.parameters.get("message", "ContinuaciÃ³n procesada")

                    # Procesar auto-reflexiÃ³n si estÃ¡ disponible
                    auto_reflexion = result.parameters.get("auto_reflexion", {})
                    if auto_reflexion.get("espera_continuacion", False):
                        tipo_esperado = auto_reflexion.get("tipo_esperado", "action")
                        datos_recordar = auto_reflexion.get("datos_recordar", {})

                        self.logger.debug(f"ContinuaciÃ³n inteligente con auto-reflexiÃ³n: {auto_reflexion.get('razonamiento', '')}")
                        self.add_to_conversation_stack(consulta_para_procesar, {**result.parameters, **datos_recordar}, tipo_esperado)
                    else:
                        self.logger.debug(f"ContinuaciÃ³n inteligente completada: {result.parameters.get('razonamiento', '')}")

                    # ğŸ”§ IMPORTANTE: Agregar return que faltaba
                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)
                    return True, message, result.parameters

                else:
                    # Otros tipos de resultado
                    message = result.parameters.get("mensaje",
                                                   result.parameters.get("message", "Consulta procesada"))

                    # NUEVO: Procesar auto-reflexiÃ³n si estÃ¡ disponible (para otros tipos de resultado)
                    auto_reflexion = result.parameters.get("auto_reflexion", {})
                    if auto_reflexion.get("espera_continuacion", False):
                        tipo_esperado = auto_reflexion.get("tipo_esperado", "action")
                        datos_recordar = auto_reflexion.get("datos_recordar", {})

                        self.logger.debug(f"Auto-reflexiÃ³n en resultado '{result.action}': {auto_reflexion.get('razonamiento', '')}")
                        self.add_to_conversation_stack(consulta_para_procesar, {**result.parameters, **datos_recordar}, tipo_esperado)

                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)
                    return True, message, result.parameters
            else:
                return False, "No se pudo procesar la consulta", {}

        except Exception as e:
            self.logger.error(f"Error en _execute_with_master_interpreter: {str(e)}")
            return False, f"Error procesando consulta: {str(e)}", {}





    def get_current_time(self):
        """Obtiene la hora actual en formato HH:MM"""
        now = datetime.now()
        return now.strftime("%H:%M")

    def get_random_greeting(self):
        """Devuelve un saludo aleatorio"""
        return random.choice(self.greeting_phrases)

    def get_random_success_phrase(self):
        """Devuelve una frase de Ã©xito aleatoria"""
        return random.choice(self.success_phrases)

    def add_to_conversation(self, user_message, system_response, query_results=None):
        """Agregar intercambio al historial conversacional"""
        from datetime import datetime

        # Agregar mensaje del usuario
        self.conversation_history.append({
            'role': 'user',
            'content': user_message,
            'timestamp': datetime.now().strftime("%H:%M:%S")
        })

        # Agregar respuesta del sistema
        self.conversation_history.append({
            'role': 'system',
            'content': system_response,
            'timestamp': datetime.now().strftime("%H:%M:%S")
        })

        # Guardar resultados de la Ãºltima consulta para referencias
        if query_results:
            self.last_query_results = {
                'user_query': user_message,
                'results': query_results,
                'timestamp': datetime.now().strftime("%H:%M:%S")
            }

        # Mantener solo Ãºltimos 10 intercambios (20 mensajes)
        if len(self.conversation_history) > 20:
            self.conversation_history = self.conversation_history[-20:]

    def _get_conversation_context(self):
        """Genera contexto conversacional inteligente"""
        if not self.conversation_history:
            return ""

        # Ãšltimos 3 intercambios (6 mensajes)
        recent_messages = self.conversation_history[-6:]

        if not recent_messages:
            return ""

        context = """

=== CONTEXTO CONVERSACIONAL RECIENTE ===
ğŸ“ HISTORIAL DE LA SESIÃ“N ACTUAL:
"""

        for msg in recent_messages:
            role_emoji = "ğŸ‘¤" if msg['role'] == 'user' else "ğŸ¤–"
            # Truncar respuestas largas del sistema
            content = msg['content']
            if msg['role'] == 'system' and len(content) > 150:
                content = content[:150] + "..."

            context += f"{role_emoji} {msg['role'].title()}: {content}\n"

        # Agregar informaciÃ³n de Ãºltimos resultados si existen
        if self.last_query_results:
            context += f"""
ğŸ“Š ÃšLTIMA CONSULTA REALIZADA:
- Consulta: "{self.last_query_results['user_query']}"
- Resultados disponibles para referencias
"""

        context += """
ğŸ§  INSTRUCCIONES PARA USO INTELIGENTE DEL CONTEXTO:
- USA el contexto SOLO si la consulta actual hace referencia a informaciÃ³n anterior
- Si el usuario dice "el primero", "ese", "Ã©l", "ella" â†’ busca en el contexto
- Si dice "y cuÃ¡ntos...", "tambiÃ©n...", "ademÃ¡s..." â†’ relaciona con consulta anterior
- Si es una consulta completamente nueva â†’ IGNORA el contexto
- Si hay dudas sobre referencias â†’ pregunta al usuario para aclarar

EJEMPLOS DE CUÃNDO USAR CONTEXTO:
âœ… "CURP del tercero" (despuÃ©s de mostrar lista)
âœ… "constancia para Ã©l" (despuÃ©s de mostrar alumno especÃ­fico)
âœ… "y del turno vespertino" (despuÃ©s de consulta de grado)
âŒ "cuÃ¡ntos alumnos hay" (consulta independiente)
âŒ "buscar GarcÃ­a" (consulta nueva)
"""

        return context

    def _handle_transformation_preview(self, parameters: Dict[str, Any]):
        """Maneja vista previa de transformaciÃ³n de PDF"""
        try:
            files = parameters.get("files", [])
            if files and self.pdf_panel:
                pdf_path = files[0]
                self.logger.info(f"Cargando vista previa de transformaciÃ³n: {pdf_path}")

                # Cargar PDF transformado en el panel
                self.pdf_panel.show_pdf(pdf_path)

                # Establecer contexto de transformaciÃ³n completada
                alumno_data = parameters.get("alumno", {})
                transformation_info = parameters.get("transformation_info", {})

                if hasattr(self.pdf_panel, 'set_transformation_completed_context'):
                    self.pdf_panel.set_transformation_completed_context(
                        original_data=self.pdf_panel.pdf_data,
                        transformed_data=parameters.get("data", {}),
                        alumno_data=alumno_data
                    )

                self.logger.debug(f"Vista previa de transformaciÃ³n cargada: {transformation_info.get('tipo_transformacion', 'N/A')}")

        except Exception as e:
            self.logger.error(f"Error manejando vista previa de transformaciÃ³n: {e}")

    # ==========================================
    # MÃ‰TODOS DE GESTIÃ“N DE PILA CONVERSACIONAL
    # ==========================================

    def add_to_conversation_stack(self, query, result_data, awaiting_type):
        """Agregar nivel a la pila conversacional"""
        from datetime import datetime

        level = {
            "query": query,
            "data": result_data.get("data", []),
            "row_count": result_data.get("row_count", 0),
            "awaiting": awaiting_type,  # "selection", "action", "confirmation", "specification"
            "timestamp": datetime.now().strftime("%H:%M:%S"),
            "sql_query": result_data.get("sql_query", ""),
            "message": result_data.get("message", "")
        }

        self.conversation_stack.append(level)
        self.awaiting_continuation = True

        self.logger.debug(f"Agregado a pila conversacional: Nivel {len(self.conversation_stack)}")
        self.logger.debug(f"Tipo esperado: {awaiting_type}")
        self.logger.debug(f"Datos disponibles: {level['row_count']} elementos")

    def clear_conversation_stack(self):
        """Limpiar pila cuando se completa una acciÃ³n o inicia consulta nueva"""
        stack_size = len(self.conversation_stack)
        self.conversation_stack = []
        self.awaiting_continuation = False
        self.logger.debug(f"Pila conversacional limpiada (tenÃ­a {stack_size} niveles)")

    def get_conversation_context_for_llm(self):
        """Formatear pila conversacional para el LLM"""
        if not self.conversation_stack:
            return ""

        context = "\n=== PILA CONVERSACIONAL ACTIVA ===\n"
        context += f"ğŸ“š NIVELES EN LA PILA: {len(self.conversation_stack)}\n"

        for i, level in enumerate(self.conversation_stack, 1):
            context += f"""
ğŸ“‹ NIVEL {i}:
- Consulta original: "{level['query']}"
- Datos disponibles: {level['row_count']} elementos
- Esperando del usuario: {level['awaiting']}
- SQL ejecutado: {level['sql_query'][:50]}{'...' if len(level['sql_query']) > 50 else ''}
- Timestamp: {level['timestamp']}
"""

        context += """
ğŸ§  INSTRUCCIONES PARA USO DE LA PILA:
- Si la nueva consulta se refiere a algÃºn nivel de la pila, USA esos datos
- NO generes nuevo SQL si puedes usar datos de la pila
- Ejemplos de referencias: "del primero", "nÃºmero 5", "para Ã©l", "ese alumno"
- Si es consulta completamente nueva, ignora la pila

PATRONES DE CONTINUACIÃ“N:
âœ… "CURP del quinto" â†’ usar elemento 5 del Ãºltimo nivel con lista
âœ… "constancia para Ã©l" â†’ usar Ãºltimo alumno seleccionado
âœ… "sÃ­" â†’ confirmar acciÃ³n propuesta en el Ãºltimo nivel
âŒ "cuÃ¡ntos alumnos hay" â†’ consulta nueva, limpiar pila
"""

        return context

    def _detect_awaiting_continuation(self, response_message, result_data):
        """Detecta automÃ¡ticamente si la respuesta espera continuaciÃ³n del usuario"""
        import re

        # Patrones que indican que se espera continuaciÃ³n
        continuation_indicators = [
            # Preguntas directas
            (r"Â¿.*informaciÃ³n.*especÃ­fica.*\?", "selection"),      # "Â¿informaciÃ³n especÃ­fica?"
            (r"Â¿.*necesitas.*\?", "action"),                       # "Â¿necesitas algo?"
            (r"Â¿.*te.*gustarÃ­a.*\?", "action"),                    # "Â¿te gustarÃ­a...?"
            (r"Â¿.*quÃ©.*tipo.*\?", "specification"),                # "Â¿quÃ© tipo de constancia?"
            (r"Â¿.*cuÃ¡l.*\?", "selection"),                         # "Â¿cuÃ¡l prefieres?"

            # Listas numeradas (indican selecciÃ³n posible)
            (r"\d+\.\s+[A-Z].*encontrados", "selection"),          # "1. NOMBRE... encontrados"
            (r"ğŸ“‹.*\(\d+.*encontrados\)", "selection"),            # "ğŸ“‹ LISTA (X encontrados)"

            # Ofertas de servicios
            (r"generar.*constancia", "action"),                    # Ofrece generar constancia
            (r"consultar.*informaciÃ³n", "action"),                 # Ofrece consultar mÃ¡s
            (r"buscar.*criterios", "action"),                      # Ofrece buscar mÃ¡s
        ]

        for pattern, awaiting_type in continuation_indicators:
            if re.search(pattern, response_message, re.IGNORECASE):
                self.logger.debug(f"PatrÃ³n detectado: '{pattern}' â†’ Tipo: {awaiting_type}")

                # Determinar tipo especÃ­fico basado en contenido
                if awaiting_type == "selection" and result_data.get("row_count", 0) > 1:
                    return "selection"  # Lista con mÃºltiples elementos
                elif "constancia" in response_message.lower():
                    return "action"     # AcciÃ³n de constancia
                elif "tipo" in response_message.lower():
                    return "specification"  # EspecificaciÃ³n de tipo
                else:
                    return awaiting_type

        # Verificar si hay datos de lista que podrÃ­an usarse despuÃ©s
        if result_data.get("row_count", 0) > 1:
            self.logger.debug(f"Lista de {result_data['row_count']} elementos detectada â†’ Posible selecciÃ³n futura")
            return "selection"

        self.logger.debug("No se detectÃ³ patrÃ³n de continuaciÃ³n")
        return None  # No espera continuaciÃ³n

    # ğŸ—‘ï¸ MÃ‰TODOS DEL SISTEMA DE MEMORIA PROBLEMÃTICO ELIMINADOS
    # El sistema de plantillas SQL los reemplaza completamente

