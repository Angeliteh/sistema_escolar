"""
Procesador de mensajes y comandos para la interfaz de chat
"""
import random
from datetime import datetime
from typing import Dict, Any
from app.core.config import Config
from app.core.logging import get_logger

# CommandExecutor eliminado - ahora usamos MasterInterpreter directamente

class MessageProcessor:
    """Procesador de mensajes y comandos para la interfaz de chat"""

    def __init__(self, gemini_client=None, pdf_panel=None):
        """Inicializa el procesador de mensajes"""
        self.gemini_client = gemini_client
        self.pdf_panel = pdf_panel
        # NUEVO: Sin CommandExecutor, MasterInterpreter se inicializa cuando se necesita
        self.master_interpreter = None

        # NUEVO: Contexto conversacional inteligente
        self.conversation_history = []
        self.last_query_results = None  # Para referencias a resultados anteriores

        # NUEVO: Pila conversacional din√°mica
        self.conversation_stack = []
        self.awaiting_continuation = False

        # üÜï FRASES DESDE CONFIGURACI√ìN CENTRALIZADA
        self.greeting_phrases = Config.RESPONSES['greeting_phrases']
        self.success_phrases = Config.RESPONSES['success_phrases']

        # üÜï LOGGING CENTRALIZADO
        self.logger = get_logger(__name__)



    def process_command(self, command_data, current_pdf=None, original_query=None, conversation_context=None):
        """Procesa un comando y devuelve el resultado"""
        if not command_data:
            return False, "No se pudo entender tu solicitud. ¬øPodr√≠as reformularla?", {}

        # A√±adir consulta original para el bypass SQL
        if original_query and isinstance(command_data, dict):
            command_data["original_query"] = original_query

        # NUEVO: A√±adir contexto conversacional
        if conversation_context and isinstance(command_data, dict):
            command_data["conversation_context"] = conversation_context

        # Procesar el comando
        accion = command_data.get("accion", "desconocida")
        parametros = command_data.get("parametros", {})

        # Si es una transformaci√≥n y hay un PDF cargado, manejarla especialmente
        if accion == "transformar_constancia" and current_pdf:
            # Verificar si el usuario quiere guardar los datos
            if "guardar" in parametros and parametros["guardar"]:
                parametros["guardar_alumno"] = True
            elif "guardar_alumno" in parametros and parametros["guardar_alumno"]:
                # Asegurarse de que el valor sea booleano
                parametros["guardar_alumno"] = True

            # Si hay un PDF cargado, usar esa ruta
            if not parametros.get("ruta_archivo"):
                parametros["ruta_archivo"] = current_pdf

            # Para transformaciones, devolver directamente el comando sin ejecutar
            # El ChatWindow se encargar√° de manejar la transformaci√≥n
            return True, "Iniciando transformaci√≥n de constancia...", {
                "accion": "transformar_constancia",
                "parametros": parametros
            }

        # Si es guardar alumno desde PDF y hay un PDF cargado, usar esa ruta
        if accion == "guardar_alumno_pdf" and current_pdf:
            if not parametros.get("ruta_archivo"):
                parametros["ruta_archivo"] = current_pdf

            command_data["parametros"] = parametros

        # NUEVO FLUJO DIRECTO: Sin CommandExecutor, directo a MasterInterpreter
        return self._execute_with_master_interpreter(command_data)

    def _execute_with_master_interpreter(self, command_data):
        """Ejecuta comando directamente con MasterInterpreter (sin CommandExecutor)"""
        try:
            accion = command_data.get("accion", "")
            parametros = command_data.get("parametros", {})
            original_query = command_data.get("original_query", "")
            conversation_context = command_data.get("conversation_context", {})

            self.logger.debug(f"Procesando directamente: {accion}")
            self.logger.debug(f"Historial conversacional actual: {len(self.conversation_history)} mensajes")

            # Inicializar MasterInterpreter si no existe
            if not hasattr(self, 'master_interpreter') or self.master_interpreter is None:
                from app.core.ai.interpretation.master_interpreter import MasterInterpreter
                self.master_interpreter = MasterInterpreter(self.gemini_client)

            # Preparar consulta para procesar
            consulta_para_procesar = original_query or parametros.get("consulta_original", "")

            if not consulta_para_procesar:
                return False, "No se pudo determinar la consulta a procesar", {}

            self.logger.debug(f"Enviando a MasterInterpreter: '{consulta_para_procesar}'")

            # Crear contexto de interpretaci√≥n
            from app.core.ai.interpretation.base_interpreter import InterpretationContext

            context = InterpretationContext(
                user_message=consulta_para_procesar,
                conversation_state=conversation_context.get("conversation_state", {}),
                user_preferences={}
            )

            # üÜï AGREGAR PDF_PANEL AL CONTEXTO PARA TRANSFORMACIONES
            if hasattr(self, 'pdf_panel') and self.pdf_panel:
                context.pdf_panel = self.pdf_panel

            # CORREGIDO: Agregar historial conversacional desde self.conversation_history
            if self.conversation_history:
                context.conversation_history = self.conversation_history
                self.logger.debug(f"Pasando {len(self.conversation_history)} mensajes de contexto conversacional")

            # Tambi√©n agregar resultados de √∫ltima consulta para referencias
            if self.last_query_results:
                context.last_query_results = self.last_query_results
                self.logger.debug(f"Pasando resultados de √∫ltima consulta: '{self.last_query_results['user_query']}'")

            # Mantener contexto externo si existe
            if conversation_context.get("conversation_history"):
                context.external_conversation_history = conversation_context["conversation_history"]
            if conversation_context.get("recent_messages"):
                context.recent_messages = conversation_context["recent_messages"]

            # NUEVO: Ejecutar con MasterInterpreter pasando la pila conversacional
            result = self.master_interpreter.interpret(context, self.conversation_stack)

            if result:
                # Manejar diferentes tipos de resultados
                if result.action == "consulta_sql_exitosa":
                    message = result.parameters.get("human_response",
                                                   result.parameters.get("message", "Consulta procesada"))

                    # NUEVO: Procesar auto-reflexi√≥n del LLM
                    auto_reflexion = result.parameters.get("auto_reflexion", {})

                    # üîß DEBUG: Verificar si auto-reflexi√≥n est√° llegando
                    self.logger.info(f"üß† DEBUG - Auto-reflexi√≥n recibida: {auto_reflexion}")

                    if auto_reflexion.get("espera_continuacion", False):
                        tipo_esperado = auto_reflexion.get("tipo_esperado", "selection")
                        datos_recordar = auto_reflexion.get("datos_recordar", {})
                        razonamiento = auto_reflexion.get("razonamiento", "")

                        self.logger.info(f"‚úÖ LLM auto-reflexi√≥n detect√≥ continuaci√≥n esperada:")
                        self.logger.info(f"   - Tipo: {tipo_esperado}")
                        self.logger.info(f"   - Razonamiento: {razonamiento}")
                        self.logger.info(f"   - Datos a recordar: {datos_recordar}")

                        # Agregar autom√°ticamente a la pila conversacional
                        self.add_to_conversation_stack(
                            consulta_para_procesar,
                            {
                                "data": result.parameters.get("data", []),
                                "row_count": result.parameters.get("row_count", 0),
                                "message": message,
                                "sql_query": result.parameters.get("sql_query", ""),
                                **datos_recordar  # Agregar datos adicionales de la reflexi√≥n
                            },
                            tipo_esperado
                        )

                        self.logger.info(f"üìö PILA CONVERSACIONAL ACTUALIZADA: {len(self.conversation_stack)} niveles")
                    else:
                        self.logger.info("‚ùå LLM auto-reflexi√≥n: No espera continuaci√≥n")

                    # NUEVO: Guardar conversaci√≥n con resultados
                    self.logger.debug(f"Guardando conversaci√≥n: '{consulta_para_procesar}' -> '{message[:50]}...'")
                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)
                    self.logger.debug(f"Total mensajes en historial: {len(self.conversation_history)}")

                    return True, message, result.parameters

                elif result.action in ["ayuda_proporcionada", "conversacion_general", "estadisticas_generadas",
                                     "constancia_generada", "constancia_requiere_aclaracion"]:
                    message = result.parameters.get("mensaje",
                                                   result.parameters.get("message", "Respuesta procesada"))

                    # NUEVO: Guardar conversaci√≥n
                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)

                    return True, message, result.parameters

                # üÜï NUEVAS ACCIONES DE CONSTANCIA
                elif result.action == "constancia_preview":
                    message = result.parameters.get("message", "Vista previa de constancia generada")

                    # Procesar auto-reflexi√≥n para constancias
                    auto_reflexion = result.parameters.get("auto_reflexion", {})
                    if auto_reflexion.get("espera_continuacion", False):
                        datos_recordar = auto_reflexion.get("datos_recordar", {})

                        self.logger.debug(f"Constancia con auto-reflexi√≥n: {auto_reflexion.get('razonamiento', '')}")
                        self.add_to_conversation_stack(
                            consulta_para_procesar,
                            {**result.parameters, **datos_recordar},
                            "confirmation"  # Espera confirmaci√≥n para constancia
                        )

                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)
                    return True, message, result.parameters

                elif result.action in ["constancia_confirmada", "constancia_abierta", "constancia_cancelada"]:
                    message = result.parameters.get("message", "Acci√≥n de constancia completada")

                    # Limpiar pila conversacional despu√©s de acci√≥n de constancia
                    self.clear_conversation_stack()

                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)
                    return True, message, result.parameters

                elif result.action == "transformar_constancia":
                    # Manejar transformaci√≥n de constancia
                    data_with_action = result.parameters.copy()
                    data_with_action["accion"] = "transformar_constancia"
                    return True, result.parameters.get("message", "Transformaci√≥n iniciada"), data_with_action

                elif result.action == "constancia_error":
                    # üÜï USAR MENSAJE AMIGABLE EN LUGAR DE ERROR T√âCNICO
                    error_message = result.parameters.get("message", "Error al procesar constancia")
                    return False, error_message, result.parameters

                elif result.action == "transformation_preview":
                    # üÜï MANEJAR VISTA PREVIA DE TRANSFORMACI√ìN
                    message = result.parameters.get("message", "Vista previa de transformaci√≥n generada")
                    self._handle_transformation_preview(result.parameters)
                    return True, message, result.parameters

                elif result.action == "transformation_error":
                    # üÜï MANEJAR ERRORES DE TRANSFORMACI√ìN
                    error_message = result.parameters.get("message", "Error al transformar PDF")
                    return False, error_message, result.parameters

                # NUEVO: Manejar resultados del sistema conversacional
                elif result.action == "seleccion_realizada":
                    message = result.parameters.get("message", "Selecci√≥n realizada")

                    # Agregar a la pila conversacional si es necesario
                    elemento_seleccionado = result.parameters.get("elemento_seleccionado", {})
                    if elemento_seleccionado:
                        self.add_to_conversation_stack(
                            consulta_para_procesar,
                            {"data": [elemento_seleccionado], "row_count": 1, "message": message},
                            "action"  # Espera acci√≥n sobre el elemento seleccionado
                        )

                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)
                    return True, message, result.parameters

                elif result.action in ["accion_realizada", "confirmacion_realizada", "especificacion_realizada"]:
                    message = result.parameters.get("message", "Acci√≥n procesada")
                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)
                    return True, message, result.parameters

                elif result.action == "continuacion_error":
                    # Error en continuaci√≥n - limpiar pila y proceder normalmente
                    self.clear_conversation_stack()
                    error_message = result.parameters.get("message", "Error en continuaci√≥n conversacional")
                    return False, error_message, result.parameters

                elif result.action == "continuacion_inteligente":
                    # NUEVO: Manejo de continuaci√≥n inteligente
                    message = result.parameters.get("message", "Continuaci√≥n procesada")

                    # Procesar auto-reflexi√≥n si est√° disponible
                    auto_reflexion = result.parameters.get("auto_reflexion", {})
                    if auto_reflexion.get("espera_continuacion", False):
                        tipo_esperado = auto_reflexion.get("tipo_esperado", "action")
                        datos_recordar = auto_reflexion.get("datos_recordar", {})

                        self.logger.debug(f"Continuaci√≥n inteligente con auto-reflexi√≥n: {auto_reflexion.get('razonamiento', '')}")
                        self.add_to_conversation_stack(consulta_para_procesar, {**result.parameters, **datos_recordar}, tipo_esperado)
                    else:
                        self.logger.debug(f"Continuaci√≥n inteligente completada: {result.parameters.get('razonamiento', '')}")

                    # üîß IMPORTANTE: Agregar return que faltaba
                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)
                    return True, message, result.parameters

                else:
                    # Otros tipos de resultado
                    message = result.parameters.get("mensaje",
                                                   result.parameters.get("message", "Consulta procesada"))

                    # NUEVO: Procesar auto-reflexi√≥n si est√° disponible (para otros tipos de resultado)
                    auto_reflexion = result.parameters.get("auto_reflexion", {})
                    if auto_reflexion.get("espera_continuacion", False):
                        tipo_esperado = auto_reflexion.get("tipo_esperado", "action")
                        datos_recordar = auto_reflexion.get("datos_recordar", {})

                        self.logger.debug(f"Auto-reflexi√≥n en resultado '{result.action}': {auto_reflexion.get('razonamiento', '')}")
                        self.add_to_conversation_stack(consulta_para_procesar, {**result.parameters, **datos_recordar}, tipo_esperado)

                    self.add_to_conversation(consulta_para_procesar, message, result.parameters)
                    return True, message, result.parameters
            else:
                return False, "No se pudo procesar la consulta", {}

        except Exception as e:
            self.logger.error(f"Error en _execute_with_master_interpreter: {str(e)}")
            return False, f"Error procesando consulta: {str(e)}", {}

    def get_current_time(self):
        """Obtiene la hora actual en formato HH:MM"""
        now = datetime.now()
        return now.strftime("%H:%M")

    def get_random_greeting(self):
        """Devuelve un saludo aleatorio"""
        return random.choice(self.greeting_phrases)

    def get_random_success_phrase(self):
        """Devuelve una frase de √©xito aleatoria"""
        return random.choice(self.success_phrases)

    def add_to_conversation(self, user_message, system_response, query_results=None):
        """Agregar intercambio al historial conversacional"""
        from datetime import datetime

        # Agregar mensaje del usuario
        self.conversation_history.append({
            'role': 'user',
            'content': user_message,
            'timestamp': datetime.now().strftime("%H:%M:%S")
        })

        # Agregar respuesta del sistema
        self.conversation_history.append({
            'role': 'system',
            'content': system_response,
            'timestamp': datetime.now().strftime("%H:%M:%S")
        })

        # Guardar resultados de la √∫ltima consulta para referencias
        if query_results:
            self.last_query_results = {
                'user_query': user_message,
                'results': query_results,
                'timestamp': datetime.now().strftime("%H:%M:%S")
            }

        # Mantener solo √∫ltimos 10 intercambios (20 mensajes)
        if len(self.conversation_history) > 20:
            self.conversation_history = self.conversation_history[-20:]

    def _get_conversation_context(self):
        """Genera contexto conversacional inteligente"""
        if not self.conversation_history:
            return ""

        # √öltimos 3 intercambios (6 mensajes)
        recent_messages = self.conversation_history[-6:]

        if not recent_messages:
            return ""

        context = """

=== CONTEXTO CONVERSACIONAL RECIENTE ===
üìù HISTORIAL DE LA SESI√ìN ACTUAL:
"""

        for msg in recent_messages:
            role_emoji = "üë§" if msg['role'] == 'user' else "ü§ñ"
            # Truncar respuestas largas del sistema
            content = msg['content']
            if msg['role'] == 'system' and len(content) > 150:
                content = content[:150] + "..."

            context += f"{role_emoji} {msg['role'].title()}: {content}\n"

        # Agregar informaci√≥n de √∫ltimos resultados si existen
        if self.last_query_results:
            context += f"""
üìä √öLTIMA CONSULTA REALIZADA:
- Consulta: "{self.last_query_results['user_query']}"
- Resultados disponibles para referencias
"""

        context += """
üß† INSTRUCCIONES PARA USO INTELIGENTE DEL CONTEXTO:
- USA el contexto SOLO si la consulta actual hace referencia a informaci√≥n anterior
- Si el usuario dice "el primero", "ese", "√©l", "ella" ‚Üí busca en el contexto
- Si dice "y cu√°ntos...", "tambi√©n...", "adem√°s..." ‚Üí relaciona con consulta anterior
- Si es una consulta completamente nueva ‚Üí IGNORA el contexto
- Si hay dudas sobre referencias ‚Üí pregunta al usuario para aclarar

EJEMPLOS DE CU√ÅNDO USAR CONTEXTO:
‚úÖ "CURP del tercero" (despu√©s de mostrar lista)
‚úÖ "constancia para √©l" (despu√©s de mostrar alumno espec√≠fico)
‚úÖ "y del turno vespertino" (despu√©s de consulta de grado)
‚ùå "cu√°ntos alumnos hay" (consulta independiente)
‚ùå "buscar Garc√≠a" (consulta nueva)
"""

        return context

    def _handle_transformation_preview(self, parameters: Dict[str, Any]):
        """Maneja vista previa de transformaci√≥n de PDF"""
        try:
            files = parameters.get("files", [])
            if files and self.pdf_panel:
                pdf_path = files[0]
                self.logger.info(f"Cargando vista previa de transformaci√≥n: {pdf_path}")

                # Cargar PDF transformado en el panel
                self.pdf_panel.show_pdf(pdf_path)

                # Establecer contexto de transformaci√≥n completada
                alumno_data = parameters.get("alumno", {})
                transformation_info = parameters.get("transformation_info", {})

                if hasattr(self.pdf_panel, 'set_transformation_completed_context'):
                    self.pdf_panel.set_transformation_completed_context(
                        original_data=self.pdf_panel.pdf_data,
                        transformed_data=parameters.get("data", {}),
                        alumno_data=alumno_data
                    )

                self.logger.debug(f"Vista previa de transformaci√≥n cargada: {transformation_info.get('tipo_transformacion', 'N/A')}")

        except Exception as e:
            self.logger.error(f"Error manejando vista previa de transformaci√≥n: {e}")

    # ==========================================
    # M√âTODOS DE GESTI√ìN DE PILA CONVERSACIONAL
    # ==========================================

    def add_to_conversation_stack(self, query, result_data, awaiting_type):
        """Agregar nivel a la pila conversacional"""
        from datetime import datetime

        level = {
            "query": query,
            "data": result_data.get("data", []),
            "row_count": result_data.get("row_count", 0),
            "awaiting": awaiting_type,  # "selection", "action", "confirmation", "specification"
            "timestamp": datetime.now().strftime("%H:%M:%S"),
            "sql_query": result_data.get("sql_query", ""),
            "message": result_data.get("message", "")
        }

        self.conversation_stack.append(level)
        self.awaiting_continuation = True

        self.logger.debug(f"Agregado a pila conversacional: Nivel {len(self.conversation_stack)}")
        self.logger.debug(f"Tipo esperado: {awaiting_type}")
        self.logger.debug(f"Datos disponibles: {level['row_count']} elementos")

    def clear_conversation_stack(self):
        """Limpiar pila cuando se completa una acci√≥n o inicia consulta nueva"""
        stack_size = len(self.conversation_stack)
        self.conversation_stack = []
        self.awaiting_continuation = False
        self.logger.debug(f"Pila conversacional limpiada (ten√≠a {stack_size} niveles)")

    def get_conversation_context_for_llm(self):
        """Formatear pila conversacional para el LLM"""
        if not self.conversation_stack:
            return ""

        context = "\n=== PILA CONVERSACIONAL ACTIVA ===\n"
        context += f"üìö NIVELES EN LA PILA: {len(self.conversation_stack)}\n"

        for i, level in enumerate(self.conversation_stack, 1):
            context += f"""
üìã NIVEL {i}:
- Consulta original: "{level['query']}"
- Datos disponibles: {level['row_count']} elementos
- Esperando del usuario: {level['awaiting']}
- SQL ejecutado: {level['sql_query'][:50]}{'...' if len(level['sql_query']) > 50 else ''}
- Timestamp: {level['timestamp']}
"""

        context += """
üß† INSTRUCCIONES PARA USO DE LA PILA:
- Si la nueva consulta se refiere a alg√∫n nivel de la pila, USA esos datos
- NO generes nuevo SQL si puedes usar datos de la pila
- Ejemplos de referencias: "del primero", "n√∫mero 5", "para √©l", "ese alumno"
- Si es consulta completamente nueva, ignora la pila

PATRONES DE CONTINUACI√ìN:
‚úÖ "CURP del quinto" ‚Üí usar elemento 5 del √∫ltimo nivel con lista
‚úÖ "constancia para √©l" ‚Üí usar √∫ltimo alumno seleccionado
‚úÖ "s√≠" ‚Üí confirmar acci√≥n propuesta en el √∫ltimo nivel
‚ùå "cu√°ntos alumnos hay" ‚Üí consulta nueva, limpiar pila
"""

        return context

    def _detect_awaiting_continuation(self, response_message, result_data):
        """Detecta autom√°ticamente si la respuesta espera continuaci√≥n del usuario"""
        import re

        # Patrones que indican que se espera continuaci√≥n
        continuation_indicators = [
            # Preguntas directas
            (r"¬ø.*informaci√≥n.*espec√≠fica.*\?", "selection"),      # "¬øinformaci√≥n espec√≠fica?"
            (r"¬ø.*necesitas.*\?", "action"),                       # "¬ønecesitas algo?"
            (r"¬ø.*te.*gustar√≠a.*\?", "action"),                    # "¬øte gustar√≠a...?"
            (r"¬ø.*qu√©.*tipo.*\?", "specification"),                # "¬øqu√© tipo de constancia?"
            (r"¬ø.*cu√°l.*\?", "selection"),                         # "¬øcu√°l prefieres?"

            # Listas numeradas (indican selecci√≥n posible)
            (r"\d+\.\s+[A-Z].*encontrados", "selection"),          # "1. NOMBRE... encontrados"
            (r"üìã.*\(\d+.*encontrados\)", "selection"),            # "üìã LISTA (X encontrados)"

            # Ofertas de servicios
            (r"generar.*constancia", "action"),                    # Ofrece generar constancia
            (r"consultar.*informaci√≥n", "action"),                 # Ofrece consultar m√°s
            (r"buscar.*criterios", "action"),                      # Ofrece buscar m√°s
        ]

        for pattern, awaiting_type in continuation_indicators:
            if re.search(pattern, response_message, re.IGNORECASE):
                self.logger.debug(f"Patr√≥n detectado: '{pattern}' ‚Üí Tipo: {awaiting_type}")

                # Determinar tipo espec√≠fico basado en contenido
                if awaiting_type == "selection" and result_data.get("row_count", 0) > 1:
                    return "selection"  # Lista con m√∫ltiples elementos
                elif "constancia" in response_message.lower():
                    return "action"     # Acci√≥n de constancia
                elif "tipo" in response_message.lower():
                    return "specification"  # Especificaci√≥n de tipo
                else:
                    return awaiting_type

        # Verificar si hay datos de lista que podr√≠an usarse despu√©s
        if result_data.get("row_count", 0) > 1:
            self.logger.debug(f"Lista de {result_data['row_count']} elementos detectada ‚Üí Posible selecci√≥n futura")
            return "selection"

        self.logger.debug("No se detect√≥ patr√≥n de continuaci√≥n")
        return None  # No espera continuaci√≥n