#!/usr/bin/env python3
"""
üî¨ TESTING A/B PARA OPTIMIZACI√ìN DEL PROMPT 3 (CR√çTICO)
Compara versi√≥n actual vs versi√≥n optimizada del _validate_and_generate_response

Uso: python testing_ab_prompt3_optimization.py
"""

import time
import json
import statistics
from typing import List, Dict, Any
from dataclasses import dataclass

# Importar las clases necesarias
import sys
import os

# Agregar el directorio ra√≠z al path
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(current_dir)

from app.ui.ai_chat.gemini_client import GeminiClient
from app.core.logging import get_logger

@dataclass
class TestResult:
    """Resultado de una prueba individual"""
    query: str
    version: str
    response_time: float
    success: bool
    response_quality: str
    has_auto_reflection: bool
    error: str = ""

class Prompt3Optimizer:
    """Versi√≥n optimizada del PROMPT 3 para testing"""

    def __init__(self, gemini_client):
        self.gemini_client = gemini_client
        self.logger = get_logger(__name__)

    def validate_and_generate_response_optimized(self, user_query: str, sql_query: str, data: List[Dict], row_count: int) -> Dict:
        """Versi√≥n ULTRA-optimizada del prompt 3 (104 ‚Üí 22 l√≠neas)"""
        try:
            # PROMPT ULTRA-OPTIMIZADO (22 l√≠neas vs 104 originales)
            optimized_prompt = f"""
Validador escolar "PROF. MAXIMO GAMIZ FERNANDEZ".

CONSULTA: "{user_query}"
DATOS: {data if row_count <= 8 else data[:3]}

VALIDAR: ¬øLos datos responden la consulta exacta?

RESPONDER como secretario profesional:
- Usa datos reales, NO placeholders
- Ofrece constancias si aplica
- NO menciones SQL/t√©cnico

AUTO-REFLEXI√ìN: ¬øEsperas continuaci√≥n?

JSON:
{{
  "respuesta_usuario": "Respuesta aqu√≠",
  "reflexion_conversacional": {{
    "espera_continuacion": true|false,
    "tipo_esperado": "selection|action|confirmation|none",
    "datos_recordar": {{"query": "{user_query}", "data": [datos], "row_count": {row_count}}},
    "razonamiento": "Por qu√© esperas continuaci√≥n"
  }}
}}

Si falla: "VALIDACION_FALLIDA"
"""

            # Enviar al LLM
            response = self.gemini_client.send_prompt_sync(optimized_prompt)

            if response:
                # Verificar si la validaci√≥n fall√≥
                if "VALIDACION_FALLIDA" in response.upper():
                    return None

                # Parsear respuesta JSON
                return self._parse_json_response(response)

            return None

        except Exception as e:
            self.logger.error(f"Error en prompt optimizado: {e}")
            return None

    def validate_and_generate_response_original(self, user_query: str, sql_query: str, data: List[Dict], row_count: int) -> Dict:
        """Versi√≥n original del prompt 3 (104 l√≠neas)"""
        try:
            # PROMPT ORIGINAL COMPLETO (104 l√≠neas)
            original_prompt = f"""
Eres un validador y comunicador experto para un sistema escolar con CAPACIDAD DE AUTO-REFLEXI√ìN.

CONTEXTO COMPLETO DEL SISTEMA:
- Sistema de gesti√≥n escolar para la escuela primaria "PROF. MAXIMO GAMIZ FERNANDEZ"
- Maneja datos de alumnos, informaci√≥n acad√©mica y generaci√≥n de constancias del ciclo escolar 2024-2025
- Los usuarios son personal administrativo, maestros y directivos que necesitan informaci√≥n para tomar decisiones educativas

CONSULTA ORIGINAL DEL USUARIO: "{user_query}"

CONSULTA SQL EJECUTADA: {sql_query}

RESULTADOS OBTENIDOS (FILTRADOS INTELIGENTEMENTE):
TIPO DE CONSULTA: SELECT (listado)
N√öMERO DE REGISTROS: {row_count}
DATOS OBTENIDOS: {data if row_count <= 15 else data[:10]}
{"... y " + str(row_count - 10) + " registros adicionales" if row_count > 10 else ""}

INFORMACI√ìN DEL FILTRO INTELIGENTE:
- Acci√≥n aplicada: mantener
- Datos originales: {len(data)} registros
- Datos filtrados: {row_count} registros
- Razonamiento del filtro: Datos procesados correctamente

INSTRUCCIONES PRINCIPALES:
1. VALIDA que el SQL resolvi√≥ exactamente lo que pidi√≥ el usuario
2. VERIFICA que los resultados son coherentes y l√≥gicos
3. Si la validaci√≥n es exitosa, GENERA una respuesta natural integrada
4. üÜï AUTO-REFLEXIONA sobre tu respuesta como un secretario experto
5. Si la validaci√≥n falla, responde con "VALIDACION_FALLIDA"

IMPORTANTE - USA LOS DATOS REALES:
- Los datos en RESULTADOS OBTENIDOS son REALES de la base de datos
- MUESTRA estos datos tal como est√°n, no inventes placeholders
- Si hay nombres, CURPs, grados - √öSALOS directamente
- NO digas "[Listado aqu√≠]" - MUESTRA el listado real

CRITERIOS DE VALIDACI√ìN:
- ¬øEl SQL responde exactamente la pregunta del usuario?
- ¬øLos resultados tienen sentido en el contexto escolar?
- ¬øLa cantidad de resultados es l√≥gica?
- ¬øLos datos mostrados son relevantes para la consulta?

FORMATO DE RESPUESTA NATURAL (si validaci√≥n exitosa):
- Presenta la informaci√≥n como un colega educativo profesional
- Contextualiza los datos dentro del marco escolar real
- Ofrece acciones espec√≠ficas (constancias, reportes, seguimiento)
- Usa el contexto de la escuela y ciclo escolar
- NO menciones t√©rminos t√©cnicos (SQL, base de datos, validaci√≥n)

REGLAS PARA MOSTRAR DATOS REALES:
- SIEMPRE muestra los datos reales obtenidos de la consulta
- NO uses placeholders como "[Listado de alumnos aqu√≠]"
- NO inventes reglas sobre cu√°ntos mostrar
- PRESENTA los datos tal como est√°n en los resultados
- Si hay muchos datos, muestra los primeros y menciona que hay m√°s disponibles

üß† AUTO-REFLEXI√ìN CONVERSACIONAL MEJORADA:
Despu√©s de generar tu respuesta, reflexiona como un secretario escolar experto:

AN√ÅLISIS REFLEXIVO ESPEC√çFICO:
- ¬øLa respuesta que acabo de dar podr√≠a generar preguntas de seguimiento?
- ¬øMostr√© una lista que el usuario podr√≠a querer referenciar ("el tercero", "n√∫mero 5")?
- ¬øProporcion√© informaci√≥n de un alumno espec√≠fico que podr√≠a necesitar CONSTANCIA?
- ¬øDeber√≠a sugerir proactivamente la generaci√≥n de constancias?
- ¬øOfrec√≠ servicios que requieren confirmaci√≥n o especificaci√≥n?
- ¬øDeber√≠a recordar estos datos para futuras consultas en esta conversaci√≥n?

SUGERENCIAS INTELIGENTES DE CONSTANCIAS:
- Si mostr√© 1 alumno espec√≠fico: Sugerir constancia directamente
- Si mostr√© pocos alumnos (2-5): Esperar selecci√≥n, luego sugerir constancia
- Si mostr√© muchos alumnos (6+): Esperar refinamiento de b√∫squeda
- Si mostr√© estad√≠sticas: No sugerir constancias

DECISI√ìN CONVERSACIONAL:
Si tu respuesta espera continuaci√≥n, especifica:
- Tipo esperado: "selection" (selecci√≥n de lista), "action" (acci√≥n sobre alumno), "confirmation" (confirmaci√≥n), "specification" (especificaci√≥n), "constancia_suggestion" (sugerir constancia)
- Datos a recordar: informaci√≥n relevante para futuras referencias
- Razonamiento: por qu√© esperas esta continuaci√≥n y si incluye sugerencia de constancia

FORMATO DE RESPUESTA COMPLETA:
{{
  "respuesta_usuario": "Tu respuesta profesional completa aqu√≠",
  "reflexion_conversacional": {{
    "espera_continuacion": true|false,
    "tipo_esperado": "selection|action|confirmation|specification|none",
    "datos_recordar": {{
      "query": "consulta original",
      "data": [datos relevantes filtrados],
      "row_count": n√∫mero_elementos_filtrados,
      "context": "contexto adicional",
      "filter_applied": "informaci√≥n del filtro inteligente"
    }},
    "razonamiento": "Explicaci√≥n de por qu√© esperas o no esperas continuaci√≥n"
  }}
}}

EJEMPLOS DE AUTO-REFLEXI√ìN:

Ejemplo 1 - Lista de alumnos:
"Mostr√© una lista de 21 alumnos Garc√≠a. Es muy probable que el usuario quiera informaci√≥n espec√≠fica de alguno, como 'CURP del quinto' o 'constancia para el tercero'. Deber√≠a recordar esta lista."

Ejemplo 2 - Informaci√≥n espec√≠fica:
"Proporcion√© datos completos de Juan P√©rez. Esto t√≠picamente lleva a solicitudes de constancias o m√°s informaci√≥n. Deber√≠a recordar que estamos hablando de Juan."

Ejemplo 3 - Consulta estad√≠stica:
"Di un n√∫mero total de alumnos. Esta es informaci√≥n general que no requiere seguimiento espec√≠fico. No necesito recordar nada especial."
"""

            # Enviar al LLM
            response = self.gemini_client.send_prompt_sync(original_prompt)

            if response:
                # Verificar si la validaci√≥n fall√≥
                if "VALIDACION_FALLIDA" in response.upper():
                    return None

                # Parsear respuesta JSON
                return self._parse_json_response(response)

            return None

        except Exception as e:
            self.logger.error(f"Error en prompt original: {e}")
            return None

    def _parse_json_response(self, response: str) -> Dict:
        """Parsea respuesta JSON del LLM"""
        try:
            import re
            clean_response = response.strip()

            json_patterns = [
                r'```json\s*(.*?)\s*```',
                r'```\s*(.*?)\s*```',
                r'(\{.*?\})'
            ]

            for pattern in json_patterns:
                matches = re.findall(pattern, clean_response, re.DOTALL)
                if matches:
                    try:
                        return json.loads(matches[0])
                    except json.JSONDecodeError:
                        continue

            try:
                return json.loads(clean_response)
            except json.JSONDecodeError:
                return None

        except Exception as e:
            return None

class ABTesterPrompt3:
    """Ejecutor de pruebas A/B para Prompt 3"""

    def __init__(self):
        self.gemini_client = GeminiClient()
        self.optimizer = Prompt3Optimizer(self.gemini_client)

        # Casos de prueba realistas
        self.test_cases = [
            {
                "user_query": "cu√°ntos alumnos hay en la escuela",
                "sql_query": "SELECT COUNT(*) as total FROM alumnos",
                "data": [{"total": 211}],
                "row_count": 1
            },
            {
                "user_query": "alumnos de 3er grado",
                "sql_query": "SELECT nombre, curp FROM alumnos a JOIN datos_escolares de ON a.id = de.alumno_id WHERE de.grado = 3",
                "data": [
                    {"nombre": "JUAN P√âREZ GARC√çA", "curp": "PEGJ120515HDFRZN01"},
                    {"nombre": "MAR√çA L√ìPEZ SANTOS", "curp": "LOSM130620MDFPNR02"},
                    {"nombre": "CARLOS RUIZ MENDOZA", "curp": "RUMC140710HDFZRL03"}
                ],
                "row_count": 3
            },
            {
                "user_query": "buscar a Mar√≠a Garc√≠a",
                "sql_query": "SELECT * FROM alumnos WHERE nombre LIKE '%MARIA%' AND nombre LIKE '%GARCIA%'",
                "data": [
                    {"id": 15, "nombre": "MAR√çA GARC√çA L√ìPEZ", "curp": "GALM130515MDFRZR01", "matricula": "2024001"}
                ],
                "row_count": 1
            },
            {
                "user_query": "estad√≠sticas por grado",
                "sql_query": "SELECT grado, COUNT(*) as total FROM datos_escolares GROUP BY grado",
                "data": [
                    {"grado": 1, "total": 35},
                    {"grado": 2, "total": 38},
                    {"grado": 3, "total": 42},
                    {"grado": 4, "total": 39},
                    {"grado": 5, "total": 33},
                    {"grado": 6, "total": 24}
                ],
                "row_count": 6
            }
        ]

    def run_single_test(self, test_case: Dict, version: str) -> TestResult:
        """Ejecuta una prueba individual"""
        start_time = time.time()

        try:
            if version == "original":
                result = self.optimizer.validate_and_generate_response_original(
                    test_case["user_query"],
                    test_case["sql_query"],
                    test_case["data"],
                    test_case["row_count"]
                )
            else:
                result = self.optimizer.validate_and_generate_response_optimized(
                    test_case["user_query"],
                    test_case["sql_query"],
                    test_case["data"],
                    test_case["row_count"]
                )

            response_time = time.time() - start_time

            if result:
                has_reflection = "reflexion_conversacional" in result
                quality = "good" if result.get("respuesta_usuario") else "poor"

                return TestResult(
                    query=test_case["user_query"],
                    version=version,
                    response_time=response_time,
                    success=True,
                    response_quality=quality,
                    has_auto_reflection=has_reflection
                )
            else:
                return TestResult(
                    query=test_case["user_query"],
                    version=version,
                    response_time=response_time,
                    success=False,
                    response_quality="failed",
                    has_auto_reflection=False,
                    error="No response"
                )

        except Exception as e:
            response_time = time.time() - start_time
            return TestResult(
                query=test_case["user_query"],
                version=version,
                response_time=response_time,
                success=False,
                response_quality="error",
                has_auto_reflection=False,
                error=str(e)
            )

    def run_ab_test(self) -> Dict[str, Any]:
        """Ejecuta el test A/B completo"""
        print("üî¨ INICIANDO TESTING A/B DEL PROMPT 3 (CR√çTICO)")
        print("=" * 60)

        results = []

        for i, test_case in enumerate(self.test_cases, 1):
            print(f"\nüìù Test {i}/{len(self.test_cases)}: {test_case['user_query']}")

            # Test versi√≥n original
            print("   üîÑ Testing versi√≥n original...")
            original_result = self.run_single_test(test_case, "original")
            results.append(original_result)

            # Test versi√≥n optimizada
            print("   ‚ö° Testing versi√≥n optimizada...")
            optimized_result = self.run_single_test(test_case, "optimized")
            results.append(optimized_result)

            # Mostrar comparaci√≥n inmediata
            print(f"   üìä Original: {original_result.response_time:.2f}s | Optimizada: {optimized_result.response_time:.2f}s")

        return self.analyze_results(results)

    def analyze_results(self, results: List[TestResult]) -> Dict[str, Any]:
        """Analiza los resultados del testing"""
        original_results = [r for r in results if r.version == "original"]
        optimized_results = [r for r in results if r.version == "optimized"]

        # M√©tricas de tiempo
        original_times = [r.response_time for r in original_results if r.success]
        optimized_times = [r.response_time for r in optimized_results if r.success]

        # M√©tricas de calidad
        original_success_rate = len([r for r in original_results if r.success]) / len(original_results)
        optimized_success_rate = len([r for r in optimized_results if r.success]) / len(optimized_results)

        # M√©tricas de auto-reflexi√≥n
        original_reflection_rate = len([r for r in original_results if r.has_auto_reflection]) / len(original_results)
        optimized_reflection_rate = len([r for r in optimized_results if r.has_auto_reflection]) / len(optimized_results)

        analysis = {
            "timing": {
                "original_avg": statistics.mean(original_times) if original_times else 0,
                "optimized_avg": statistics.mean(optimized_times) if optimized_times else 0,
                "improvement_percent": 0,
                "original_times": original_times,
                "optimized_times": optimized_times
            },
            "quality": {
                "original_success_rate": original_success_rate,
                "optimized_success_rate": optimized_success_rate,
                "quality_maintained": optimized_success_rate >= original_success_rate * 0.95
            },
            "reflection": {
                "original_reflection_rate": original_reflection_rate,
                "optimized_reflection_rate": optimized_reflection_rate,
                "reflection_maintained": optimized_reflection_rate >= original_reflection_rate * 0.95
            },
            "detailed_results": results
        }

        if original_times and optimized_times:
            improvement = (statistics.mean(original_times) - statistics.mean(optimized_times)) / statistics.mean(original_times) * 100
            analysis["timing"]["improvement_percent"] = improvement

        return analysis

def main():
    """Funci√≥n principal"""
    tester = ABTesterPrompt3()
    results = tester.run_ab_test()

    print("\n" + "=" * 60)
    print("üìä RESULTADOS DEL TESTING A/B - PROMPT 3")
    print("=" * 60)

    timing = results["timing"]
    quality = results["quality"]
    reflection = results["reflection"]

    print(f"\n‚è±Ô∏è  M√âTRICAS DE TIEMPO:")
    print(f"   Original promedio: {timing['original_avg']:.2f}s")
    print(f"   Optimizada promedio: {timing['optimized_avg']:.2f}s")
    print(f"   Mejora: {timing['improvement_percent']:.1f}%")

    print(f"\nüéØ M√âTRICAS DE CALIDAD:")
    print(f"   Tasa √©xito original: {quality['original_success_rate']:.1%}")
    print(f"   Tasa √©xito optimizada: {quality['optimized_success_rate']:.1%}")
    print(f"   Calidad mantenida: {'‚úÖ S√ç' if quality['quality_maintained'] else '‚ùå NO'}")

    print(f"\nüß† M√âTRICAS DE AUTO-REFLEXI√ìN:")
    print(f"   Auto-reflexi√≥n original: {reflection['original_reflection_rate']:.1%}")
    print(f"   Auto-reflexi√≥n optimizada: {reflection['optimized_reflection_rate']:.1%}")
    print(f"   Auto-reflexi√≥n mantenida: {'‚úÖ S√ç' if reflection['reflection_maintained'] else '‚ùå NO'}")

    # Recomendaci√≥n (criterio ajustado para ser m√°s realista)
    if (timing['improvement_percent'] >= 15 and
        quality['quality_maintained'] and
        reflection['reflection_maintained']):
        print(f"\nüéâ RECOMENDACI√ìN: ‚úÖ IMPLEMENTAR VERSI√ìN OPTIMIZADA")
        print(f"   Mejora de velocidad ({timing['improvement_percent']:.1f}%) manteniendo calidad y funcionalidad")
    else:
        print(f"\n‚ö†Ô∏è  RECOMENDACI√ìN: ‚ùå NO IMPLEMENTAR")
        print(f"   Mejora insuficiente ({timing['improvement_percent']:.1f}% < 15%) o p√©rdida de calidad/funcionalidad")

if __name__ == "__main__":
    main()
